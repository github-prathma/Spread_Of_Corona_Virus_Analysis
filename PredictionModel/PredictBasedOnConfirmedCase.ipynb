{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('COVID19_open_line_list.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>country</th>\n",
       "      <th>wuhan(0)_not_wuhan(1)</th>\n",
       "      <th>date_onset_symptoms</th>\n",
       "      <th>date_admission_hospital</th>\n",
       "      <th>date_confirmation</th>\n",
       "      <th>symptoms</th>\n",
       "      <th>lives_in_Wuhan</th>\n",
       "      <th>travel_history_dates</th>\n",
       "      <th>travel_history_location</th>\n",
       "      <th>reported_market_exposure</th>\n",
       "      <th>chronic_disease_binary</th>\n",
       "      <th>chronic_disease</th>\n",
       "      <th>date_death_or_discharge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>11545</td>\n",
       "      <td>70-79</td>\n",
       "      <td>male</td>\n",
       "      <td>Japan</td>\n",
       "      <td>1</td>\n",
       "      <td>19.02.2020</td>\n",
       "      <td>20.02.2020</td>\n",
       "      <td>21.02.2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>1771</td>\n",
       "      <td>60-69</td>\n",
       "      <td>male</td>\n",
       "      <td>Japan</td>\n",
       "      <td>1</td>\n",
       "      <td>14.01.2020</td>\n",
       "      <td>25.01.2020</td>\n",
       "      <td>28.01.2020</td>\n",
       "      <td>chills, cough, joint pain</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>2594</td>\n",
       "      <td>60-69</td>\n",
       "      <td>male</td>\n",
       "      <td>Australia</td>\n",
       "      <td>1</td>\n",
       "      <td>23.01.2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.01.2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wuhan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>3021</td>\n",
       "      <td>60-69</td>\n",
       "      <td>male</td>\n",
       "      <td>United States</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.01.2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>11547</td>\n",
       "      <td>60-69</td>\n",
       "      <td>male</td>\n",
       "      <td>Japan</td>\n",
       "      <td>1</td>\n",
       "      <td>06.02.2020</td>\n",
       "      <td>21.02.2020</td>\n",
       "      <td>21.02.2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1575</th>\n",
       "      <td>5108</td>\n",
       "      <td>5</td>\n",
       "      <td>female</td>\n",
       "      <td>China</td>\n",
       "      <td>1</td>\n",
       "      <td>22.01.2020</td>\n",
       "      <td>27.01.2020</td>\n",
       "      <td>02.02.2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1577</th>\n",
       "      <td>9191</td>\n",
       "      <td>4</td>\n",
       "      <td>female</td>\n",
       "      <td>China</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08.02.2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>25.01.2020 -</td>\n",
       "      <td>Wuhan City</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1579</th>\n",
       "      <td>2362</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>China</td>\n",
       "      <td>1</td>\n",
       "      <td>27.01.2020</td>\n",
       "      <td>27.01.2020</td>\n",
       "      <td>29.01.2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>21.01.2020</td>\n",
       "      <td>Wuhan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1580</th>\n",
       "      <td>163</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>China</td>\n",
       "      <td>1</td>\n",
       "      <td>22.01.2020</td>\n",
       "      <td>23.01.2020</td>\n",
       "      <td>24.01.2020</td>\n",
       "      <td>fever, sneeze</td>\n",
       "      <td>yes</td>\n",
       "      <td>21.01.2020</td>\n",
       "      <td>Wuhan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1589</th>\n",
       "      <td>10921</td>\n",
       "      <td>0.25</td>\n",
       "      <td>female</td>\n",
       "      <td>Vietnam</td>\n",
       "      <td>1</td>\n",
       "      <td>06.02.2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.02.2020</td>\n",
       "      <td>cough, runny nose</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.02.2020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>484 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID    age     sex        country wuhan(0)_not_wuhan(1)  \\\n",
       "258   11545  70-79    male          Japan                     1   \n",
       "276    1771  60-69    male          Japan                     1   \n",
       "277    2594  60-69    male      Australia                     1   \n",
       "278    3021  60-69    male  United States                     1   \n",
       "287   11547  60-69    male          Japan                     1   \n",
       "...     ...    ...     ...            ...                   ...   \n",
       "1575   5108      5  female          China                     1   \n",
       "1577   9191      4  female          China                     1   \n",
       "1579   2362      3  female          China                     1   \n",
       "1580    163      2  female          China                     1   \n",
       "1589  10921   0.25  female        Vietnam                     1   \n",
       "\n",
       "     date_onset_symptoms date_admission_hospital date_confirmation  \\\n",
       "258           19.02.2020              20.02.2020        21.02.2020   \n",
       "276           14.01.2020              25.01.2020        28.01.2020   \n",
       "277           23.01.2020                     NaN        29.01.2020   \n",
       "278                  NaN                     NaN        30.01.2020   \n",
       "287           06.02.2020              21.02.2020        21.02.2020   \n",
       "...                  ...                     ...               ...   \n",
       "1575          22.01.2020              27.01.2020        02.02.2020   \n",
       "1577                 NaN                     NaN        08.02.2020   \n",
       "1579          27.01.2020              27.01.2020        29.01.2020   \n",
       "1580          22.01.2020              23.01.2020        24.01.2020   \n",
       "1589          06.02.2020                     NaN        11.02.2020   \n",
       "\n",
       "                       symptoms lives_in_Wuhan travel_history_dates  \\\n",
       "258                         NaN             no                  NaN   \n",
       "276   chills, cough, joint pain             no                  NaN   \n",
       "277                         NaN             no                  NaN   \n",
       "278                         NaN             no                  NaN   \n",
       "287                         NaN             no                  NaN   \n",
       "...                         ...            ...                  ...   \n",
       "1575                        NaN             no                  NaN   \n",
       "1577                        NaN             no         25.01.2020 -   \n",
       "1579                        NaN             no           21.01.2020   \n",
       "1580              fever, sneeze            yes           21.01.2020   \n",
       "1589          cough, runny nose             no                  NaN   \n",
       "\n",
       "     travel_history_location reported_market_exposure chronic_disease_binary  \\\n",
       "258                      NaN                      NaN                    NaN   \n",
       "276                      NaN                       no                    NaN   \n",
       "277                    Wuhan                      NaN                    NaN   \n",
       "278                      NaN                      NaN                    NaN   \n",
       "287                      NaN                      NaN                    NaN   \n",
       "...                      ...                      ...                    ...   \n",
       "1575                     NaN                      NaN                    NaN   \n",
       "1577              Wuhan City                      NaN                    NaN   \n",
       "1579                   Wuhan                      NaN                    NaN   \n",
       "1580                   Wuhan                      NaN                    NaN   \n",
       "1589                     NaN                      NaN                    NaN   \n",
       "\n",
       "     chronic_disease date_death_or_discharge  \n",
       "258              NaN                     NaN  \n",
       "276              NaN                     NaN  \n",
       "277              NaN                     NaN  \n",
       "278              NaN                     NaN  \n",
       "287              NaN                     NaN  \n",
       "...              ...                     ...  \n",
       "1575             NaN                     NaN  \n",
       "1577             NaN                     NaN  \n",
       "1579             NaN                     NaN  \n",
       "1580             NaN                     NaN  \n",
       "1589             NaN              20.02.2020  \n",
       "\n",
       "[484 rows x 16 columns]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[pd.notnull(df['age'])]\n",
    "df = df[pd.notnull(df['sex'])]\n",
    "df = df[pd.notnull(df['country'])]\n",
    "df = df[pd.notnull(df['lives_in_Wuhan'])]\n",
    "df.drop(columns = ['city','province','latitude','longitude','geo_resolution','additional_information','source','sequence_available','outcome','notes_for_discussion','location','admin3','admin2','admin1','country_new','admin_id','data_moderator_initials'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pneumonitis', 'runny nose', 'muscular soreness', 'rigor', 'physical discomfort', 'vomiting', 'myalgias', 'myalgia', 'soreness', 'lesions on chest radiographs', 'lack of energy', 'pleural effusion', 'coughing', 'diarrhea', 'feeling ill', 'sneeze', 'other symptoms', 'pleuritic chest pain', 'chest tightness', 'pharyngeal discomfort', 'muscle ache', 'fatigue', 'weak', 'sore throat', 'muscle soreness', 'severe dyspnea', 'pharynx', 'headache', 'respiratory symptoms', 'expectoration', 'nasal congestion', 'sneezing', 'nausea', 'cough', 'muscular stiffness', 'chest distress', 'chest pain', 'rhinorrhoea', 'pharyngalgia', 'sore limbs', 'shortness of breath', 'sore muscle', 'dizziness', 'eye irritation', 'pneumonia', 'discomfort', 'fever', 'dyspnea', 'anhelation', 'eventually showed acute left heart failure and acute coronary syndrome', 'muscle aches', 'joint pain', 'flu-like symptoms', 'muscle pain', 'weakness', 'conjunctivitis', 'asymptomatic', 'dry cough', 'diarrhoea', 'sputum', 'chills', 'sweating'}\n"
     ]
    }
   ],
   "source": [
    "test = df.iloc[:,13]\n",
    "symptom_set = set()\n",
    "for row in list(test):\n",
    "    row = str(row)\n",
    "    l = row.split(\",\")\n",
    "    for symp in l:\n",
    "        symp = symp.strip()\n",
    "        if symp == \"nan\":\n",
    "            continue\n",
    "        elif symp not in symptom_set:\n",
    "            if \"fever\" in symp or \"Fever\" in symp:\n",
    "                symptom_set.add(\"fever\")\n",
    "            else:\n",
    "                symptom_set.add(symp)\n",
    "        else:\n",
    "            continue\n",
    "print(symptom_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Japan': 0, 'Australia': 1, 'United States': 2, 'Canada': 3, 'Sweden': 4, 'Germany': 5, 'Finland': 6, 'China': 7, 'Singapore': 8, 'Thailand': 9, 'Vietnam': 10, 'South Korea': 11, 'Spain': 12, 'Cambodia': 13, 'North Macedonia': 14, 'Georgia': 15, 'France': 16, 'Philippines': 17, 'Malaysia': 18, 'Greece': 19, 'Afghanistan': 20, 'Estonia': 21, 'Nepal': 22, 'Italy': 23, 'Croatia': 24, 'Pakistan': 25, 'Romania': 26}\n"
     ]
    }
   ],
   "source": [
    "test = df.iloc[:,5]\n",
    "country_dict = dict()\n",
    "count = 0\n",
    "for row in list(test):\n",
    "    row = str(row)\n",
    "    if row in country_dict:\n",
    "        continue\n",
    "    else:\n",
    "        country_dict[row] = count\n",
    "        count+= 1\n",
    "print(country_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanedData = []\n",
    "count = 0\n",
    "Count = 0\n",
    "for index,row in df.iterrows():\n",
    "    cur = []\n",
    "    Count += 1\n",
    "    # Clean the age column\n",
    "    if str(row[\"age\"]).isnumeric():\n",
    "        #cur.append(int(row[\"age\"]) // 10)\n",
    "        cur += [0] * (int(row[\"age\"]) // 10) + [1] + (9 - (int(row[\"age\"]) // 10)) * [0]\n",
    "    else:\n",
    "        if \"-\" in row[\"age\"]:\n",
    "            loc = row[\"age\"].index(\"-\")\n",
    "            #cur.append(int(row[\"age\"][:loc]) // 10)\n",
    "            cur += [0] * (int(row[\"age\"][:loc]) // 10) + [1] + (9 - (int(row[\"age\"][:loc]) // 10)) * [0]\n",
    "        else:\n",
    "            #cur.append(int(float(row[\"age\"]) // 10))\n",
    "            cur += [0] * ((int(float(row[\"age\"]))) // 10) + [1] + (9 - ((int(float(row[\"age\"]))) // 10)) * [0]\n",
    "            \n",
    "    \n",
    "    # Clean the sex column\n",
    "    if row[\"sex\"] == \"male\":\n",
    "        cur += [1,0]\n",
    "    else:\n",
    "        cur += [0,1]\n",
    "    # Clean the country\n",
    "    #cur.append(country_dict[str(row[\"country\"])])\n",
    "    cur += [0]*(country_dict[str(row[\"country\"])]) + [1] + (26 -country_dict[str(row[\"country\"])]) * [0]\n",
    "    \n",
    "    # Clean the Wuhan column, check whether they are citizens in Wuhan, 1 means not Wuhan\n",
    "    cur.append(row[\"wuhan(0)_not_wuhan(1)\"])\n",
    "    # Clean the sympton date\n",
    "    \n",
    "    # Clean the sympton\n",
    "    temp = str(row[\"symptoms\"]).lower()\n",
    "    # fever, cough, pneumonitis, fatigue\n",
    "    # Fever- related\n",
    "    if \"fever\" in temp or \"headache\" in temp:\n",
    "        cur.append(1)\n",
    "    else:\n",
    "        cur.append(0)\n",
    "    # Cough related\n",
    "    if \"cou\" in temp or \"throa\" in temp or \"dry\" in temp or \"pharyngeal\" in temp or \"expectoration\" in temp or \"flu\" in temp:\n",
    "        cur.append(1)\n",
    "    else:\n",
    "        cur.append(0)\n",
    "    # Cold related\n",
    "    if \"chill\" in temp or \"nose\" in temp or \"nasal\" in temp or \"sneez\" in temp:\n",
    "        cur.append(1)\n",
    "    else:\n",
    "        cur.append(0)\n",
    "    # pneumonitis related\n",
    "    if \"pneumon\" in temp or \"respiratory\" in temp or \"breath\" in temp:\n",
    "        cur.append(1)\n",
    "    else:\n",
    "        cur.append(0)\n",
    "    # Muscle or fatigue, physical issue related\n",
    "    if \"fatigue\" in temp or \"myalgias\" in temp or \"musc\" in temp or \"walk\" in temp or \"chest\" in temp or \"limbs\" in temp or \"joint\" in temp or \"physical\" in temp or \"energy\" in temp:\n",
    "        cur.append(1)\n",
    "    else:\n",
    "        cur.append(0)\n",
    "    # Stomacha related\n",
    "    if \"diarrhoea\" in temp or \"abdominal\" in temp:\n",
    "        cur.append(1)\n",
    "    else:\n",
    "        cur.append(0)\n",
    "    # Other symptom or non-symptom\n",
    "    if len(temp) > 0 and temp != \"nan\":\n",
    "        cur.append(1)\n",
    "    else:\n",
    "        cur.append(0)\n",
    "    \n",
    "    # Clean the column whether live in Wuhan or have travel relations with Wuhan\n",
    "    if str(row[\"lives_in_Wuhan\"]).lower() == \"nan\" or str(row[\"lives_in_Wuhan\"]).lower() == \"no\" or \"wuhan\" not in str(row[\"travel_history_location\"]).lower():\n",
    "        cur.append(0)\n",
    "    else:\n",
    "        cur.append(1)\n",
    "        \n",
    "    # Clean the target value: date_death_or_discharge\n",
    "    if str(row[\"date_death_or_discharge\"]).lower() == \"nan\":\n",
    "        count += 1\n",
    "        cur.append(0)\n",
    "    else:\n",
    "        cur.append(1)\n",
    "    cleanedData.append(cur)\n",
    "    \n",
    "#print(count,Count)\n",
    "#print(cleanedData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "f = open(\"CleanedConfirmedCase.csv\", \"a\")\n",
    "fieldnames = ['0s','10s','20s','30s','40s','50s','60s','70s','80s','90s','Male','Female','Japan', 'Australia', 'United States', 'Canada', 'Sweden', 'Germany', 'Finland', 'China', 'Singapore', 'Thailand', 'Vietnam', 'South Korea', 'Spain', 'Cambodia', 'North Macedonia', 'Georgia', 'France', 'Philippines', 'Malaysia', 'Greece', 'Afghanistan', 'Estonia', 'Nepal', 'Italy', 'Croatia', 'Pakistan', 'Romania','Wuhan?','Fever','Cough','Cold','Pneumonitis','Fatigue','Stomacha','Other Symptoms','Relation with Wuhan','Death or Not']\n",
    "writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "writer.writeheader()\n",
    "writer = csv.writer(f)\n",
    "writer.writerows(cleanedData)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"CleanedConfirmedCase.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0s</th>\n",
       "      <th>10s</th>\n",
       "      <th>20s</th>\n",
       "      <th>30s</th>\n",
       "      <th>40s</th>\n",
       "      <th>50s</th>\n",
       "      <th>60s</th>\n",
       "      <th>70s</th>\n",
       "      <th>80s</th>\n",
       "      <th>90s</th>\n",
       "      <th>...</th>\n",
       "      <th>Wuhan?</th>\n",
       "      <th>Fever</th>\n",
       "      <th>Cough</th>\n",
       "      <th>Cold</th>\n",
       "      <th>Pneumonitis</th>\n",
       "      <th>Fatigue</th>\n",
       "      <th>Stomacha</th>\n",
       "      <th>Other Symptoms</th>\n",
       "      <th>Relation with Wuhan</th>\n",
       "      <th>Death or Not</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>484 rows Ã— 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0s  10s  20s  30s  40s  50s  60s  70s  80s  90s  ...  Wuhan?  Fever  \\\n",
       "0     0    0    0    0    0    0    0    1    0    0  ...       1      0   \n",
       "1     0    0    0    0    0    0    1    0    0    0  ...       1      0   \n",
       "2     0    0    0    0    0    0    1    0    0    0  ...       1      0   \n",
       "3     0    0    0    0    0    0    1    0    0    0  ...       1      0   \n",
       "4     0    0    0    0    0    0    1    0    0    0  ...       1      0   \n",
       "..   ..  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...     ...    ...   \n",
       "479   1    0    0    0    0    0    0    0    0    0  ...       1      0   \n",
       "480   1    0    0    0    0    0    0    0    0    0  ...       1      0   \n",
       "481   1    0    0    0    0    0    0    0    0    0  ...       1      0   \n",
       "482   1    0    0    0    0    0    0    0    0    0  ...       1      1   \n",
       "483   1    0    0    0    0    0    0    0    0    0  ...       1      0   \n",
       "\n",
       "     Cough  Cold  Pneumonitis  Fatigue  Stomacha  Other Symptoms  \\\n",
       "0        0     0            0        0         0               0   \n",
       "1        1     1            0        1         0               1   \n",
       "2        0     0            0        0         0               0   \n",
       "3        0     0            0        0         0               0   \n",
       "4        0     0            0        0         0               0   \n",
       "..     ...   ...          ...      ...       ...             ...   \n",
       "479      0     0            0        0         0               0   \n",
       "480      0     0            0        0         0               0   \n",
       "481      0     0            0        0         0               0   \n",
       "482      0     1            0        0         0               1   \n",
       "483      1     1            0        0         0               1   \n",
       "\n",
       "     Relation with Wuhan  Death or Not  \n",
       "0                      0             0  \n",
       "1                      0             0  \n",
       "2                      0             0  \n",
       "3                      0             0  \n",
       "4                      0             0  \n",
       "..                   ...           ...  \n",
       "479                    0             0  \n",
       "480                    0             0  \n",
       "481                    0             0  \n",
       "482                    1             0  \n",
       "483                    0             1  \n",
       "\n",
       "[484 rows x 49 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Wuhan?  Fever  Cough  Cold  Pneumonitis  Fatigue  Stomacha  \\\n",
      "0         1      0      0     0            0        0         0   \n",
      "1         1      0      1     1            0        1         0   \n",
      "2         1      0      0     0            0        0         0   \n",
      "3         1      0      0     0            0        0         0   \n",
      "4         1      0      0     0            0        0         0   \n",
      "..      ...    ...    ...   ...          ...      ...       ...   \n",
      "479       1      0      0     0            0        0         0   \n",
      "480       1      0      0     0            0        0         0   \n",
      "481       1      0      0     0            0        0         0   \n",
      "482       1      1      0     1            0        0         0   \n",
      "483       1      0      1     1            0        0         0   \n",
      "\n",
      "     Other Symptoms  Relation with Wuhan  \n",
      "0                 0                    0  \n",
      "1                 1                    0  \n",
      "2                 0                    0  \n",
      "3                 0                    0  \n",
      "4                 0                    0  \n",
      "..              ...                  ...  \n",
      "479               0                    0  \n",
      "480               0                    0  \n",
      "481               0                    0  \n",
      "482               1                    1  \n",
      "483               1                    0  \n",
      "\n",
      "[484 rows x 9 columns]\n",
      "0      0\n",
      "1      0\n",
      "2      0\n",
      "3      0\n",
      "4      0\n",
      "      ..\n",
      "479    0\n",
      "480    0\n",
      "481    0\n",
      "482    0\n",
      "483    1\n",
      "Name: Death or Not, Length: 484, dtype: int64\n",
      "Train on 387 samples, validate on 97 samples\n",
      "Epoch 1/300\n",
      "387/387 [==============================] - 0s 451us/step - loss: 0.5866 - accuracy: 0.8863 - val_loss: 0.5099 - val_accuracy: 0.9175\n",
      "Epoch 2/300\n",
      "387/387 [==============================] - 0s 131us/step - loss: 0.4092 - accuracy: 0.9612 - val_loss: 0.3970 - val_accuracy: 0.9175\n",
      "Epoch 3/300\n",
      "387/387 [==============================] - 0s 135us/step - loss: 0.2980 - accuracy: 0.9612 - val_loss: 0.3311 - val_accuracy: 0.9175\n",
      "Epoch 4/300\n",
      "387/387 [==============================] - 0s 128us/step - loss: 0.2309 - accuracy: 0.9612 - val_loss: 0.3002 - val_accuracy: 0.9175\n",
      "Epoch 5/300\n",
      "387/387 [==============================] - 0s 122us/step - loss: 0.1960 - accuracy: 0.9612 - val_loss: 0.2915 - val_accuracy: 0.9175\n",
      "Epoch 6/300\n",
      "387/387 [==============================] - 0s 126us/step - loss: 0.1784 - accuracy: 0.9612 - val_loss: 0.2922 - val_accuracy: 0.9175\n",
      "Epoch 7/300\n",
      "387/387 [==============================] - 0s 147us/step - loss: 0.1709 - accuracy: 0.9612 - val_loss: 0.2956 - val_accuracy: 0.9175\n",
      "Epoch 8/300\n",
      "387/387 [==============================] - 0s 164us/step - loss: 0.1676 - accuracy: 0.9612 - val_loss: 0.2992 - val_accuracy: 0.9175\n",
      "Epoch 9/300\n",
      "387/387 [==============================] - 0s 140us/step - loss: 0.1660 - accuracy: 0.9612 - val_loss: 0.3028 - val_accuracy: 0.9175\n",
      "Epoch 10/300\n",
      "387/387 [==============================] - 0s 133us/step - loss: 0.1655 - accuracy: 0.9612 - val_loss: 0.3054 - val_accuracy: 0.9175\n",
      "Epoch 11/300\n",
      "387/387 [==============================] - 0s 124us/step - loss: 0.1651 - accuracy: 0.9612 - val_loss: 0.3074 - val_accuracy: 0.9175\n",
      "Epoch 12/300\n",
      "387/387 [==============================] - 0s 126us/step - loss: 0.1651 - accuracy: 0.9612 - val_loss: 0.3091 - val_accuracy: 0.9175\n",
      "Epoch 13/300\n",
      "387/387 [==============================] - 0s 134us/step - loss: 0.1650 - accuracy: 0.9612 - val_loss: 0.3098 - val_accuracy: 0.9175\n",
      "Epoch 14/300\n",
      "387/387 [==============================] - 0s 133us/step - loss: 0.1650 - accuracy: 0.9612 - val_loss: 0.3106 - val_accuracy: 0.9175\n",
      "Epoch 15/300\n",
      "387/387 [==============================] - 0s 139us/step - loss: 0.1653 - accuracy: 0.9612 - val_loss: 0.3126 - val_accuracy: 0.9175\n",
      "Epoch 16/300\n",
      "387/387 [==============================] - 0s 169us/step - loss: 0.1650 - accuracy: 0.9612 - val_loss: 0.3130 - val_accuracy: 0.9175\n",
      "Epoch 17/300\n",
      "387/387 [==============================] - 0s 152us/step - loss: 0.1650 - accuracy: 0.9612 - val_loss: 0.3122 - val_accuracy: 0.9175\n",
      "Epoch 18/300\n",
      "387/387 [==============================] - 0s 139us/step - loss: 0.1648 - accuracy: 0.9612 - val_loss: 0.3123 - val_accuracy: 0.9175\n",
      "Epoch 19/300\n",
      "387/387 [==============================] - 0s 147us/step - loss: 0.1646 - accuracy: 0.9612 - val_loss: 0.3134 - val_accuracy: 0.9175\n",
      "Epoch 20/300\n",
      "387/387 [==============================] - 0s 166us/step - loss: 0.1649 - accuracy: 0.9612 - val_loss: 0.3129 - val_accuracy: 0.9175\n",
      "Epoch 21/300\n",
      "387/387 [==============================] - 0s 158us/step - loss: 0.1648 - accuracy: 0.9612 - val_loss: 0.3125 - val_accuracy: 0.9175\n",
      "Epoch 22/300\n",
      "387/387 [==============================] - 0s 151us/step - loss: 0.1648 - accuracy: 0.9612 - val_loss: 0.3130 - val_accuracy: 0.9175\n",
      "Epoch 23/300\n",
      "387/387 [==============================] - 0s 137us/step - loss: 0.1647 - accuracy: 0.9612 - val_loss: 0.3125 - val_accuracy: 0.9175\n",
      "Epoch 24/300\n",
      "387/387 [==============================] - 0s 138us/step - loss: 0.1645 - accuracy: 0.9612 - val_loss: 0.3117 - val_accuracy: 0.9175\n",
      "Epoch 25/300\n",
      "387/387 [==============================] - 0s 121us/step - loss: 0.1647 - accuracy: 0.9612 - val_loss: 0.3121 - val_accuracy: 0.9175\n",
      "Epoch 26/300\n",
      "387/387 [==============================] - 0s 124us/step - loss: 0.1645 - accuracy: 0.9612 - val_loss: 0.3120 - val_accuracy: 0.9175\n",
      "Epoch 27/300\n",
      "387/387 [==============================] - 0s 113us/step - loss: 0.1645 - accuracy: 0.9612 - val_loss: 0.3117 - val_accuracy: 0.9175\n",
      "Epoch 28/300\n",
      "387/387 [==============================] - 0s 120us/step - loss: 0.1642 - accuracy: 0.9612 - val_loss: 0.3125 - val_accuracy: 0.9175\n",
      "Epoch 29/300\n",
      "387/387 [==============================] - 0s 115us/step - loss: 0.1642 - accuracy: 0.9612 - val_loss: 0.3136 - val_accuracy: 0.9175\n",
      "Epoch 30/300\n",
      "387/387 [==============================] - 0s 129us/step - loss: 0.1644 - accuracy: 0.9612 - val_loss: 0.3127 - val_accuracy: 0.9175\n",
      "Epoch 31/300\n",
      "387/387 [==============================] - 0s 119us/step - loss: 0.1643 - accuracy: 0.9612 - val_loss: 0.3123 - val_accuracy: 0.9175\n",
      "Epoch 32/300\n",
      "387/387 [==============================] - 0s 128us/step - loss: 0.1645 - accuracy: 0.9612 - val_loss: 0.3119 - val_accuracy: 0.9175\n",
      "Epoch 33/300\n",
      "387/387 [==============================] - 0s 128us/step - loss: 0.1644 - accuracy: 0.9612 - val_loss: 0.3113 - val_accuracy: 0.9175\n",
      "Epoch 34/300\n",
      "387/387 [==============================] - 0s 129us/step - loss: 0.1639 - accuracy: 0.9612 - val_loss: 0.3110 - val_accuracy: 0.9175\n",
      "Epoch 35/300\n",
      "387/387 [==============================] - 0s 118us/step - loss: 0.1638 - accuracy: 0.9612 - val_loss: 0.3117 - val_accuracy: 0.9175\n",
      "Epoch 36/300\n",
      "387/387 [==============================] - 0s 121us/step - loss: 0.1645 - accuracy: 0.9612 - val_loss: 0.3123 - val_accuracy: 0.9175\n",
      "Epoch 37/300\n",
      "387/387 [==============================] - 0s 116us/step - loss: 0.1640 - accuracy: 0.9612 - val_loss: 0.3113 - val_accuracy: 0.9175\n",
      "Epoch 38/300\n",
      "387/387 [==============================] - 0s 119us/step - loss: 0.1639 - accuracy: 0.9612 - val_loss: 0.3111 - val_accuracy: 0.9175\n",
      "Epoch 39/300\n",
      "387/387 [==============================] - 0s 121us/step - loss: 0.1641 - accuracy: 0.9612 - val_loss: 0.3106 - val_accuracy: 0.9175\n",
      "Epoch 40/300\n",
      "387/387 [==============================] - 0s 123us/step - loss: 0.1638 - accuracy: 0.9612 - val_loss: 0.3107 - val_accuracy: 0.9175\n",
      "Epoch 41/300\n",
      "387/387 [==============================] - 0s 145us/step - loss: 0.1638 - accuracy: 0.9612 - val_loss: 0.3110 - val_accuracy: 0.9175\n",
      "Epoch 42/300\n",
      "387/387 [==============================] - 0s 119us/step - loss: 0.1641 - accuracy: 0.9612 - val_loss: 0.3115 - val_accuracy: 0.9175\n",
      "Epoch 43/300\n",
      "387/387 [==============================] - 0s 113us/step - loss: 0.1637 - accuracy: 0.9612 - val_loss: 0.3100 - val_accuracy: 0.9175\n",
      "Epoch 44/300\n",
      "387/387 [==============================] - 0s 121us/step - loss: 0.1635 - accuracy: 0.9612 - val_loss: 0.3098 - val_accuracy: 0.9175\n",
      "Epoch 45/300\n",
      "387/387 [==============================] - 0s 125us/step - loss: 0.1635 - accuracy: 0.9612 - val_loss: 0.3097 - val_accuracy: 0.9175\n",
      "Epoch 46/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "387/387 [==============================] - 0s 118us/step - loss: 0.1636 - accuracy: 0.9612 - val_loss: 0.3098 - val_accuracy: 0.9175\n",
      "Epoch 47/300\n",
      "387/387 [==============================] - 0s 126us/step - loss: 0.1635 - accuracy: 0.9612 - val_loss: 0.3096 - val_accuracy: 0.9175\n",
      "Epoch 48/300\n",
      "387/387 [==============================] - 0s 120us/step - loss: 0.1634 - accuracy: 0.9612 - val_loss: 0.3091 - val_accuracy: 0.9175\n",
      "Epoch 49/300\n",
      "387/387 [==============================] - 0s 110us/step - loss: 0.1628 - accuracy: 0.9612 - val_loss: 0.3115 - val_accuracy: 0.9175\n",
      "Epoch 50/300\n",
      "387/387 [==============================] - 0s 114us/step - loss: 0.1640 - accuracy: 0.9612 - val_loss: 0.3119 - val_accuracy: 0.9175\n",
      "Epoch 51/300\n",
      "387/387 [==============================] - 0s 112us/step - loss: 0.1635 - accuracy: 0.9612 - val_loss: 0.3111 - val_accuracy: 0.9175\n",
      "Epoch 52/300\n",
      "387/387 [==============================] - 0s 114us/step - loss: 0.1632 - accuracy: 0.9612 - val_loss: 0.3113 - val_accuracy: 0.9175\n",
      "Epoch 53/300\n",
      "387/387 [==============================] - 0s 130us/step - loss: 0.1632 - accuracy: 0.9612 - val_loss: 0.3114 - val_accuracy: 0.9175\n",
      "Epoch 54/300\n",
      "387/387 [==============================] - 0s 118us/step - loss: 0.1636 - accuracy: 0.9612 - val_loss: 0.3105 - val_accuracy: 0.9175\n",
      "Epoch 55/300\n",
      "387/387 [==============================] - 0s 114us/step - loss: 0.1632 - accuracy: 0.9612 - val_loss: 0.3108 - val_accuracy: 0.9175\n",
      "Epoch 56/300\n",
      "387/387 [==============================] - 0s 122us/step - loss: 0.1633 - accuracy: 0.9612 - val_loss: 0.3106 - val_accuracy: 0.9175\n",
      "Epoch 57/300\n",
      "387/387 [==============================] - 0s 114us/step - loss: 0.1631 - accuracy: 0.9612 - val_loss: 0.3104 - val_accuracy: 0.9175\n",
      "Epoch 58/300\n",
      "387/387 [==============================] - 0s 122us/step - loss: 0.1632 - accuracy: 0.9612 - val_loss: 0.3106 - val_accuracy: 0.9175\n",
      "Epoch 59/300\n",
      "387/387 [==============================] - 0s 114us/step - loss: 0.1633 - accuracy: 0.9612 - val_loss: 0.3101 - val_accuracy: 0.9175\n",
      "Epoch 60/300\n",
      "387/387 [==============================] - 0s 116us/step - loss: 0.1631 - accuracy: 0.9612 - val_loss: 0.3098 - val_accuracy: 0.9175\n",
      "Epoch 61/300\n",
      "387/387 [==============================] - 0s 113us/step - loss: 0.1630 - accuracy: 0.9612 - val_loss: 0.3092 - val_accuracy: 0.9175\n",
      "Epoch 62/300\n",
      "387/387 [==============================] - 0s 118us/step - loss: 0.1629 - accuracy: 0.9612 - val_loss: 0.3082 - val_accuracy: 0.9175\n",
      "Epoch 63/300\n",
      "387/387 [==============================] - 0s 121us/step - loss: 0.1629 - accuracy: 0.9612 - val_loss: 0.3075 - val_accuracy: 0.9175\n",
      "Epoch 64/300\n",
      "387/387 [==============================] - 0s 115us/step - loss: 0.1629 - accuracy: 0.9612 - val_loss: 0.3085 - val_accuracy: 0.9175\n",
      "Epoch 65/300\n",
      "387/387 [==============================] - 0s 109us/step - loss: 0.1627 - accuracy: 0.9612 - val_loss: 0.3092 - val_accuracy: 0.9175\n",
      "Epoch 66/300\n",
      "387/387 [==============================] - 0s 118us/step - loss: 0.1626 - accuracy: 0.9612 - val_loss: 0.3103 - val_accuracy: 0.9175\n",
      "Epoch 67/300\n",
      "387/387 [==============================] - 0s 113us/step - loss: 0.1633 - accuracy: 0.9612 - val_loss: 0.3107 - val_accuracy: 0.9175\n",
      "Epoch 68/300\n",
      "387/387 [==============================] - 0s 113us/step - loss: 0.1628 - accuracy: 0.9612 - val_loss: 0.3090 - val_accuracy: 0.9175\n",
      "Epoch 69/300\n",
      "387/387 [==============================] - 0s 116us/step - loss: 0.1628 - accuracy: 0.9612 - val_loss: 0.3093 - val_accuracy: 0.9175\n",
      "Epoch 70/300\n",
      "387/387 [==============================] - 0s 120us/step - loss: 0.1629 - accuracy: 0.9612 - val_loss: 0.3086 - val_accuracy: 0.9175\n",
      "Epoch 71/300\n",
      "387/387 [==============================] - 0s 121us/step - loss: 0.1626 - accuracy: 0.9612 - val_loss: 0.3081 - val_accuracy: 0.9175\n",
      "Epoch 72/300\n",
      "387/387 [==============================] - 0s 114us/step - loss: 0.1625 - accuracy: 0.9612 - val_loss: 0.3084 - val_accuracy: 0.9175\n",
      "Epoch 73/300\n",
      "387/387 [==============================] - 0s 113us/step - loss: 0.1626 - accuracy: 0.9612 - val_loss: 0.3081 - val_accuracy: 0.9175\n",
      "Epoch 74/300\n",
      "387/387 [==============================] - 0s 122us/step - loss: 0.1625 - accuracy: 0.9612 - val_loss: 0.3067 - val_accuracy: 0.9175\n",
      "Epoch 75/300\n",
      "387/387 [==============================] - 0s 112us/step - loss: 0.1623 - accuracy: 0.9612 - val_loss: 0.3065 - val_accuracy: 0.9175\n",
      "Epoch 76/300\n",
      "387/387 [==============================] - 0s 129us/step - loss: 0.1622 - accuracy: 0.9612 - val_loss: 0.3072 - val_accuracy: 0.9175\n",
      "Epoch 77/300\n",
      "387/387 [==============================] - 0s 129us/step - loss: 0.1624 - accuracy: 0.9612 - val_loss: 0.3078 - val_accuracy: 0.9175\n",
      "Epoch 78/300\n",
      "387/387 [==============================] - 0s 118us/step - loss: 0.1622 - accuracy: 0.9612 - val_loss: 0.3076 - val_accuracy: 0.9175\n",
      "Epoch 79/300\n",
      "387/387 [==============================] - 0s 119us/step - loss: 0.1622 - accuracy: 0.9612 - val_loss: 0.3072 - val_accuracy: 0.9175\n",
      "Epoch 80/300\n",
      "387/387 [==============================] - 0s 116us/step - loss: 0.1623 - accuracy: 0.9612 - val_loss: 0.3073 - val_accuracy: 0.9175\n",
      "Epoch 81/300\n",
      "387/387 [==============================] - 0s 113us/step - loss: 0.1621 - accuracy: 0.9612 - val_loss: 0.3073 - val_accuracy: 0.9175\n",
      "Epoch 82/300\n",
      "387/387 [==============================] - 0s 116us/step - loss: 0.1621 - accuracy: 0.9612 - val_loss: 0.3076 - val_accuracy: 0.9175\n",
      "Epoch 83/300\n",
      "387/387 [==============================] - 0s 138us/step - loss: 0.1623 - accuracy: 0.9612 - val_loss: 0.3078 - val_accuracy: 0.9175\n",
      "Epoch 84/300\n",
      "387/387 [==============================] - 0s 141us/step - loss: 0.1620 - accuracy: 0.9612 - val_loss: 0.3070 - val_accuracy: 0.9175\n",
      "Epoch 85/300\n",
      "387/387 [==============================] - 0s 119us/step - loss: 0.1620 - accuracy: 0.9612 - val_loss: 0.3069 - val_accuracy: 0.9175\n",
      "Epoch 86/300\n",
      "387/387 [==============================] - 0s 112us/step - loss: 0.1619 - accuracy: 0.9612 - val_loss: 0.3054 - val_accuracy: 0.9175\n",
      "Epoch 87/300\n",
      "387/387 [==============================] - 0s 114us/step - loss: 0.1619 - accuracy: 0.9612 - val_loss: 0.3057 - val_accuracy: 0.9175\n",
      "Epoch 88/300\n",
      "387/387 [==============================] - 0s 115us/step - loss: 0.1625 - accuracy: 0.9612 - val_loss: 0.3073 - val_accuracy: 0.9175\n",
      "Epoch 89/300\n",
      "387/387 [==============================] - 0s 114us/step - loss: 0.1619 - accuracy: 0.9612 - val_loss: 0.3067 - val_accuracy: 0.9175\n",
      "Epoch 90/300\n",
      "387/387 [==============================] - 0s 122us/step - loss: 0.1615 - accuracy: 0.9612 - val_loss: 0.3080 - val_accuracy: 0.9175\n",
      "Epoch 91/300\n",
      "387/387 [==============================] - 0s 121us/step - loss: 0.1618 - accuracy: 0.9612 - val_loss: 0.3073 - val_accuracy: 0.9175\n",
      "Epoch 92/300\n",
      "387/387 [==============================] - 0s 121us/step - loss: 0.1620 - accuracy: 0.9612 - val_loss: 0.3079 - val_accuracy: 0.9175\n",
      "Epoch 93/300\n",
      "387/387 [==============================] - 0s 126us/step - loss: 0.1619 - accuracy: 0.9612 - val_loss: 0.3062 - val_accuracy: 0.9175\n",
      "Epoch 94/300\n",
      "387/387 [==============================] - 0s 119us/step - loss: 0.1616 - accuracy: 0.9612 - val_loss: 0.3050 - val_accuracy: 0.9175\n",
      "Epoch 95/300\n",
      "387/387 [==============================] - 0s 121us/step - loss: 0.1615 - accuracy: 0.9612 - val_loss: 0.3045 - val_accuracy: 0.9175\n",
      "Epoch 96/300\n",
      "387/387 [==============================] - 0s 113us/step - loss: 0.1615 - accuracy: 0.9612 - val_loss: 0.3041 - val_accuracy: 0.9175\n",
      "Epoch 97/300\n",
      "387/387 [==============================] - 0s 117us/step - loss: 0.1614 - accuracy: 0.9612 - val_loss: 0.3048 - val_accuracy: 0.9175\n",
      "Epoch 98/300\n",
      "387/387 [==============================] - 0s 115us/step - loss: 0.1613 - accuracy: 0.9612 - val_loss: 0.3052 - val_accuracy: 0.9175\n",
      "Epoch 99/300\n",
      "387/387 [==============================] - 0s 124us/step - loss: 0.1613 - accuracy: 0.9612 - val_loss: 0.3050 - val_accuracy: 0.9175\n",
      "Epoch 100/300\n",
      "387/387 [==============================] - 0s 123us/step - loss: 0.1613 - accuracy: 0.9612 - val_loss: 0.3053 - val_accuracy: 0.9175\n",
      "Epoch 101/300\n",
      "387/387 [==============================] - 0s 121us/step - loss: 0.1613 - accuracy: 0.9612 - val_loss: 0.3056 - val_accuracy: 0.9175\n",
      "Epoch 102/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "387/387 [==============================] - 0s 117us/step - loss: 0.1613 - accuracy: 0.9612 - val_loss: 0.3055 - val_accuracy: 0.9175\n",
      "Epoch 103/300\n",
      "387/387 [==============================] - 0s 126us/step - loss: 0.1613 - accuracy: 0.9612 - val_loss: 0.3053 - val_accuracy: 0.9175\n",
      "Epoch 104/300\n",
      "387/387 [==============================] - 0s 123us/step - loss: 0.1612 - accuracy: 0.9612 - val_loss: 0.3062 - val_accuracy: 0.9175\n",
      "Epoch 105/300\n",
      "387/387 [==============================] - 0s 131us/step - loss: 0.1614 - accuracy: 0.9612 - val_loss: 0.3056 - val_accuracy: 0.9175\n",
      "Epoch 106/300\n",
      "387/387 [==============================] - 0s 115us/step - loss: 0.1612 - accuracy: 0.9612 - val_loss: 0.3066 - val_accuracy: 0.9175\n",
      "Epoch 107/300\n",
      "387/387 [==============================] - 0s 115us/step - loss: 0.1612 - accuracy: 0.9612 - val_loss: 0.3052 - val_accuracy: 0.9175\n",
      "Epoch 108/300\n",
      "387/387 [==============================] - 0s 110us/step - loss: 0.1613 - accuracy: 0.9612 - val_loss: 0.3052 - val_accuracy: 0.9175\n",
      "Epoch 109/300\n",
      "387/387 [==============================] - 0s 116us/step - loss: 0.1610 - accuracy: 0.9612 - val_loss: 0.3048 - val_accuracy: 0.9175\n",
      "Epoch 110/300\n",
      "387/387 [==============================] - 0s 117us/step - loss: 0.1610 - accuracy: 0.9612 - val_loss: 0.3047 - val_accuracy: 0.9175\n",
      "Epoch 111/300\n",
      "387/387 [==============================] - 0s 113us/step - loss: 0.1610 - accuracy: 0.9612 - val_loss: 0.3048 - val_accuracy: 0.9175\n",
      "Epoch 112/300\n",
      "387/387 [==============================] - 0s 118us/step - loss: 0.1609 - accuracy: 0.9612 - val_loss: 0.3045 - val_accuracy: 0.9175\n",
      "Epoch 113/300\n",
      "387/387 [==============================] - 0s 132us/step - loss: 0.1609 - accuracy: 0.9612 - val_loss: 0.3041 - val_accuracy: 0.9175\n",
      "Epoch 114/300\n",
      "387/387 [==============================] - 0s 115us/step - loss: 0.1608 - accuracy: 0.9612 - val_loss: 0.3045 - val_accuracy: 0.9175\n",
      "Epoch 115/300\n",
      "387/387 [==============================] - 0s 115us/step - loss: 0.1608 - accuracy: 0.9612 - val_loss: 0.3054 - val_accuracy: 0.9175\n",
      "Epoch 116/300\n",
      "387/387 [==============================] - 0s 121us/step - loss: 0.1611 - accuracy: 0.9612 - val_loss: 0.3050 - val_accuracy: 0.9175\n",
      "Epoch 117/300\n",
      "387/387 [==============================] - 0s 116us/step - loss: 0.1606 - accuracy: 0.9612 - val_loss: 0.3030 - val_accuracy: 0.9175\n",
      "Epoch 118/300\n",
      "387/387 [==============================] - 0s 127us/step - loss: 0.1609 - accuracy: 0.9612 - val_loss: 0.3035 - val_accuracy: 0.9175\n",
      "Epoch 119/300\n",
      "387/387 [==============================] - 0s 115us/step - loss: 0.1606 - accuracy: 0.9612 - val_loss: 0.3031 - val_accuracy: 0.9175\n",
      "Epoch 120/300\n",
      "387/387 [==============================] - 0s 119us/step - loss: 0.1606 - accuracy: 0.9612 - val_loss: 0.3030 - val_accuracy: 0.9175\n",
      "Epoch 121/300\n",
      "387/387 [==============================] - 0s 116us/step - loss: 0.1605 - accuracy: 0.9612 - val_loss: 0.3030 - val_accuracy: 0.9175\n",
      "Epoch 122/300\n",
      "387/387 [==============================] - 0s 125us/step - loss: 0.1608 - accuracy: 0.9612 - val_loss: 0.3042 - val_accuracy: 0.9175\n",
      "Epoch 123/300\n",
      "387/387 [==============================] - 0s 111us/step - loss: 0.1605 - accuracy: 0.9612 - val_loss: 0.3036 - val_accuracy: 0.9175\n",
      "Epoch 124/300\n",
      "387/387 [==============================] - 0s 117us/step - loss: 0.1606 - accuracy: 0.9612 - val_loss: 0.3038 - val_accuracy: 0.9175\n",
      "Epoch 125/300\n",
      "387/387 [==============================] - 0s 113us/step - loss: 0.1605 - accuracy: 0.9612 - val_loss: 0.3039 - val_accuracy: 0.9175\n",
      "Epoch 126/300\n",
      "387/387 [==============================] - 0s 114us/step - loss: 0.1609 - accuracy: 0.9612 - val_loss: 0.3044 - val_accuracy: 0.9175\n",
      "Epoch 127/300\n",
      "387/387 [==============================] - 0s 123us/step - loss: 0.1603 - accuracy: 0.9612 - val_loss: 0.3044 - val_accuracy: 0.9175\n",
      "Epoch 128/300\n",
      "387/387 [==============================] - 0s 123us/step - loss: 0.1605 - accuracy: 0.9612 - val_loss: 0.3031 - val_accuracy: 0.9175\n",
      "Epoch 129/300\n",
      "387/387 [==============================] - 0s 116us/step - loss: 0.1602 - accuracy: 0.9612 - val_loss: 0.3018 - val_accuracy: 0.9175\n",
      "Epoch 130/300\n",
      "387/387 [==============================] - 0s 110us/step - loss: 0.1603 - accuracy: 0.9612 - val_loss: 0.3023 - val_accuracy: 0.9175\n",
      "Epoch 131/300\n",
      "387/387 [==============================] - 0s 111us/step - loss: 0.1601 - accuracy: 0.9612 - val_loss: 0.3026 - val_accuracy: 0.9175\n",
      "Epoch 132/300\n",
      "387/387 [==============================] - 0s 115us/step - loss: 0.1604 - accuracy: 0.9612 - val_loss: 0.3031 - val_accuracy: 0.9175\n",
      "Epoch 133/300\n",
      "387/387 [==============================] - 0s 115us/step - loss: 0.1602 - accuracy: 0.9612 - val_loss: 0.3021 - val_accuracy: 0.9175\n",
      "Epoch 134/300\n",
      "387/387 [==============================] - 0s 114us/step - loss: 0.1601 - accuracy: 0.9612 - val_loss: 0.3019 - val_accuracy: 0.9175\n",
      "Epoch 135/300\n",
      "387/387 [==============================] - 0s 124us/step - loss: 0.1600 - accuracy: 0.9612 - val_loss: 0.3013 - val_accuracy: 0.9175\n",
      "Epoch 136/300\n",
      "387/387 [==============================] - 0s 117us/step - loss: 0.1599 - accuracy: 0.9612 - val_loss: 0.3019 - val_accuracy: 0.9175\n",
      "Epoch 137/300\n",
      "387/387 [==============================] - 0s 117us/step - loss: 0.1600 - accuracy: 0.9612 - val_loss: 0.3025 - val_accuracy: 0.9175\n",
      "Epoch 138/300\n",
      "387/387 [==============================] - 0s 116us/step - loss: 0.1599 - accuracy: 0.9612 - val_loss: 0.3037 - val_accuracy: 0.9175\n",
      "Epoch 139/300\n",
      "387/387 [==============================] - 0s 114us/step - loss: 0.1602 - accuracy: 0.9612 - val_loss: 0.3034 - val_accuracy: 0.9175\n",
      "Epoch 140/300\n",
      "387/387 [==============================] - 0s 121us/step - loss: 0.1601 - accuracy: 0.9612 - val_loss: 0.3025 - val_accuracy: 0.9175\n",
      "Epoch 141/300\n",
      "387/387 [==============================] - 0s 124us/step - loss: 0.1598 - accuracy: 0.9612 - val_loss: 0.3020 - val_accuracy: 0.9175\n",
      "Epoch 142/300\n",
      "387/387 [==============================] - 0s 127us/step - loss: 0.1597 - accuracy: 0.9612 - val_loss: 0.3015 - val_accuracy: 0.9175\n",
      "Epoch 143/300\n",
      "387/387 [==============================] - 0s 130us/step - loss: 0.1598 - accuracy: 0.9612 - val_loss: 0.3021 - val_accuracy: 0.9175\n",
      "Epoch 144/300\n",
      "387/387 [==============================] - 0s 117us/step - loss: 0.1599 - accuracy: 0.9612 - val_loss: 0.3031 - val_accuracy: 0.9175\n",
      "Epoch 145/300\n",
      "387/387 [==============================] - 0s 117us/step - loss: 0.1598 - accuracy: 0.9612 - val_loss: 0.3028 - val_accuracy: 0.9175\n",
      "Epoch 146/300\n",
      "387/387 [==============================] - 0s 112us/step - loss: 0.1597 - accuracy: 0.9612 - val_loss: 0.3023 - val_accuracy: 0.9175\n",
      "Epoch 147/300\n",
      "387/387 [==============================] - 0s 115us/step - loss: 0.1597 - accuracy: 0.9612 - val_loss: 0.3024 - val_accuracy: 0.9175\n",
      "Epoch 148/300\n",
      "387/387 [==============================] - 0s 148us/step - loss: 0.1597 - accuracy: 0.9612 - val_loss: 0.3028 - val_accuracy: 0.9175\n",
      "Epoch 149/300\n",
      "387/387 [==============================] - 0s 116us/step - loss: 0.1596 - accuracy: 0.9612 - val_loss: 0.3025 - val_accuracy: 0.9175\n",
      "Epoch 150/300\n",
      "387/387 [==============================] - 0s 112us/step - loss: 0.1595 - accuracy: 0.9612 - val_loss: 0.3016 - val_accuracy: 0.9175\n",
      "Epoch 151/300\n",
      "387/387 [==============================] - 0s 118us/step - loss: 0.1594 - accuracy: 0.9612 - val_loss: 0.3022 - val_accuracy: 0.9175\n",
      "Epoch 152/300\n",
      "387/387 [==============================] - 0s 122us/step - loss: 0.1595 - accuracy: 0.9612 - val_loss: 0.3017 - val_accuracy: 0.9175\n",
      "Epoch 153/300\n",
      "387/387 [==============================] - 0s 128us/step - loss: 0.1595 - accuracy: 0.9612 - val_loss: 0.3017 - val_accuracy: 0.9175\n",
      "Epoch 154/300\n",
      "387/387 [==============================] - 0s 132us/step - loss: 0.1593 - accuracy: 0.9612 - val_loss: 0.3023 - val_accuracy: 0.9175\n",
      "Epoch 155/300\n",
      "387/387 [==============================] - 0s 142us/step - loss: 0.1593 - accuracy: 0.9612 - val_loss: 0.3029 - val_accuracy: 0.9175\n",
      "Epoch 156/300\n",
      "387/387 [==============================] - 0s 127us/step - loss: 0.1595 - accuracy: 0.9612 - val_loss: 0.3019 - val_accuracy: 0.9175\n",
      "Epoch 157/300\n",
      "387/387 [==============================] - 0s 112us/step - loss: 0.1598 - accuracy: 0.9612 - val_loss: 0.3027 - val_accuracy: 0.9175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 158/300\n",
      "387/387 [==============================] - 0s 113us/step - loss: 0.1594 - accuracy: 0.9612 - val_loss: 0.3020 - val_accuracy: 0.9175\n",
      "Epoch 159/300\n",
      "387/387 [==============================] - 0s 112us/step - loss: 0.1594 - accuracy: 0.9612 - val_loss: 0.3010 - val_accuracy: 0.9175\n",
      "Epoch 160/300\n",
      "387/387 [==============================] - 0s 111us/step - loss: 0.1592 - accuracy: 0.9612 - val_loss: 0.3013 - val_accuracy: 0.9175\n",
      "Epoch 161/300\n",
      "387/387 [==============================] - 0s 125us/step - loss: 0.1592 - accuracy: 0.9612 - val_loss: 0.3012 - val_accuracy: 0.9175\n",
      "Epoch 162/300\n",
      "387/387 [==============================] - 0s 120us/step - loss: 0.1592 - accuracy: 0.9612 - val_loss: 0.3014 - val_accuracy: 0.9175\n",
      "Epoch 163/300\n",
      "387/387 [==============================] - 0s 124us/step - loss: 0.1590 - accuracy: 0.9612 - val_loss: 0.3017 - val_accuracy: 0.9175\n",
      "Epoch 164/300\n",
      "387/387 [==============================] - 0s 133us/step - loss: 0.1590 - accuracy: 0.9612 - val_loss: 0.3023 - val_accuracy: 0.9175\n",
      "Epoch 165/300\n",
      "387/387 [==============================] - 0s 119us/step - loss: 0.1592 - accuracy: 0.9612 - val_loss: 0.3017 - val_accuracy: 0.9175\n",
      "Epoch 166/300\n",
      "387/387 [==============================] - 0s 116us/step - loss: 0.1590 - accuracy: 0.9612 - val_loss: 0.3010 - val_accuracy: 0.9175\n",
      "Epoch 167/300\n",
      "387/387 [==============================] - 0s 121us/step - loss: 0.1592 - accuracy: 0.9612 - val_loss: 0.3014 - val_accuracy: 0.9175\n",
      "Epoch 168/300\n",
      "387/387 [==============================] - 0s 123us/step - loss: 0.1591 - accuracy: 0.9612 - val_loss: 0.3017 - val_accuracy: 0.9175\n",
      "Epoch 169/300\n",
      "387/387 [==============================] - 0s 109us/step - loss: 0.1592 - accuracy: 0.9612 - val_loss: 0.3012 - val_accuracy: 0.9175\n",
      "Epoch 170/300\n",
      "387/387 [==============================] - 0s 112us/step - loss: 0.1589 - accuracy: 0.9612 - val_loss: 0.3004 - val_accuracy: 0.9175\n",
      "Epoch 171/300\n",
      "387/387 [==============================] - 0s 110us/step - loss: 0.1588 - accuracy: 0.9612 - val_loss: 0.3010 - val_accuracy: 0.9175\n",
      "Epoch 172/300\n",
      "387/387 [==============================] - 0s 117us/step - loss: 0.1589 - accuracy: 0.9612 - val_loss: 0.3014 - val_accuracy: 0.9175\n",
      "Epoch 173/300\n",
      "387/387 [==============================] - 0s 114us/step - loss: 0.1588 - accuracy: 0.9612 - val_loss: 0.3006 - val_accuracy: 0.9175\n",
      "Epoch 174/300\n",
      "387/387 [==============================] - 0s 112us/step - loss: 0.1588 - accuracy: 0.9612 - val_loss: 0.3006 - val_accuracy: 0.9175\n",
      "Epoch 175/300\n",
      "387/387 [==============================] - 0s 107us/step - loss: 0.1585 - accuracy: 0.9612 - val_loss: 0.3020 - val_accuracy: 0.9175\n",
      "Epoch 176/300\n",
      "387/387 [==============================] - 0s 110us/step - loss: 0.1590 - accuracy: 0.9612 - val_loss: 0.3017 - val_accuracy: 0.9175\n",
      "Epoch 177/300\n",
      "387/387 [==============================] - 0s 114us/step - loss: 0.1592 - accuracy: 0.9612 - val_loss: 0.3021 - val_accuracy: 0.9175\n",
      "Epoch 178/300\n",
      "387/387 [==============================] - 0s 110us/step - loss: 0.1587 - accuracy: 0.9612 - val_loss: 0.3016 - val_accuracy: 0.9175\n",
      "Epoch 179/300\n",
      "387/387 [==============================] - 0s 112us/step - loss: 0.1591 - accuracy: 0.9612 - val_loss: 0.3019 - val_accuracy: 0.9175\n",
      "Epoch 180/300\n",
      "387/387 [==============================] - 0s 119us/step - loss: 0.1586 - accuracy: 0.9612 - val_loss: 0.3005 - val_accuracy: 0.9175\n",
      "Epoch 181/300\n",
      "387/387 [==============================] - 0s 111us/step - loss: 0.1587 - accuracy: 0.9612 - val_loss: 0.3005 - val_accuracy: 0.9175\n",
      "Epoch 182/300\n",
      "387/387 [==============================] - 0s 109us/step - loss: 0.1586 - accuracy: 0.9612 - val_loss: 0.3008 - val_accuracy: 0.9175\n",
      "Epoch 183/300\n",
      "387/387 [==============================] - 0s 116us/step - loss: 0.1585 - accuracy: 0.9612 - val_loss: 0.3004 - val_accuracy: 0.9175\n",
      "Epoch 184/300\n",
      "387/387 [==============================] - 0s 108us/step - loss: 0.1587 - accuracy: 0.9612 - val_loss: 0.3000 - val_accuracy: 0.9175\n",
      "Epoch 185/300\n",
      "387/387 [==============================] - 0s 112us/step - loss: 0.1584 - accuracy: 0.9612 - val_loss: 0.3005 - val_accuracy: 0.9175\n",
      "Epoch 186/300\n",
      "387/387 [==============================] - 0s 109us/step - loss: 0.1584 - accuracy: 0.9612 - val_loss: 0.3000 - val_accuracy: 0.9175\n",
      "Epoch 187/300\n",
      "387/387 [==============================] - 0s 111us/step - loss: 0.1588 - accuracy: 0.9612 - val_loss: 0.3010 - val_accuracy: 0.9175\n",
      "Epoch 188/300\n",
      "387/387 [==============================] - 0s 123us/step - loss: 0.1583 - accuracy: 0.9612 - val_loss: 0.3017 - val_accuracy: 0.9175\n",
      "Epoch 189/300\n",
      "387/387 [==============================] - 0s 125us/step - loss: 0.1585 - accuracy: 0.9612 - val_loss: 0.3017 - val_accuracy: 0.9175\n",
      "Epoch 190/300\n",
      "387/387 [==============================] - 0s 125us/step - loss: 0.1586 - accuracy: 0.9612 - val_loss: 0.3016 - val_accuracy: 0.9175\n",
      "Epoch 191/300\n",
      "387/387 [==============================] - 0s 133us/step - loss: 0.1584 - accuracy: 0.9612 - val_loss: 0.3012 - val_accuracy: 0.9175\n",
      "Epoch 192/300\n",
      "387/387 [==============================] - 0s 133us/step - loss: 0.1584 - accuracy: 0.9612 - val_loss: 0.3005 - val_accuracy: 0.9175\n",
      "Epoch 193/300\n",
      "387/387 [==============================] - 0s 116us/step - loss: 0.1584 - accuracy: 0.9612 - val_loss: 0.3004 - val_accuracy: 0.9175\n",
      "Epoch 194/300\n",
      "387/387 [==============================] - 0s 125us/step - loss: 0.1582 - accuracy: 0.9612 - val_loss: 0.3005 - val_accuracy: 0.9175\n",
      "Epoch 195/300\n",
      "387/387 [==============================] - 0s 137us/step - loss: 0.1582 - accuracy: 0.9612 - val_loss: 0.3010 - val_accuracy: 0.9175\n",
      "Epoch 196/300\n",
      "387/387 [==============================] - 0s 119us/step - loss: 0.1583 - accuracy: 0.9612 - val_loss: 0.3011 - val_accuracy: 0.9175\n",
      "Epoch 197/300\n",
      "387/387 [==============================] - 0s 120us/step - loss: 0.1581 - accuracy: 0.9612 - val_loss: 0.3005 - val_accuracy: 0.9175\n",
      "Epoch 198/300\n",
      "387/387 [==============================] - 0s 129us/step - loss: 0.1580 - accuracy: 0.9612 - val_loss: 0.3011 - val_accuracy: 0.9175\n",
      "Epoch 199/300\n",
      "387/387 [==============================] - 0s 120us/step - loss: 0.1582 - accuracy: 0.9612 - val_loss: 0.3000 - val_accuracy: 0.9175\n",
      "Epoch 200/300\n",
      "387/387 [==============================] - 0s 130us/step - loss: 0.1584 - accuracy: 0.9612 - val_loss: 0.3010 - val_accuracy: 0.9175\n",
      "Epoch 201/300\n",
      "387/387 [==============================] - 0s 119us/step - loss: 0.1581 - accuracy: 0.9612 - val_loss: 0.3004 - val_accuracy: 0.9175\n",
      "Epoch 202/300\n",
      "387/387 [==============================] - 0s 121us/step - loss: 0.1580 - accuracy: 0.9612 - val_loss: 0.2995 - val_accuracy: 0.9175\n",
      "Epoch 203/300\n",
      "387/387 [==============================] - 0s 121us/step - loss: 0.1578 - accuracy: 0.9612 - val_loss: 0.2992 - val_accuracy: 0.9175\n",
      "Epoch 204/300\n",
      "387/387 [==============================] - 0s 119us/step - loss: 0.1579 - accuracy: 0.9612 - val_loss: 0.2989 - val_accuracy: 0.9175\n",
      "Epoch 205/300\n",
      "387/387 [==============================] - 0s 147us/step - loss: 0.1580 - accuracy: 0.9612 - val_loss: 0.3008 - val_accuracy: 0.9175\n",
      "Epoch 206/300\n",
      "387/387 [==============================] - 0s 114us/step - loss: 0.1581 - accuracy: 0.9612 - val_loss: 0.2994 - val_accuracy: 0.9175\n",
      "Epoch 207/300\n",
      "387/387 [==============================] - 0s 128us/step - loss: 0.1580 - accuracy: 0.9612 - val_loss: 0.2992 - val_accuracy: 0.9175\n",
      "Epoch 208/300\n",
      "387/387 [==============================] - 0s 117us/step - loss: 0.1577 - accuracy: 0.9612 - val_loss: 0.2998 - val_accuracy: 0.9175\n",
      "Epoch 209/300\n",
      "387/387 [==============================] - 0s 119us/step - loss: 0.1579 - accuracy: 0.9612 - val_loss: 0.2996 - val_accuracy: 0.9175\n",
      "Epoch 210/300\n",
      "387/387 [==============================] - 0s 118us/step - loss: 0.1577 - accuracy: 0.9612 - val_loss: 0.3005 - val_accuracy: 0.9175\n",
      "Epoch 211/300\n",
      "387/387 [==============================] - 0s 119us/step - loss: 0.1580 - accuracy: 0.9612 - val_loss: 0.3007 - val_accuracy: 0.9175\n",
      "Epoch 212/300\n",
      "387/387 [==============================] - 0s 118us/step - loss: 0.1579 - accuracy: 0.9612 - val_loss: 0.3005 - val_accuracy: 0.9175\n",
      "Epoch 213/300\n",
      "387/387 [==============================] - 0s 121us/step - loss: 0.1577 - accuracy: 0.9612 - val_loss: 0.2999 - val_accuracy: 0.9175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 214/300\n",
      "387/387 [==============================] - 0s 118us/step - loss: 0.1576 - accuracy: 0.9612 - val_loss: 0.2985 - val_accuracy: 0.9175\n",
      "Epoch 215/300\n",
      "387/387 [==============================] - 0s 119us/step - loss: 0.1574 - accuracy: 0.9612 - val_loss: 0.2986 - val_accuracy: 0.9175\n",
      "Epoch 216/300\n",
      "387/387 [==============================] - 0s 118us/step - loss: 0.1576 - accuracy: 0.9612 - val_loss: 0.2976 - val_accuracy: 0.9175\n",
      "Epoch 217/300\n",
      "387/387 [==============================] - 0s 116us/step - loss: 0.1573 - accuracy: 0.9612 - val_loss: 0.2984 - val_accuracy: 0.9175\n",
      "Epoch 218/300\n",
      "387/387 [==============================] - 0s 112us/step - loss: 0.1575 - accuracy: 0.9612 - val_loss: 0.2978 - val_accuracy: 0.9175\n",
      "Epoch 219/300\n",
      "387/387 [==============================] - 0s 114us/step - loss: 0.1573 - accuracy: 0.9612 - val_loss: 0.2980 - val_accuracy: 0.9175\n",
      "Epoch 220/300\n",
      "387/387 [==============================] - 0s 124us/step - loss: 0.1576 - accuracy: 0.9612 - val_loss: 0.2974 - val_accuracy: 0.9175\n",
      "Epoch 221/300\n",
      "387/387 [==============================] - 0s 124us/step - loss: 0.1573 - accuracy: 0.9612 - val_loss: 0.2969 - val_accuracy: 0.9175\n",
      "Epoch 222/300\n",
      "387/387 [==============================] - 0s 117us/step - loss: 0.1574 - accuracy: 0.9612 - val_loss: 0.2971 - val_accuracy: 0.9175\n",
      "Epoch 223/300\n",
      "387/387 [==============================] - 0s 120us/step - loss: 0.1574 - accuracy: 0.9612 - val_loss: 0.2973 - val_accuracy: 0.9175\n",
      "Epoch 224/300\n",
      "387/387 [==============================] - 0s 138us/step - loss: 0.1574 - accuracy: 0.9612 - val_loss: 0.2970 - val_accuracy: 0.9175\n",
      "Epoch 225/300\n",
      "387/387 [==============================] - 0s 134us/step - loss: 0.1573 - accuracy: 0.9612 - val_loss: 0.2962 - val_accuracy: 0.9175\n",
      "Epoch 226/300\n",
      "387/387 [==============================] - 0s 119us/step - loss: 0.1572 - accuracy: 0.9612 - val_loss: 0.2963 - val_accuracy: 0.9175\n",
      "Epoch 227/300\n",
      "387/387 [==============================] - 0s 128us/step - loss: 0.1572 - accuracy: 0.9612 - val_loss: 0.2970 - val_accuracy: 0.9175\n",
      "Epoch 228/300\n",
      "387/387 [==============================] - 0s 126us/step - loss: 0.1573 - accuracy: 0.9612 - val_loss: 0.2968 - val_accuracy: 0.9175\n",
      "Epoch 229/300\n",
      "387/387 [==============================] - 0s 115us/step - loss: 0.1574 - accuracy: 0.9612 - val_loss: 0.2978 - val_accuracy: 0.9175\n",
      "Epoch 230/300\n",
      "387/387 [==============================] - 0s 114us/step - loss: 0.1571 - accuracy: 0.9612 - val_loss: 0.2970 - val_accuracy: 0.9175\n",
      "Epoch 231/300\n",
      "387/387 [==============================] - 0s 113us/step - loss: 0.1571 - accuracy: 0.9612 - val_loss: 0.2972 - val_accuracy: 0.9175\n",
      "Epoch 232/300\n",
      "387/387 [==============================] - 0s 118us/step - loss: 0.1571 - accuracy: 0.9612 - val_loss: 0.2969 - val_accuracy: 0.9175\n",
      "Epoch 233/300\n",
      "387/387 [==============================] - 0s 125us/step - loss: 0.1570 - accuracy: 0.9612 - val_loss: 0.2975 - val_accuracy: 0.9175\n",
      "Epoch 234/300\n",
      "387/387 [==============================] - 0s 126us/step - loss: 0.1575 - accuracy: 0.9612 - val_loss: 0.2984 - val_accuracy: 0.9175\n",
      "Epoch 235/300\n",
      "387/387 [==============================] - 0s 122us/step - loss: 0.1570 - accuracy: 0.9612 - val_loss: 0.2978 - val_accuracy: 0.9175\n",
      "Epoch 236/300\n",
      "387/387 [==============================] - 0s 117us/step - loss: 0.1577 - accuracy: 0.9612 - val_loss: 0.2984 - val_accuracy: 0.9175\n",
      "Epoch 237/300\n",
      "387/387 [==============================] - 0s 116us/step - loss: 0.1571 - accuracy: 0.9612 - val_loss: 0.2980 - val_accuracy: 0.9175\n",
      "Epoch 238/300\n",
      "387/387 [==============================] - 0s 112us/step - loss: 0.1572 - accuracy: 0.9612 - val_loss: 0.2979 - val_accuracy: 0.9175\n",
      "Epoch 239/300\n",
      "387/387 [==============================] - 0s 121us/step - loss: 0.1570 - accuracy: 0.9612 - val_loss: 0.2975 - val_accuracy: 0.9175\n",
      "Epoch 240/300\n",
      "387/387 [==============================] - 0s 119us/step - loss: 0.1566 - accuracy: 0.9612 - val_loss: 0.2995 - val_accuracy: 0.9175\n",
      "Epoch 241/300\n",
      "387/387 [==============================] - 0s 133us/step - loss: 0.1573 - accuracy: 0.9612 - val_loss: 0.2995 - val_accuracy: 0.9175\n",
      "Epoch 242/300\n",
      "387/387 [==============================] - 0s 121us/step - loss: 0.1570 - accuracy: 0.9612 - val_loss: 0.2989 - val_accuracy: 0.9175\n",
      "Epoch 243/300\n",
      "387/387 [==============================] - 0s 135us/step - loss: 0.1570 - accuracy: 0.9612 - val_loss: 0.2972 - val_accuracy: 0.9175\n",
      "Epoch 244/300\n",
      "387/387 [==============================] - 0s 116us/step - loss: 0.1570 - accuracy: 0.9612 - val_loss: 0.2978 - val_accuracy: 0.9175\n",
      "Epoch 245/300\n",
      "387/387 [==============================] - 0s 128us/step - loss: 0.1569 - accuracy: 0.9612 - val_loss: 0.2973 - val_accuracy: 0.9175\n",
      "Epoch 246/300\n",
      "387/387 [==============================] - 0s 124us/step - loss: 0.1568 - accuracy: 0.9612 - val_loss: 0.2968 - val_accuracy: 0.9175\n",
      "Epoch 247/300\n",
      "387/387 [==============================] - 0s 134us/step - loss: 0.1567 - accuracy: 0.9612 - val_loss: 0.2960 - val_accuracy: 0.9175\n",
      "Epoch 248/300\n",
      "387/387 [==============================] - 0s 128us/step - loss: 0.1568 - accuracy: 0.9612 - val_loss: 0.2963 - val_accuracy: 0.9175\n",
      "Epoch 249/300\n",
      "387/387 [==============================] - 0s 126us/step - loss: 0.1566 - accuracy: 0.9612 - val_loss: 0.2961 - val_accuracy: 0.9175\n",
      "Epoch 250/300\n",
      "387/387 [==============================] - 0s 119us/step - loss: 0.1570 - accuracy: 0.9612 - val_loss: 0.2974 - val_accuracy: 0.9175\n",
      "Epoch 251/300\n",
      "387/387 [==============================] - 0s 121us/step - loss: 0.1566 - accuracy: 0.9612 - val_loss: 0.2980 - val_accuracy: 0.9175\n",
      "Epoch 252/300\n",
      "387/387 [==============================] - 0s 120us/step - loss: 0.1567 - accuracy: 0.9612 - val_loss: 0.2972 - val_accuracy: 0.9175\n",
      "Epoch 253/300\n",
      "387/387 [==============================] - 0s 121us/step - loss: 0.1565 - accuracy: 0.9612 - val_loss: 0.2975 - val_accuracy: 0.9175\n",
      "Epoch 254/300\n",
      "387/387 [==============================] - 0s 122us/step - loss: 0.1566 - accuracy: 0.9612 - val_loss: 0.2971 - val_accuracy: 0.9175\n",
      "Epoch 255/300\n",
      "387/387 [==============================] - 0s 121us/step - loss: 0.1569 - accuracy: 0.9612 - val_loss: 0.2972 - val_accuracy: 0.9175\n",
      "Epoch 256/300\n",
      "387/387 [==============================] - 0s 123us/step - loss: 0.1566 - accuracy: 0.9612 - val_loss: 0.2979 - val_accuracy: 0.9175\n",
      "Epoch 257/300\n",
      "387/387 [==============================] - 0s 130us/step - loss: 0.1564 - accuracy: 0.9612 - val_loss: 0.2983 - val_accuracy: 0.9175\n",
      "Epoch 258/300\n",
      "387/387 [==============================] - 0s 118us/step - loss: 0.1566 - accuracy: 0.9612 - val_loss: 0.2986 - val_accuracy: 0.9175\n",
      "Epoch 259/300\n",
      "387/387 [==============================] - 0s 112us/step - loss: 0.1566 - accuracy: 0.9612 - val_loss: 0.2985 - val_accuracy: 0.9175\n",
      "Epoch 260/300\n",
      "387/387 [==============================] - 0s 115us/step - loss: 0.1568 - accuracy: 0.9612 - val_loss: 0.2982 - val_accuracy: 0.9175\n",
      "Epoch 261/300\n",
      "387/387 [==============================] - 0s 121us/step - loss: 0.1565 - accuracy: 0.9612 - val_loss: 0.2979 - val_accuracy: 0.9175\n",
      "Epoch 262/300\n",
      "387/387 [==============================] - 0s 130us/step - loss: 0.1566 - accuracy: 0.9612 - val_loss: 0.2971 - val_accuracy: 0.9175\n",
      "Epoch 263/300\n",
      "387/387 [==============================] - 0s 122us/step - loss: 0.1565 - accuracy: 0.9612 - val_loss: 0.2965 - val_accuracy: 0.9175\n",
      "Epoch 264/300\n",
      "387/387 [==============================] - 0s 136us/step - loss: 0.1564 - accuracy: 0.9612 - val_loss: 0.2965 - val_accuracy: 0.9175\n",
      "Epoch 265/300\n",
      "387/387 [==============================] - 0s 115us/step - loss: 0.1565 - accuracy: 0.9612 - val_loss: 0.2969 - val_accuracy: 0.9175\n",
      "Epoch 266/300\n",
      "387/387 [==============================] - 0s 127us/step - loss: 0.1564 - accuracy: 0.9612 - val_loss: 0.2971 - val_accuracy: 0.9175\n",
      "Epoch 267/300\n",
      "387/387 [==============================] - 0s 127us/step - loss: 0.1565 - accuracy: 0.9612 - val_loss: 0.2972 - val_accuracy: 0.9175\n",
      "Epoch 268/300\n",
      "387/387 [==============================] - 0s 128us/step - loss: 0.1564 - accuracy: 0.9612 - val_loss: 0.2969 - val_accuracy: 0.9175\n",
      "Epoch 269/300\n",
      "387/387 [==============================] - 0s 129us/step - loss: 0.1565 - accuracy: 0.9612 - val_loss: 0.2966 - val_accuracy: 0.9175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 270/300\n",
      "387/387 [==============================] - 0s 125us/step - loss: 0.1563 - accuracy: 0.9612 - val_loss: 0.2960 - val_accuracy: 0.9175\n",
      "Epoch 271/300\n",
      "387/387 [==============================] - 0s 121us/step - loss: 0.1563 - accuracy: 0.9612 - val_loss: 0.2954 - val_accuracy: 0.9175\n",
      "Epoch 272/300\n",
      "387/387 [==============================] - 0s 125us/step - loss: 0.1561 - accuracy: 0.9612 - val_loss: 0.2957 - val_accuracy: 0.9175\n",
      "Epoch 273/300\n",
      "387/387 [==============================] - 0s 118us/step - loss: 0.1558 - accuracy: 0.9612 - val_loss: 0.2972 - val_accuracy: 0.9175\n",
      "Epoch 274/300\n",
      "387/387 [==============================] - 0s 119us/step - loss: 0.1562 - accuracy: 0.9612 - val_loss: 0.2972 - val_accuracy: 0.9175\n",
      "Epoch 275/300\n",
      "387/387 [==============================] - 0s 116us/step - loss: 0.1561 - accuracy: 0.9612 - val_loss: 0.2971 - val_accuracy: 0.9175\n",
      "Epoch 276/300\n",
      "387/387 [==============================] - 0s 124us/step - loss: 0.1565 - accuracy: 0.9612 - val_loss: 0.2981 - val_accuracy: 0.9175\n",
      "Epoch 277/300\n",
      "387/387 [==============================] - 0s 120us/step - loss: 0.1563 - accuracy: 0.9612 - val_loss: 0.2966 - val_accuracy: 0.9175\n",
      "Epoch 278/300\n",
      "387/387 [==============================] - 0s 119us/step - loss: 0.1561 - accuracy: 0.9612 - val_loss: 0.2966 - val_accuracy: 0.9175\n",
      "Epoch 279/300\n",
      "387/387 [==============================] - 0s 118us/step - loss: 0.1564 - accuracy: 0.9612 - val_loss: 0.2966 - val_accuracy: 0.9175\n",
      "Epoch 280/300\n",
      "387/387 [==============================] - 0s 127us/step - loss: 0.1561 - accuracy: 0.9612 - val_loss: 0.2969 - val_accuracy: 0.9175\n",
      "Epoch 281/300\n",
      "387/387 [==============================] - 0s 126us/step - loss: 0.1566 - accuracy: 0.9612 - val_loss: 0.2981 - val_accuracy: 0.9175\n",
      "Epoch 282/300\n",
      "387/387 [==============================] - 0s 139us/step - loss: 0.1563 - accuracy: 0.9612 - val_loss: 0.2984 - val_accuracy: 0.9175\n",
      "Epoch 283/300\n",
      "387/387 [==============================] - 0s 121us/step - loss: 0.1560 - accuracy: 0.9612 - val_loss: 0.2990 - val_accuracy: 0.9175\n",
      "Epoch 284/300\n",
      "387/387 [==============================] - 0s 118us/step - loss: 0.1564 - accuracy: 0.9612 - val_loss: 0.2991 - val_accuracy: 0.9175\n",
      "Epoch 285/300\n",
      "387/387 [==============================] - 0s 119us/step - loss: 0.1563 - accuracy: 0.9612 - val_loss: 0.2976 - val_accuracy: 0.9175\n",
      "Epoch 286/300\n",
      "387/387 [==============================] - 0s 121us/step - loss: 0.1561 - accuracy: 0.9612 - val_loss: 0.2967 - val_accuracy: 0.9175\n",
      "Epoch 287/300\n",
      "387/387 [==============================] - 0s 126us/step - loss: 0.1560 - accuracy: 0.9612 - val_loss: 0.2964 - val_accuracy: 0.9175\n",
      "Epoch 288/300\n",
      "387/387 [==============================] - 0s 114us/step - loss: 0.1562 - accuracy: 0.9612 - val_loss: 0.2963 - val_accuracy: 0.9175\n",
      "Epoch 289/300\n",
      "387/387 [==============================] - 0s 120us/step - loss: 0.1560 - accuracy: 0.9612 - val_loss: 0.2961 - val_accuracy: 0.9175\n",
      "Epoch 290/300\n",
      "387/387 [==============================] - 0s 121us/step - loss: 0.1561 - accuracy: 0.9612 - val_loss: 0.2964 - val_accuracy: 0.9175\n",
      "Epoch 291/300\n",
      "387/387 [==============================] - 0s 134us/step - loss: 0.1561 - accuracy: 0.9612 - val_loss: 0.2962 - val_accuracy: 0.9175\n",
      "Epoch 292/300\n",
      "387/387 [==============================] - 0s 118us/step - loss: 0.1558 - accuracy: 0.9612 - val_loss: 0.2963 - val_accuracy: 0.9175\n",
      "Epoch 293/300\n",
      "387/387 [==============================] - 0s 115us/step - loss: 0.1560 - accuracy: 0.9612 - val_loss: 0.2961 - val_accuracy: 0.9175\n",
      "Epoch 294/300\n",
      "387/387 [==============================] - 0s 118us/step - loss: 0.1560 - accuracy: 0.9612 - val_loss: 0.2959 - val_accuracy: 0.9175\n",
      "Epoch 295/300\n",
      "387/387 [==============================] - 0s 123us/step - loss: 0.1568 - accuracy: 0.9612 - val_loss: 0.2986 - val_accuracy: 0.9175\n",
      "Epoch 296/300\n",
      "387/387 [==============================] - 0s 132us/step - loss: 0.1561 - accuracy: 0.9612 - val_loss: 0.2975 - val_accuracy: 0.9175\n",
      "Epoch 297/300\n",
      "387/387 [==============================] - 0s 123us/step - loss: 0.1558 - accuracy: 0.9612 - val_loss: 0.2979 - val_accuracy: 0.9175\n",
      "Epoch 298/300\n",
      "387/387 [==============================] - 0s 120us/step - loss: 0.1560 - accuracy: 0.9612 - val_loss: 0.2968 - val_accuracy: 0.9175\n",
      "Epoch 299/300\n",
      "387/387 [==============================] - 0s 114us/step - loss: 0.1559 - accuracy: 0.9612 - val_loss: 0.2965 - val_accuracy: 0.9175\n",
      "Epoch 300/300\n",
      "387/387 [==============================] - 0s 133us/step - loss: 0.1558 - accuracy: 0.9612 - val_loss: 0.2968 - val_accuracy: 0.9175\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "X = df.iloc[:,-10:-1]\n",
    "Y = df.iloc[:,-1]\n",
    "print(X)\n",
    "print(Y)\n",
    "\n",
    "\n",
    "def create_model_null():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(18,input_dim = 9, activation = 'sigmoid'))\n",
    "    model.add(Dense(1,activation = 'sigmoid'))\n",
    "    return model\n",
    "\n",
    "\n",
    "'''\n",
    "Model just with backpropagation\n",
    "'''\n",
    "def BP(X,Y):\n",
    "    n = create_model_null()\n",
    "    n.compile(optimizer = 'rmsprop', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    history = n.fit(X, Y, validation_split=0.2, epochs=300, batch_size=10, verbose=1, shuffle = True)\n",
    "    # Plot training & validation accuracy values\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('Model accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    # Plot training & validation loss values\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper left')\n",
    "    plt.show()\n",
    "    \n",
    "BP(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.952054794520548\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=1) \n",
    "# 70% training and 30% test\n",
    "clf = DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
