{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('COVID19_open_line_list.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>country</th>\n",
       "      <th>wuhan(0)_not_wuhan(1)</th>\n",
       "      <th>date_onset_symptoms</th>\n",
       "      <th>date_admission_hospital</th>\n",
       "      <th>date_confirmation</th>\n",
       "      <th>symptoms</th>\n",
       "      <th>lives_in_Wuhan</th>\n",
       "      <th>travel_history_dates</th>\n",
       "      <th>travel_history_location</th>\n",
       "      <th>reported_market_exposure</th>\n",
       "      <th>chronic_disease_binary</th>\n",
       "      <th>chronic_disease</th>\n",
       "      <th>date_death_or_discharge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>11545</td>\n",
       "      <td>70-79</td>\n",
       "      <td>male</td>\n",
       "      <td>Japan</td>\n",
       "      <td>1</td>\n",
       "      <td>19.02.2020</td>\n",
       "      <td>20.02.2020</td>\n",
       "      <td>21.02.2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>1771</td>\n",
       "      <td>60-69</td>\n",
       "      <td>male</td>\n",
       "      <td>Japan</td>\n",
       "      <td>1</td>\n",
       "      <td>14.01.2020</td>\n",
       "      <td>25.01.2020</td>\n",
       "      <td>28.01.2020</td>\n",
       "      <td>chills, cough, joint pain</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>2594</td>\n",
       "      <td>60-69</td>\n",
       "      <td>male</td>\n",
       "      <td>Australia</td>\n",
       "      <td>1</td>\n",
       "      <td>23.01.2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.01.2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wuhan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>3021</td>\n",
       "      <td>60-69</td>\n",
       "      <td>male</td>\n",
       "      <td>United States</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.01.2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>11547</td>\n",
       "      <td>60-69</td>\n",
       "      <td>male</td>\n",
       "      <td>Japan</td>\n",
       "      <td>1</td>\n",
       "      <td>06.02.2020</td>\n",
       "      <td>21.02.2020</td>\n",
       "      <td>21.02.2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1575</th>\n",
       "      <td>5108</td>\n",
       "      <td>5</td>\n",
       "      <td>female</td>\n",
       "      <td>China</td>\n",
       "      <td>1</td>\n",
       "      <td>22.01.2020</td>\n",
       "      <td>27.01.2020</td>\n",
       "      <td>02.02.2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1577</th>\n",
       "      <td>9191</td>\n",
       "      <td>4</td>\n",
       "      <td>female</td>\n",
       "      <td>China</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08.02.2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>25.01.2020 -</td>\n",
       "      <td>Wuhan City</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1579</th>\n",
       "      <td>2362</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>China</td>\n",
       "      <td>1</td>\n",
       "      <td>27.01.2020</td>\n",
       "      <td>27.01.2020</td>\n",
       "      <td>29.01.2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>21.01.2020</td>\n",
       "      <td>Wuhan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1580</th>\n",
       "      <td>163</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>China</td>\n",
       "      <td>1</td>\n",
       "      <td>22.01.2020</td>\n",
       "      <td>23.01.2020</td>\n",
       "      <td>24.01.2020</td>\n",
       "      <td>fever, sneeze</td>\n",
       "      <td>yes</td>\n",
       "      <td>21.01.2020</td>\n",
       "      <td>Wuhan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1589</th>\n",
       "      <td>10921</td>\n",
       "      <td>0.25</td>\n",
       "      <td>female</td>\n",
       "      <td>Vietnam</td>\n",
       "      <td>1</td>\n",
       "      <td>06.02.2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.02.2020</td>\n",
       "      <td>cough, runny nose</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.02.2020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>484 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID    age     sex        country wuhan(0)_not_wuhan(1)  \\\n",
       "258   11545  70-79    male          Japan                     1   \n",
       "276    1771  60-69    male          Japan                     1   \n",
       "277    2594  60-69    male      Australia                     1   \n",
       "278    3021  60-69    male  United States                     1   \n",
       "287   11547  60-69    male          Japan                     1   \n",
       "...     ...    ...     ...            ...                   ...   \n",
       "1575   5108      5  female          China                     1   \n",
       "1577   9191      4  female          China                     1   \n",
       "1579   2362      3  female          China                     1   \n",
       "1580    163      2  female          China                     1   \n",
       "1589  10921   0.25  female        Vietnam                     1   \n",
       "\n",
       "     date_onset_symptoms date_admission_hospital date_confirmation  \\\n",
       "258           19.02.2020              20.02.2020        21.02.2020   \n",
       "276           14.01.2020              25.01.2020        28.01.2020   \n",
       "277           23.01.2020                     NaN        29.01.2020   \n",
       "278                  NaN                     NaN        30.01.2020   \n",
       "287           06.02.2020              21.02.2020        21.02.2020   \n",
       "...                  ...                     ...               ...   \n",
       "1575          22.01.2020              27.01.2020        02.02.2020   \n",
       "1577                 NaN                     NaN        08.02.2020   \n",
       "1579          27.01.2020              27.01.2020        29.01.2020   \n",
       "1580          22.01.2020              23.01.2020        24.01.2020   \n",
       "1589          06.02.2020                     NaN        11.02.2020   \n",
       "\n",
       "                       symptoms lives_in_Wuhan travel_history_dates  \\\n",
       "258                         NaN             no                  NaN   \n",
       "276   chills, cough, joint pain             no                  NaN   \n",
       "277                         NaN             no                  NaN   \n",
       "278                         NaN             no                  NaN   \n",
       "287                         NaN             no                  NaN   \n",
       "...                         ...            ...                  ...   \n",
       "1575                        NaN             no                  NaN   \n",
       "1577                        NaN             no         25.01.2020 -   \n",
       "1579                        NaN             no           21.01.2020   \n",
       "1580              fever, sneeze            yes           21.01.2020   \n",
       "1589          cough, runny nose             no                  NaN   \n",
       "\n",
       "     travel_history_location reported_market_exposure chronic_disease_binary  \\\n",
       "258                      NaN                      NaN                    NaN   \n",
       "276                      NaN                       no                    NaN   \n",
       "277                    Wuhan                      NaN                    NaN   \n",
       "278                      NaN                      NaN                    NaN   \n",
       "287                      NaN                      NaN                    NaN   \n",
       "...                      ...                      ...                    ...   \n",
       "1575                     NaN                      NaN                    NaN   \n",
       "1577              Wuhan City                      NaN                    NaN   \n",
       "1579                   Wuhan                      NaN                    NaN   \n",
       "1580                   Wuhan                      NaN                    NaN   \n",
       "1589                     NaN                      NaN                    NaN   \n",
       "\n",
       "     chronic_disease date_death_or_discharge  \n",
       "258              NaN                     NaN  \n",
       "276              NaN                     NaN  \n",
       "277              NaN                     NaN  \n",
       "278              NaN                     NaN  \n",
       "287              NaN                     NaN  \n",
       "...              ...                     ...  \n",
       "1575             NaN                     NaN  \n",
       "1577             NaN                     NaN  \n",
       "1579             NaN                     NaN  \n",
       "1580             NaN                     NaN  \n",
       "1589             NaN              20.02.2020  \n",
       "\n",
       "[484 rows x 16 columns]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[pd.notnull(df['age'])]\n",
    "df = df[pd.notnull(df['sex'])]\n",
    "df = df[pd.notnull(df['country'])]\n",
    "df = df[pd.notnull(df['lives_in_Wuhan'])]\n",
    "df.drop(columns = ['city','province','latitude','longitude','geo_resolution','additional_information','source','sequence_available','outcome','notes_for_discussion','location','admin3','admin2','admin1','country_new','admin_id','data_moderator_initials'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pneumonitis', 'runny nose', 'muscular soreness', 'rigor', 'physical discomfort', 'vomiting', 'myalgias', 'myalgia', 'soreness', 'lesions on chest radiographs', 'lack of energy', 'pleural effusion', 'coughing', 'diarrhea', 'feeling ill', 'sneeze', 'other symptoms', 'pleuritic chest pain', 'chest tightness', 'pharyngeal discomfort', 'muscle ache', 'fatigue', 'weak', 'sore throat', 'muscle soreness', 'severe dyspnea', 'pharynx', 'headache', 'respiratory symptoms', 'expectoration', 'nasal congestion', 'sneezing', 'nausea', 'cough', 'muscular stiffness', 'chest distress', 'chest pain', 'rhinorrhoea', 'pharyngalgia', 'sore limbs', 'shortness of breath', 'sore muscle', 'dizziness', 'eye irritation', 'pneumonia', 'discomfort', 'fever', 'dyspnea', 'anhelation', 'eventually showed acute left heart failure and acute coronary syndrome', 'muscle aches', 'joint pain', 'flu-like symptoms', 'muscle pain', 'weakness', 'conjunctivitis', 'asymptomatic', 'dry cough', 'diarrhoea', 'sputum', 'chills', 'sweating'}\n"
     ]
    }
   ],
   "source": [
    "test = df.iloc[:,13]\n",
    "symptom_set = set()\n",
    "for row in list(test):\n",
    "    row = str(row)\n",
    "    l = row.split(\",\")\n",
    "    for symp in l:\n",
    "        symp = symp.strip()\n",
    "        if symp == \"nan\":\n",
    "            continue\n",
    "        elif symp not in symptom_set:\n",
    "            if \"fever\" in symp or \"Fever\" in symp:\n",
    "                symptom_set.add(\"fever\")\n",
    "            else:\n",
    "                symptom_set.add(symp)\n",
    "        else:\n",
    "            continue\n",
    "print(symptom_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Japan': 0, 'Australia': 1, 'United States': 2, 'Canada': 3, 'Sweden': 4, 'Germany': 5, 'Finland': 6, 'China': 7, 'Singapore': 8, 'Thailand': 9, 'Vietnam': 10, 'South Korea': 11, 'Spain': 12, 'Cambodia': 13, 'North Macedonia': 14, 'Georgia': 15, 'France': 16, 'Philippines': 17, 'Malaysia': 18, 'Greece': 19, 'Afghanistan': 20, 'Estonia': 21, 'Nepal': 22, 'Italy': 23, 'Croatia': 24, 'Pakistan': 25, 'Romania': 26}\n"
     ]
    }
   ],
   "source": [
    "test = df.iloc[:,5]\n",
    "country_dict = dict()\n",
    "count = 0\n",
    "for row in list(test):\n",
    "    row = str(row)\n",
    "    if row in country_dict:\n",
    "        continue\n",
    "    else:\n",
    "        country_dict[row] = count\n",
    "        count+= 1\n",
    "print(country_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanedData = []\n",
    "count = 0\n",
    "Count = 0\n",
    "for index,row in df.iterrows():\n",
    "    cur = []\n",
    "    Count += 1\n",
    "    # Clean the age column\n",
    "    if str(row[\"age\"]).isnumeric():\n",
    "        #cur.append(int(row[\"age\"]) // 10)\n",
    "        cur += [0] * (int(row[\"age\"]) // 10) + [1] + (9 - (int(row[\"age\"]) // 10)) * [0]\n",
    "    else:\n",
    "        if \"-\" in row[\"age\"]:\n",
    "            loc = row[\"age\"].index(\"-\")\n",
    "            #cur.append(int(row[\"age\"][:loc]) // 10)\n",
    "            cur += [0] * (int(row[\"age\"][:loc]) // 10) + [1] + (9 - (int(row[\"age\"][:loc]) // 10)) * [0]\n",
    "        else:\n",
    "            #cur.append(int(float(row[\"age\"]) // 10))\n",
    "            cur += [0] * ((int(float(row[\"age\"]))) // 10) + [1] + (9 - ((int(float(row[\"age\"]))) // 10)) * [0]\n",
    "            \n",
    "    \n",
    "    # Clean the sex column\n",
    "    if row[\"sex\"] == \"male\":\n",
    "        cur += [1,0]\n",
    "    else:\n",
    "        cur += [0,1]\n",
    "    # Clean the country\n",
    "    #cur.append(country_dict[str(row[\"country\"])])\n",
    "    cur += [0]*(country_dict[str(row[\"country\"])]) + [1] + (26 -country_dict[str(row[\"country\"])]) * [0]\n",
    "    \n",
    "    # Clean the Wuhan column, check whether they are citizens in Wuhan, 1 means not Wuhan\n",
    "    cur.append(row[\"wuhan(0)_not_wuhan(1)\"])\n",
    "    # Clean the sympton date\n",
    "    \n",
    "    # Clean the sympton\n",
    "    temp = str(row[\"symptoms\"]).lower()\n",
    "    # fever, cough, pneumonitis, fatigue\n",
    "    # Fever- related\n",
    "    if \"fever\" in temp or \"headache\" in temp:\n",
    "        cur.append(1)\n",
    "    else:\n",
    "        cur.append(0)\n",
    "    # Cough related\n",
    "    if \"cou\" in temp or \"throa\" in temp or \"dry\" in temp or \"pharyngeal\" in temp or \"expectoration\" in temp or \"flu\" in temp:\n",
    "        cur.append(1)\n",
    "    else:\n",
    "        cur.append(0)\n",
    "    # Cold related\n",
    "    if \"chill\" in temp or \"nose\" in temp or \"nasal\" in temp or \"sneez\" in temp:\n",
    "        cur.append(1)\n",
    "    else:\n",
    "        cur.append(0)\n",
    "    # pneumonitis related\n",
    "    if \"pneumon\" in temp or \"respiratory\" in temp or \"breath\" in temp:\n",
    "        cur.append(1)\n",
    "    else:\n",
    "        cur.append(0)\n",
    "    # Muscle or fatigue, physical issue related\n",
    "    if \"fatigue\" in temp or \"myalgias\" in temp or \"musc\" in temp or \"walk\" in temp or \"chest\" in temp or \"limbs\" in temp or \"joint\" in temp or \"physical\" in temp or \"energy\" in temp:\n",
    "        cur.append(1)\n",
    "    else:\n",
    "        cur.append(0)\n",
    "    # Stomacha related\n",
    "    if \"diarrhoea\" in temp or \"abdominal\" in temp:\n",
    "        cur.append(1)\n",
    "    else:\n",
    "        cur.append(0)\n",
    "    # Other symptom or non-symptom\n",
    "    if len(temp) > 0 and temp != \"nan\":\n",
    "        cur.append(1)\n",
    "    else:\n",
    "        cur.append(0)\n",
    "    \n",
    "    # Clean the column whether live in Wuhan or have travel relations with Wuhan\n",
    "    if str(row[\"lives_in_Wuhan\"]).lower() == \"nan\" or str(row[\"lives_in_Wuhan\"]).lower() == \"no\" or \"wuhan\" not in str(row[\"travel_history_location\"]).lower():\n",
    "        cur.append(0)\n",
    "    else:\n",
    "        cur.append(1)\n",
    "        \n",
    "    # Clean the target value: date_death_or_discharge\n",
    "    if str(row[\"date_death_or_discharge\"]).lower() == \"nan\":\n",
    "        count += 1\n",
    "        cur.append(0)\n",
    "    else:\n",
    "        cur.append(1)\n",
    "    cleanedData.append(cur)\n",
    "    \n",
    "#print(count,Count)\n",
    "#print(cleanedData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "f = open(\"CleanedConfirmedCase.csv\", \"a\")\n",
    "fieldnames = ['0s','10s','20s','30s','40s','50s','60s','70s','80s','90s','Male','Female','Japan', 'Australia', 'United States', 'Canada', 'Sweden', 'Germany', 'Finland', 'China', 'Singapore', 'Thailand', 'Vietnam', 'South Korea', 'Spain', 'Cambodia', 'North Macedonia', 'Georgia', 'France', 'Philippines', 'Malaysia', 'Greece', 'Afghanistan', 'Estonia', 'Nepal', 'Italy', 'Croatia', 'Pakistan', 'Romania','Wuhan?','Fever','Cough','Cold','Pneumonitis','Fatigue','Stomacha','Other Symptoms','Relation with Wuhan','Death or Not']\n",
    "writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "writer.writeheader()\n",
    "writer = csv.writer(f)\n",
    "writer.writerows(cleanedData)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"CleanedConfirmedCase.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0s</th>\n",
       "      <th>10s</th>\n",
       "      <th>20s</th>\n",
       "      <th>30s</th>\n",
       "      <th>40s</th>\n",
       "      <th>50s</th>\n",
       "      <th>60s</th>\n",
       "      <th>70s</th>\n",
       "      <th>80s</th>\n",
       "      <th>90s</th>\n",
       "      <th>...</th>\n",
       "      <th>Wuhan?</th>\n",
       "      <th>Fever</th>\n",
       "      <th>Cough</th>\n",
       "      <th>Cold</th>\n",
       "      <th>Pneumonitis</th>\n",
       "      <th>Fatigue</th>\n",
       "      <th>Stomacha</th>\n",
       "      <th>Other Symptoms</th>\n",
       "      <th>Relation with Wuhan</th>\n",
       "      <th>Death or Not</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>484 rows Ã— 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0s  10s  20s  30s  40s  50s  60s  70s  80s  90s  ...  Wuhan?  Fever  \\\n",
       "0     0    0    0    0    0    0    0    1    0    0  ...       1      0   \n",
       "1     0    0    0    0    0    0    1    0    0    0  ...       1      0   \n",
       "2     0    0    0    0    0    0    1    0    0    0  ...       1      0   \n",
       "3     0    0    0    0    0    0    1    0    0    0  ...       1      0   \n",
       "4     0    0    0    0    0    0    1    0    0    0  ...       1      0   \n",
       "..   ..  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...     ...    ...   \n",
       "479   1    0    0    0    0    0    0    0    0    0  ...       1      0   \n",
       "480   1    0    0    0    0    0    0    0    0    0  ...       1      0   \n",
       "481   1    0    0    0    0    0    0    0    0    0  ...       1      0   \n",
       "482   1    0    0    0    0    0    0    0    0    0  ...       1      1   \n",
       "483   1    0    0    0    0    0    0    0    0    0  ...       1      0   \n",
       "\n",
       "     Cough  Cold  Pneumonitis  Fatigue  Stomacha  Other Symptoms  \\\n",
       "0        0     0            0        0         0               0   \n",
       "1        1     1            0        1         0               1   \n",
       "2        0     0            0        0         0               0   \n",
       "3        0     0            0        0         0               0   \n",
       "4        0     0            0        0         0               0   \n",
       "..     ...   ...          ...      ...       ...             ...   \n",
       "479      0     0            0        0         0               0   \n",
       "480      0     0            0        0         0               0   \n",
       "481      0     0            0        0         0               0   \n",
       "482      0     1            0        0         0               1   \n",
       "483      1     1            0        0         0               1   \n",
       "\n",
       "     Relation with Wuhan  Death or Not  \n",
       "0                      0             0  \n",
       "1                      0             0  \n",
       "2                      0             0  \n",
       "3                      0             0  \n",
       "4                      0             0  \n",
       "..                   ...           ...  \n",
       "479                    0             0  \n",
       "480                    0             0  \n",
       "481                    0             0  \n",
       "482                    1             0  \n",
       "483                    0             1  \n",
       "\n",
       "[484 rows x 49 columns]"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0s  10s  20s  30s  40s  50s  60s  70s  80s  90s  ...  Romania  Wuhan?  \\\n",
      "0     0    0    0    0    0    0    0    1    0    0  ...        0       1   \n",
      "1     0    0    0    0    0    0    1    0    0    0  ...        0       1   \n",
      "2     0    0    0    0    0    0    1    0    0    0  ...        0       1   \n",
      "3     0    0    0    0    0    0    1    0    0    0  ...        0       1   \n",
      "4     0    0    0    0    0    0    1    0    0    0  ...        0       1   \n",
      "..   ..  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...      ...     ...   \n",
      "479   1    0    0    0    0    0    0    0    0    0  ...        0       1   \n",
      "480   1    0    0    0    0    0    0    0    0    0  ...        0       1   \n",
      "481   1    0    0    0    0    0    0    0    0    0  ...        0       1   \n",
      "482   1    0    0    0    0    0    0    0    0    0  ...        0       1   \n",
      "483   1    0    0    0    0    0    0    0    0    0  ...        0       1   \n",
      "\n",
      "     Fever  Cough  Cold  Pneumonitis  Fatigue  Stomacha  Other Symptoms  \\\n",
      "0        0      0     0            0        0         0               0   \n",
      "1        0      1     1            0        1         0               1   \n",
      "2        0      0     0            0        0         0               0   \n",
      "3        0      0     0            0        0         0               0   \n",
      "4        0      0     0            0        0         0               0   \n",
      "..     ...    ...   ...          ...      ...       ...             ...   \n",
      "479      0      0     0            0        0         0               0   \n",
      "480      0      0     0            0        0         0               0   \n",
      "481      0      0     0            0        0         0               0   \n",
      "482      1      0     1            0        0         0               1   \n",
      "483      0      1     1            0        0         0               1   \n",
      "\n",
      "     Relation with Wuhan  \n",
      "0                      0  \n",
      "1                      0  \n",
      "2                      0  \n",
      "3                      0  \n",
      "4                      0  \n",
      "..                   ...  \n",
      "479                    0  \n",
      "480                    0  \n",
      "481                    0  \n",
      "482                    1  \n",
      "483                    0  \n",
      "\n",
      "[484 rows x 48 columns]\n",
      "0      0\n",
      "1      0\n",
      "2      0\n",
      "3      0\n",
      "4      0\n",
      "      ..\n",
      "479    0\n",
      "480    0\n",
      "481    0\n",
      "482    0\n",
      "483    1\n",
      "Name: Death or Not, Length: 484, dtype: int64\n",
      "Train on 338 samples, validate on 146 samples\n",
      "Epoch 1/2000\n",
      "338/338 [==============================] - 0s 428us/step - loss: 0.1582 - accuracy: 0.9645 - val_loss: 0.2818 - val_accuracy: 0.9247\n",
      "Epoch 2/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.1513 - accuracy: 0.9645 - val_loss: 0.2863 - val_accuracy: 0.9247\n",
      "Epoch 3/2000\n",
      "338/338 [==============================] - 0s 82us/step - loss: 0.1498 - accuracy: 0.9645 - val_loss: 0.2882 - val_accuracy: 0.9247\n",
      "Epoch 4/2000\n",
      "338/338 [==============================] - 0s 82us/step - loss: 0.1484 - accuracy: 0.9645 - val_loss: 0.2912 - val_accuracy: 0.9247\n",
      "Epoch 5/2000\n",
      "338/338 [==============================] - 0s 98us/step - loss: 0.1478 - accuracy: 0.9645 - val_loss: 0.2911 - val_accuracy: 0.9247\n",
      "Epoch 6/2000\n",
      "338/338 [==============================] - 0s 86us/step - loss: 0.1454 - accuracy: 0.9645 - val_loss: 0.2906 - val_accuracy: 0.9247\n",
      "Epoch 7/2000\n",
      "338/338 [==============================] - 0s 77us/step - loss: 0.1439 - accuracy: 0.9645 - val_loss: 0.2889 - val_accuracy: 0.9247\n",
      "Epoch 8/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.1434 - accuracy: 0.9645 - val_loss: 0.2922 - val_accuracy: 0.9247\n",
      "Epoch 9/2000\n",
      "338/338 [==============================] - 0s 89us/step - loss: 0.1420 - accuracy: 0.9645 - val_loss: 0.2919 - val_accuracy: 0.9247\n",
      "Epoch 10/2000\n",
      "338/338 [==============================] - 0s 80us/step - loss: 0.1405 - accuracy: 0.9645 - val_loss: 0.2946 - val_accuracy: 0.9247\n",
      "Epoch 11/2000\n",
      "338/338 [==============================] - 0s 81us/step - loss: 0.1390 - accuracy: 0.9645 - val_loss: 0.2891 - val_accuracy: 0.9247\n",
      "Epoch 12/2000\n",
      "338/338 [==============================] - 0s 75us/step - loss: 0.1376 - accuracy: 0.9645 - val_loss: 0.2945 - val_accuracy: 0.9247\n",
      "Epoch 13/2000\n",
      "338/338 [==============================] - 0s 81us/step - loss: 0.1375 - accuracy: 0.9645 - val_loss: 0.2933 - val_accuracy: 0.9247\n",
      "Epoch 14/2000\n",
      "338/338 [==============================] - 0s 83us/step - loss: 0.1355 - accuracy: 0.9645 - val_loss: 0.2943 - val_accuracy: 0.9247\n",
      "Epoch 15/2000\n",
      "338/338 [==============================] - 0s 81us/step - loss: 0.1345 - accuracy: 0.9645 - val_loss: 0.2922 - val_accuracy: 0.9247\n",
      "Epoch 16/2000\n",
      "338/338 [==============================] - 0s 86us/step - loss: 0.1325 - accuracy: 0.9645 - val_loss: 0.3015 - val_accuracy: 0.9247\n",
      "Epoch 17/2000\n",
      "338/338 [==============================] - 0s 83us/step - loss: 0.1325 - accuracy: 0.9645 - val_loss: 0.3029 - val_accuracy: 0.9247\n",
      "Epoch 18/2000\n",
      "338/338 [==============================] - 0s 85us/step - loss: 0.1318 - accuracy: 0.9645 - val_loss: 0.2960 - val_accuracy: 0.9247\n",
      "Epoch 19/2000\n",
      "338/338 [==============================] - 0s 79us/step - loss: 0.1302 - accuracy: 0.9645 - val_loss: 0.2973 - val_accuracy: 0.9247\n",
      "Epoch 20/2000\n",
      "338/338 [==============================] - 0s 85us/step - loss: 0.1273 - accuracy: 0.9645 - val_loss: 0.2874 - val_accuracy: 0.9247\n",
      "Epoch 21/2000\n",
      "338/338 [==============================] - 0s 93us/step - loss: 0.1281 - accuracy: 0.9645 - val_loss: 0.2961 - val_accuracy: 0.9247\n",
      "Epoch 22/2000\n",
      "338/338 [==============================] - 0s 81us/step - loss: 0.1283 - accuracy: 0.9645 - val_loss: 0.3031 - val_accuracy: 0.9247\n",
      "Epoch 23/2000\n",
      "338/338 [==============================] - 0s 76us/step - loss: 0.1256 - accuracy: 0.9645 - val_loss: 0.3004 - val_accuracy: 0.9247\n",
      "Epoch 24/2000\n",
      "338/338 [==============================] - 0s 76us/step - loss: 0.1255 - accuracy: 0.9645 - val_loss: 0.3050 - val_accuracy: 0.9247\n",
      "Epoch 25/2000\n",
      "338/338 [==============================] - 0s 74us/step - loss: 0.1235 - accuracy: 0.9645 - val_loss: 0.3011 - val_accuracy: 0.9247\n",
      "Epoch 26/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.1261 - accuracy: 0.9645 - val_loss: 0.3062 - val_accuracy: 0.9247\n",
      "Epoch 27/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.1211 - accuracy: 0.9645 - val_loss: 0.3063 - val_accuracy: 0.9247\n",
      "Epoch 28/2000\n",
      "338/338 [==============================] - 0s 74us/step - loss: 0.1205 - accuracy: 0.9645 - val_loss: 0.3011 - val_accuracy: 0.9247\n",
      "Epoch 29/2000\n",
      "338/338 [==============================] - 0s 82us/step - loss: 0.1202 - accuracy: 0.9645 - val_loss: 0.3023 - val_accuracy: 0.9247\n",
      "Epoch 30/2000\n",
      "338/338 [==============================] - 0s 81us/step - loss: 0.1193 - accuracy: 0.9645 - val_loss: 0.3093 - val_accuracy: 0.9247\n",
      "Epoch 31/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.1179 - accuracy: 0.9645 - val_loss: 0.3062 - val_accuracy: 0.9247\n",
      "Epoch 32/2000\n",
      "338/338 [==============================] - 0s 76us/step - loss: 0.1171 - accuracy: 0.9645 - val_loss: 0.3069 - val_accuracy: 0.9247\n",
      "Epoch 33/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.1155 - accuracy: 0.9645 - val_loss: 0.3170 - val_accuracy: 0.9247\n",
      "Epoch 34/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.1158 - accuracy: 0.9645 - val_loss: 0.3165 - val_accuracy: 0.9247\n",
      "Epoch 35/2000\n",
      "338/338 [==============================] - 0s 75us/step - loss: 0.1147 - accuracy: 0.9645 - val_loss: 0.3135 - val_accuracy: 0.9247\n",
      "Epoch 36/2000\n",
      "338/338 [==============================] - 0s 74us/step - loss: 0.1140 - accuracy: 0.9645 - val_loss: 0.3114 - val_accuracy: 0.9247\n",
      "Epoch 37/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.1137 - accuracy: 0.9645 - val_loss: 0.3178 - val_accuracy: 0.9247\n",
      "Epoch 38/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.1115 - accuracy: 0.9645 - val_loss: 0.3218 - val_accuracy: 0.9247\n",
      "Epoch 39/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.1111 - accuracy: 0.9645 - val_loss: 0.3153 - val_accuracy: 0.9247\n",
      "Epoch 40/2000\n",
      "338/338 [==============================] - 0s 75us/step - loss: 0.1102 - accuracy: 0.9645 - val_loss: 0.3102 - val_accuracy: 0.9247\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.1093 - accuracy: 0.9645 - val_loss: 0.3132 - val_accuracy: 0.9247\n",
      "Epoch 42/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.1080 - accuracy: 0.9645 - val_loss: 0.3164 - val_accuracy: 0.9247\n",
      "Epoch 43/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.1075 - accuracy: 0.9645 - val_loss: 0.3175 - val_accuracy: 0.9247\n",
      "Epoch 44/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.1059 - accuracy: 0.9645 - val_loss: 0.3268 - val_accuracy: 0.9247\n",
      "Epoch 45/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.1063 - accuracy: 0.9645 - val_loss: 0.3283 - val_accuracy: 0.9247\n",
      "Epoch 46/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.1051 - accuracy: 0.9645 - val_loss: 0.3250 - val_accuracy: 0.9247\n",
      "Epoch 47/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.1048 - accuracy: 0.9645 - val_loss: 0.3248 - val_accuracy: 0.9247\n",
      "Epoch 48/2000\n",
      "338/338 [==============================] - 0s 75us/step - loss: 0.1024 - accuracy: 0.9645 - val_loss: 0.3349 - val_accuracy: 0.9247\n",
      "Epoch 49/2000\n",
      "338/338 [==============================] - 0s 81us/step - loss: 0.1026 - accuracy: 0.9645 - val_loss: 0.3284 - val_accuracy: 0.9247\n",
      "Epoch 50/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.1016 - accuracy: 0.9645 - val_loss: 0.3188 - val_accuracy: 0.9315\n",
      "Epoch 51/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.1010 - accuracy: 0.9675 - val_loss: 0.3236 - val_accuracy: 0.9315\n",
      "Epoch 52/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.1006 - accuracy: 0.9645 - val_loss: 0.3263 - val_accuracy: 0.9315\n",
      "Epoch 53/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0988 - accuracy: 0.9645 - val_loss: 0.3217 - val_accuracy: 0.9315\n",
      "Epoch 54/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0980 - accuracy: 0.9704 - val_loss: 0.3380 - val_accuracy: 0.9315\n",
      "Epoch 55/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0985 - accuracy: 0.9645 - val_loss: 0.3346 - val_accuracy: 0.9315\n",
      "Epoch 56/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0972 - accuracy: 0.9675 - val_loss: 0.3296 - val_accuracy: 0.9315\n",
      "Epoch 57/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0962 - accuracy: 0.9675 - val_loss: 0.3363 - val_accuracy: 0.9315\n",
      "Epoch 58/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0959 - accuracy: 0.9734 - val_loss: 0.3409 - val_accuracy: 0.9315\n",
      "Epoch 59/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0953 - accuracy: 0.9675 - val_loss: 0.3407 - val_accuracy: 0.9315\n",
      "Epoch 60/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0943 - accuracy: 0.9675 - val_loss: 0.3346 - val_accuracy: 0.9315\n",
      "Epoch 61/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0932 - accuracy: 0.9704 - val_loss: 0.3308 - val_accuracy: 0.9315\n",
      "Epoch 62/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0933 - accuracy: 0.9734 - val_loss: 0.3416 - val_accuracy: 0.9315\n",
      "Epoch 63/2000\n",
      "338/338 [==============================] - 0s 74us/step - loss: 0.0923 - accuracy: 0.9734 - val_loss: 0.3451 - val_accuracy: 0.9315\n",
      "Epoch 64/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0930 - accuracy: 0.9704 - val_loss: 0.3462 - val_accuracy: 0.9315\n",
      "Epoch 65/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0914 - accuracy: 0.9734 - val_loss: 0.3458 - val_accuracy: 0.9315\n",
      "Epoch 66/2000\n",
      "338/338 [==============================] - 0s 76us/step - loss: 0.0906 - accuracy: 0.9734 - val_loss: 0.3551 - val_accuracy: 0.9315\n",
      "Epoch 67/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0903 - accuracy: 0.9734 - val_loss: 0.3559 - val_accuracy: 0.9315\n",
      "Epoch 68/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0901 - accuracy: 0.9734 - val_loss: 0.3544 - val_accuracy: 0.9315\n",
      "Epoch 69/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0903 - accuracy: 0.9734 - val_loss: 0.3571 - val_accuracy: 0.9315\n",
      "Epoch 70/2000\n",
      "338/338 [==============================] - 0s 74us/step - loss: 0.0883 - accuracy: 0.9734 - val_loss: 0.3641 - val_accuracy: 0.9315\n",
      "Epoch 71/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0885 - accuracy: 0.9763 - val_loss: 0.3634 - val_accuracy: 0.9315\n",
      "Epoch 72/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0879 - accuracy: 0.9734 - val_loss: 0.3704 - val_accuracy: 0.9315\n",
      "Epoch 73/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0876 - accuracy: 0.9734 - val_loss: 0.3623 - val_accuracy: 0.9315\n",
      "Epoch 74/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0870 - accuracy: 0.9793 - val_loss: 0.3692 - val_accuracy: 0.9315\n",
      "Epoch 75/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0870 - accuracy: 0.9793 - val_loss: 0.3747 - val_accuracy: 0.9315\n",
      "Epoch 76/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0864 - accuracy: 0.9793 - val_loss: 0.3731 - val_accuracy: 0.9315\n",
      "Epoch 77/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0854 - accuracy: 0.9793 - val_loss: 0.3702 - val_accuracy: 0.9315\n",
      "Epoch 78/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0854 - accuracy: 0.9793 - val_loss: 0.3701 - val_accuracy: 0.9315\n",
      "Epoch 79/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0851 - accuracy: 0.9793 - val_loss: 0.3713 - val_accuracy: 0.9315\n",
      "Epoch 80/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0846 - accuracy: 0.9793 - val_loss: 0.3798 - val_accuracy: 0.9315\n",
      "Epoch 81/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0843 - accuracy: 0.9793 - val_loss: 0.3819 - val_accuracy: 0.9315\n",
      "Epoch 82/2000\n",
      "338/338 [==============================] - 0s 75us/step - loss: 0.0837 - accuracy: 0.9793 - val_loss: 0.3907 - val_accuracy: 0.9315\n",
      "Epoch 83/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0836 - accuracy: 0.9793 - val_loss: 0.3866 - val_accuracy: 0.9315\n",
      "Epoch 84/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0832 - accuracy: 0.9793 - val_loss: 0.3889 - val_accuracy: 0.9315\n",
      "Epoch 85/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0834 - accuracy: 0.9793 - val_loss: 0.3881 - val_accuracy: 0.9315\n",
      "Epoch 86/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0823 - accuracy: 0.9793 - val_loss: 0.3910 - val_accuracy: 0.9315\n",
      "Epoch 87/2000\n",
      "338/338 [==============================] - 0s 74us/step - loss: 0.0821 - accuracy: 0.9793 - val_loss: 0.3897 - val_accuracy: 0.9315\n",
      "Epoch 88/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0816 - accuracy: 0.9793 - val_loss: 0.3986 - val_accuracy: 0.9315\n",
      "Epoch 89/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0825 - accuracy: 0.9793 - val_loss: 0.4009 - val_accuracy: 0.9315\n",
      "Epoch 90/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0808 - accuracy: 0.9793 - val_loss: 0.3949 - val_accuracy: 0.9315\n",
      "Epoch 91/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0805 - accuracy: 0.9793 - val_loss: 0.4124 - val_accuracy: 0.9315\n",
      "Epoch 92/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0806 - accuracy: 0.9793 - val_loss: 0.4163 - val_accuracy: 0.9315\n",
      "Epoch 93/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0809 - accuracy: 0.9793 - val_loss: 0.4132 - val_accuracy: 0.9315\n",
      "Epoch 94/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0802 - accuracy: 0.9793 - val_loss: 0.4145 - val_accuracy: 0.9315\n",
      "Epoch 95/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0805 - accuracy: 0.9793 - val_loss: 0.4113 - val_accuracy: 0.9315\n",
      "Epoch 96/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0793 - accuracy: 0.9793 - val_loss: 0.4116 - val_accuracy: 0.9315\n",
      "Epoch 97/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "338/338 [==============================] - 0s 68us/step - loss: 0.0801 - accuracy: 0.9793 - val_loss: 0.4124 - val_accuracy: 0.9315\n",
      "Epoch 98/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0793 - accuracy: 0.9793 - val_loss: 0.4146 - val_accuracy: 0.9315\n",
      "Epoch 99/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0787 - accuracy: 0.9793 - val_loss: 0.4168 - val_accuracy: 0.9315\n",
      "Epoch 100/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0787 - accuracy: 0.9793 - val_loss: 0.4246 - val_accuracy: 0.9315\n",
      "Epoch 101/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0788 - accuracy: 0.9793 - val_loss: 0.4255 - val_accuracy: 0.9315\n",
      "Epoch 102/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0787 - accuracy: 0.9793 - val_loss: 0.4244 - val_accuracy: 0.9315\n",
      "Epoch 103/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0772 - accuracy: 0.9793 - val_loss: 0.4381 - val_accuracy: 0.9315\n",
      "Epoch 104/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0789 - accuracy: 0.9793 - val_loss: 0.4301 - val_accuracy: 0.9315\n",
      "Epoch 105/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0776 - accuracy: 0.9793 - val_loss: 0.4373 - val_accuracy: 0.9315\n",
      "Epoch 106/2000\n",
      "338/338 [==============================] - 0s 65us/step - loss: 0.0779 - accuracy: 0.9793 - val_loss: 0.4371 - val_accuracy: 0.9315\n",
      "Epoch 107/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0775 - accuracy: 0.9793 - val_loss: 0.4392 - val_accuracy: 0.9315\n",
      "Epoch 108/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0782 - accuracy: 0.9793 - val_loss: 0.4419 - val_accuracy: 0.9315\n",
      "Epoch 109/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0765 - accuracy: 0.9793 - val_loss: 0.4496 - val_accuracy: 0.9315\n",
      "Epoch 110/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0782 - accuracy: 0.9793 - val_loss: 0.4502 - val_accuracy: 0.9315\n",
      "Epoch 111/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0770 - accuracy: 0.9793 - val_loss: 0.4470 - val_accuracy: 0.9315\n",
      "Epoch 112/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0774 - accuracy: 0.9793 - val_loss: 0.4470 - val_accuracy: 0.9315\n",
      "Epoch 113/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0764 - accuracy: 0.9793 - val_loss: 0.4539 - val_accuracy: 0.9315\n",
      "Epoch 114/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0758 - accuracy: 0.9793 - val_loss: 0.4610 - val_accuracy: 0.9315\n",
      "Epoch 115/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0764 - accuracy: 0.9793 - val_loss: 0.4521 - val_accuracy: 0.9315\n",
      "Epoch 116/2000\n",
      "338/338 [==============================] - 0s 62us/step - loss: 0.0756 - accuracy: 0.9793 - val_loss: 0.4577 - val_accuracy: 0.9315\n",
      "Epoch 117/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0760 - accuracy: 0.9793 - val_loss: 0.4553 - val_accuracy: 0.9315\n",
      "Epoch 118/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0763 - accuracy: 0.9793 - val_loss: 0.4630 - val_accuracy: 0.9315\n",
      "Epoch 119/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0760 - accuracy: 0.9793 - val_loss: 0.4591 - val_accuracy: 0.9315\n",
      "Epoch 120/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0757 - accuracy: 0.9793 - val_loss: 0.4617 - val_accuracy: 0.9315\n",
      "Epoch 121/2000\n",
      "338/338 [==============================] - 0s 74us/step - loss: 0.0754 - accuracy: 0.9793 - val_loss: 0.4536 - val_accuracy: 0.9315\n",
      "Epoch 122/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0752 - accuracy: 0.9793 - val_loss: 0.4649 - val_accuracy: 0.9315\n",
      "Epoch 123/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0759 - accuracy: 0.9793 - val_loss: 0.4662 - val_accuracy: 0.9315\n",
      "Epoch 124/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0748 - accuracy: 0.9793 - val_loss: 0.4684 - val_accuracy: 0.9315\n",
      "Epoch 125/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0755 - accuracy: 0.9793 - val_loss: 0.4625 - val_accuracy: 0.9315\n",
      "Epoch 126/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0742 - accuracy: 0.9793 - val_loss: 0.4585 - val_accuracy: 0.9315\n",
      "Epoch 127/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0746 - accuracy: 0.9793 - val_loss: 0.4573 - val_accuracy: 0.9315\n",
      "Epoch 128/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0738 - accuracy: 0.9822 - val_loss: 0.4713 - val_accuracy: 0.9315\n",
      "Epoch 129/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0742 - accuracy: 0.9793 - val_loss: 0.4754 - val_accuracy: 0.9315\n",
      "Epoch 130/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0748 - accuracy: 0.9822 - val_loss: 0.4772 - val_accuracy: 0.9315\n",
      "Epoch 131/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0745 - accuracy: 0.9793 - val_loss: 0.4779 - val_accuracy: 0.9315\n",
      "Epoch 132/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0737 - accuracy: 0.9793 - val_loss: 0.4675 - val_accuracy: 0.9315\n",
      "Epoch 133/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0740 - accuracy: 0.9822 - val_loss: 0.4720 - val_accuracy: 0.9315\n",
      "Epoch 134/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0743 - accuracy: 0.9822 - val_loss: 0.4771 - val_accuracy: 0.9315\n",
      "Epoch 135/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0744 - accuracy: 0.9822 - val_loss: 0.4802 - val_accuracy: 0.9315\n",
      "Epoch 136/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0734 - accuracy: 0.9822 - val_loss: 0.4838 - val_accuracy: 0.9315\n",
      "Epoch 137/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0743 - accuracy: 0.9793 - val_loss: 0.4798 - val_accuracy: 0.9315\n",
      "Epoch 138/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0733 - accuracy: 0.9822 - val_loss: 0.4823 - val_accuracy: 0.9315\n",
      "Epoch 139/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0739 - accuracy: 0.9822 - val_loss: 0.4848 - val_accuracy: 0.9315\n",
      "Epoch 140/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0732 - accuracy: 0.9822 - val_loss: 0.4847 - val_accuracy: 0.9315\n",
      "Epoch 141/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0730 - accuracy: 0.9822 - val_loss: 0.4936 - val_accuracy: 0.9315\n",
      "Epoch 142/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0729 - accuracy: 0.9822 - val_loss: 0.4962 - val_accuracy: 0.9315\n",
      "Epoch 143/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0740 - accuracy: 0.9822 - val_loss: 0.4883 - val_accuracy: 0.9315\n",
      "Epoch 144/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0732 - accuracy: 0.9822 - val_loss: 0.4884 - val_accuracy: 0.9315\n",
      "Epoch 145/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0729 - accuracy: 0.9822 - val_loss: 0.4919 - val_accuracy: 0.9315\n",
      "Epoch 146/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0737 - accuracy: 0.9822 - val_loss: 0.4927 - val_accuracy: 0.9315\n",
      "Epoch 147/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0726 - accuracy: 0.9822 - val_loss: 0.4945 - val_accuracy: 0.9315\n",
      "Epoch 148/2000\n",
      "338/338 [==============================] - 0s 65us/step - loss: 0.0726 - accuracy: 0.9822 - val_loss: 0.4908 - val_accuracy: 0.9315\n",
      "Epoch 149/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0731 - accuracy: 0.9822 - val_loss: 0.4933 - val_accuracy: 0.9315\n",
      "Epoch 150/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0728 - accuracy: 0.9822 - val_loss: 0.4938 - val_accuracy: 0.9315\n",
      "Epoch 151/2000\n",
      "338/338 [==============================] - 0s 65us/step - loss: 0.0728 - accuracy: 0.9822 - val_loss: 0.4928 - val_accuracy: 0.9315\n",
      "Epoch 152/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0724 - accuracy: 0.9822 - val_loss: 0.4976 - val_accuracy: 0.9315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 153/2000\n",
      "338/338 [==============================] - 0s 64us/step - loss: 0.0727 - accuracy: 0.9822 - val_loss: 0.4956 - val_accuracy: 0.9315\n",
      "Epoch 154/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0720 - accuracy: 0.9822 - val_loss: 0.4928 - val_accuracy: 0.9384\n",
      "Epoch 155/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0731 - accuracy: 0.9822 - val_loss: 0.4965 - val_accuracy: 0.9384\n",
      "Epoch 156/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0727 - accuracy: 0.9822 - val_loss: 0.4953 - val_accuracy: 0.9384\n",
      "Epoch 157/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0722 - accuracy: 0.9822 - val_loss: 0.5035 - val_accuracy: 0.9315\n",
      "Epoch 158/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0724 - accuracy: 0.9822 - val_loss: 0.4996 - val_accuracy: 0.9384\n",
      "Epoch 159/2000\n",
      "338/338 [==============================] - 0s 65us/step - loss: 0.0718 - accuracy: 0.9822 - val_loss: 0.4975 - val_accuracy: 0.9384\n",
      "Epoch 160/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0720 - accuracy: 0.9822 - val_loss: 0.5011 - val_accuracy: 0.9384\n",
      "Epoch 161/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0726 - accuracy: 0.9822 - val_loss: 0.5089 - val_accuracy: 0.9384\n",
      "Epoch 162/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0721 - accuracy: 0.9822 - val_loss: 0.5032 - val_accuracy: 0.9384\n",
      "Epoch 163/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0719 - accuracy: 0.9822 - val_loss: 0.4990 - val_accuracy: 0.9452\n",
      "Epoch 164/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0725 - accuracy: 0.9822 - val_loss: 0.5056 - val_accuracy: 0.9384\n",
      "Epoch 165/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0720 - accuracy: 0.9822 - val_loss: 0.5074 - val_accuracy: 0.9452\n",
      "Epoch 166/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0715 - accuracy: 0.9822 - val_loss: 0.5151 - val_accuracy: 0.9384\n",
      "Epoch 167/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0722 - accuracy: 0.9822 - val_loss: 0.5087 - val_accuracy: 0.9452\n",
      "Epoch 168/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0714 - accuracy: 0.9822 - val_loss: 0.5078 - val_accuracy: 0.9452\n",
      "Epoch 169/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0718 - accuracy: 0.9822 - val_loss: 0.5058 - val_accuracy: 0.9452\n",
      "Epoch 170/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0717 - accuracy: 0.9822 - val_loss: 0.5096 - val_accuracy: 0.9452\n",
      "Epoch 171/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0715 - accuracy: 0.9822 - val_loss: 0.5127 - val_accuracy: 0.9452\n",
      "Epoch 172/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0715 - accuracy: 0.9822 - val_loss: 0.5128 - val_accuracy: 0.9452\n",
      "Epoch 173/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0724 - accuracy: 0.9822 - val_loss: 0.5135 - val_accuracy: 0.9452\n",
      "Epoch 174/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0711 - accuracy: 0.9822 - val_loss: 0.5070 - val_accuracy: 0.9452\n",
      "Epoch 175/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0714 - accuracy: 0.9822 - val_loss: 0.5145 - val_accuracy: 0.9452\n",
      "Epoch 176/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0711 - accuracy: 0.9822 - val_loss: 0.5164 - val_accuracy: 0.9452\n",
      "Epoch 177/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0717 - accuracy: 0.9822 - val_loss: 0.5111 - val_accuracy: 0.9452\n",
      "Epoch 178/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0711 - accuracy: 0.9822 - val_loss: 0.5115 - val_accuracy: 0.9452\n",
      "Epoch 179/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0719 - accuracy: 0.9822 - val_loss: 0.5136 - val_accuracy: 0.9452\n",
      "Epoch 180/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0713 - accuracy: 0.9822 - val_loss: 0.5118 - val_accuracy: 0.9452\n",
      "Epoch 181/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0717 - accuracy: 0.9822 - val_loss: 0.5172 - val_accuracy: 0.9452\n",
      "Epoch 182/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0718 - accuracy: 0.9822 - val_loss: 0.5182 - val_accuracy: 0.9452\n",
      "Epoch 183/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0707 - accuracy: 0.9822 - val_loss: 0.5217 - val_accuracy: 0.9452\n",
      "Epoch 184/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0705 - accuracy: 0.9822 - val_loss: 0.5080 - val_accuracy: 0.9452\n",
      "Epoch 185/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0708 - accuracy: 0.9822 - val_loss: 0.5202 - val_accuracy: 0.9452\n",
      "Epoch 186/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0713 - accuracy: 0.9822 - val_loss: 0.5189 - val_accuracy: 0.9452\n",
      "Epoch 187/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0712 - accuracy: 0.9822 - val_loss: 0.5173 - val_accuracy: 0.9452\n",
      "Epoch 188/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0708 - accuracy: 0.9822 - val_loss: 0.5250 - val_accuracy: 0.9452\n",
      "Epoch 189/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0713 - accuracy: 0.9822 - val_loss: 0.5269 - val_accuracy: 0.9452\n",
      "Epoch 190/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0712 - accuracy: 0.9822 - val_loss: 0.5210 - val_accuracy: 0.9452\n",
      "Epoch 191/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0707 - accuracy: 0.9822 - val_loss: 0.5131 - val_accuracy: 0.9452\n",
      "Epoch 192/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0696 - accuracy: 0.9822 - val_loss: 0.5274 - val_accuracy: 0.9452\n",
      "Epoch 193/2000\n",
      "338/338 [==============================] - 0s 76us/step - loss: 0.0710 - accuracy: 0.9822 - val_loss: 0.5257 - val_accuracy: 0.9452\n",
      "Epoch 194/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0708 - accuracy: 0.9822 - val_loss: 0.5257 - val_accuracy: 0.9452\n",
      "Epoch 195/2000\n",
      "338/338 [==============================] - 0s 78us/step - loss: 0.0710 - accuracy: 0.9822 - val_loss: 0.5275 - val_accuracy: 0.9452\n",
      "Epoch 196/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0708 - accuracy: 0.9822 - val_loss: 0.5337 - val_accuracy: 0.9452\n",
      "Epoch 197/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0712 - accuracy: 0.9822 - val_loss: 0.5290 - val_accuracy: 0.9452\n",
      "Epoch 198/2000\n",
      "338/338 [==============================] - 0s 81us/step - loss: 0.0710 - accuracy: 0.9822 - val_loss: 0.5220 - val_accuracy: 0.9452\n",
      "Epoch 199/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0709 - accuracy: 0.9822 - val_loss: 0.5247 - val_accuracy: 0.9452\n",
      "Epoch 200/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0715 - accuracy: 0.9822 - val_loss: 0.5253 - val_accuracy: 0.9452\n",
      "Epoch 201/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0709 - accuracy: 0.9822 - val_loss: 0.5259 - val_accuracy: 0.9452\n",
      "Epoch 202/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0708 - accuracy: 0.9822 - val_loss: 0.5234 - val_accuracy: 0.9452\n",
      "Epoch 203/2000\n",
      "338/338 [==============================] - 0s 64us/step - loss: 0.0708 - accuracy: 0.9822 - val_loss: 0.5296 - val_accuracy: 0.9452\n",
      "Epoch 204/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0711 - accuracy: 0.9822 - val_loss: 0.5299 - val_accuracy: 0.9452\n",
      "Epoch 205/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0709 - accuracy: 0.9822 - val_loss: 0.5286 - val_accuracy: 0.9452\n",
      "Epoch 206/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0708 - accuracy: 0.9822 - val_loss: 0.5304 - val_accuracy: 0.9452\n",
      "Epoch 207/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0712 - accuracy: 0.9822 - val_loss: 0.5308 - val_accuracy: 0.9452\n",
      "Epoch 208/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0709 - accuracy: 0.9822 - val_loss: 0.5274 - val_accuracy: 0.9452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 209/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0708 - accuracy: 0.9822 - val_loss: 0.5259 - val_accuracy: 0.9452\n",
      "Epoch 210/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0705 - accuracy: 0.9822 - val_loss: 0.5288 - val_accuracy: 0.9452\n",
      "Epoch 211/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0707 - accuracy: 0.9822 - val_loss: 0.5289 - val_accuracy: 0.9452\n",
      "Epoch 212/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0706 - accuracy: 0.9822 - val_loss: 0.5280 - val_accuracy: 0.9452\n",
      "Epoch 213/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0704 - accuracy: 0.9822 - val_loss: 0.5286 - val_accuracy: 0.9452\n",
      "Epoch 214/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0719 - accuracy: 0.9822 - val_loss: 0.5323 - val_accuracy: 0.9452\n",
      "Epoch 215/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0710 - accuracy: 0.9822 - val_loss: 0.5355 - val_accuracy: 0.9452\n",
      "Epoch 216/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0711 - accuracy: 0.9822 - val_loss: 0.5346 - val_accuracy: 0.9452\n",
      "Epoch 217/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0713 - accuracy: 0.9822 - val_loss: 0.5331 - val_accuracy: 0.9452\n",
      "Epoch 218/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0707 - accuracy: 0.9822 - val_loss: 0.5304 - val_accuracy: 0.9452\n",
      "Epoch 219/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0702 - accuracy: 0.9822 - val_loss: 0.5317 - val_accuracy: 0.9452\n",
      "Epoch 220/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0703 - accuracy: 0.9822 - val_loss: 0.5273 - val_accuracy: 0.9452\n",
      "Epoch 221/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0697 - accuracy: 0.9822 - val_loss: 0.5386 - val_accuracy: 0.9452\n",
      "Epoch 222/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0703 - accuracy: 0.9822 - val_loss: 0.5408 - val_accuracy: 0.9452\n",
      "Epoch 223/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0715 - accuracy: 0.9822 - val_loss: 0.5367 - val_accuracy: 0.9452\n",
      "Epoch 224/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0700 - accuracy: 0.9822 - val_loss: 0.5366 - val_accuracy: 0.9452\n",
      "Epoch 225/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0705 - accuracy: 0.9822 - val_loss: 0.5338 - val_accuracy: 0.9452\n",
      "Epoch 226/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0709 - accuracy: 0.9822 - val_loss: 0.5384 - val_accuracy: 0.9452\n",
      "Epoch 227/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0701 - accuracy: 0.9822 - val_loss: 0.5390 - val_accuracy: 0.9452\n",
      "Epoch 228/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0707 - accuracy: 0.9822 - val_loss: 0.5361 - val_accuracy: 0.9452\n",
      "Epoch 229/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0704 - accuracy: 0.9822 - val_loss: 0.5322 - val_accuracy: 0.9452\n",
      "Epoch 230/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0701 - accuracy: 0.9822 - val_loss: 0.5330 - val_accuracy: 0.9452\n",
      "Epoch 231/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0710 - accuracy: 0.9822 - val_loss: 0.5338 - val_accuracy: 0.9452\n",
      "Epoch 232/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0703 - accuracy: 0.9822 - val_loss: 0.5335 - val_accuracy: 0.9452\n",
      "Epoch 233/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0700 - accuracy: 0.9822 - val_loss: 0.5406 - val_accuracy: 0.9452\n",
      "Epoch 234/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0703 - accuracy: 0.9822 - val_loss: 0.5386 - val_accuracy: 0.9452\n",
      "Epoch 235/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0699 - accuracy: 0.9822 - val_loss: 0.5381 - val_accuracy: 0.9452\n",
      "Epoch 236/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0710 - accuracy: 0.9822 - val_loss: 0.5393 - val_accuracy: 0.9452\n",
      "Epoch 237/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0703 - accuracy: 0.9822 - val_loss: 0.5405 - val_accuracy: 0.9452\n",
      "Epoch 238/2000\n",
      "338/338 [==============================] - 0s 76us/step - loss: 0.0696 - accuracy: 0.9822 - val_loss: 0.5455 - val_accuracy: 0.9452\n",
      "Epoch 239/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0716 - accuracy: 0.9822 - val_loss: 0.5441 - val_accuracy: 0.9452\n",
      "Epoch 240/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0703 - accuracy: 0.9822 - val_loss: 0.5425 - val_accuracy: 0.9452\n",
      "Epoch 241/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0699 - accuracy: 0.9822 - val_loss: 0.5383 - val_accuracy: 0.9452\n",
      "Epoch 242/2000\n",
      "338/338 [==============================] - 0s 77us/step - loss: 0.0699 - accuracy: 0.9822 - val_loss: 0.5390 - val_accuracy: 0.9452\n",
      "Epoch 243/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0714 - accuracy: 0.9822 - val_loss: 0.5414 - val_accuracy: 0.9452\n",
      "Epoch 244/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0699 - accuracy: 0.9822 - val_loss: 0.5375 - val_accuracy: 0.9452\n",
      "Epoch 245/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0694 - accuracy: 0.9822 - val_loss: 0.5448 - val_accuracy: 0.9452\n",
      "Epoch 246/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0710 - accuracy: 0.9822 - val_loss: 0.5419 - val_accuracy: 0.9452\n",
      "Epoch 247/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0703 - accuracy: 0.9822 - val_loss: 0.5417 - val_accuracy: 0.9452\n",
      "Epoch 248/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0703 - accuracy: 0.9822 - val_loss: 0.5388 - val_accuracy: 0.9452\n",
      "Epoch 249/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0702 - accuracy: 0.9822 - val_loss: 0.5415 - val_accuracy: 0.9452\n",
      "Epoch 250/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0700 - accuracy: 0.9822 - val_loss: 0.5417 - val_accuracy: 0.9452\n",
      "Epoch 251/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0698 - accuracy: 0.9822 - val_loss: 0.5424 - val_accuracy: 0.9452\n",
      "Epoch 252/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0706 - accuracy: 0.9822 - val_loss: 0.5420 - val_accuracy: 0.9452\n",
      "Epoch 253/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0697 - accuracy: 0.9822 - val_loss: 0.5425 - val_accuracy: 0.9452\n",
      "Epoch 254/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0699 - accuracy: 0.9822 - val_loss: 0.5374 - val_accuracy: 0.9452\n",
      "Epoch 255/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0692 - accuracy: 0.9822 - val_loss: 0.5457 - val_accuracy: 0.9452\n",
      "Epoch 256/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0700 - accuracy: 0.9822 - val_loss: 0.5413 - val_accuracy: 0.9452\n",
      "Epoch 257/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0696 - accuracy: 0.9822 - val_loss: 0.5478 - val_accuracy: 0.9452\n",
      "Epoch 258/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0706 - accuracy: 0.9822 - val_loss: 0.5466 - val_accuracy: 0.9452\n",
      "Epoch 259/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0700 - accuracy: 0.9822 - val_loss: 0.5432 - val_accuracy: 0.9452\n",
      "Epoch 260/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0703 - accuracy: 0.9822 - val_loss: 0.5455 - val_accuracy: 0.9452\n",
      "Epoch 261/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0694 - accuracy: 0.9822 - val_loss: 0.5437 - val_accuracy: 0.9452\n",
      "Epoch 262/2000\n",
      "338/338 [==============================] - 0s 76us/step - loss: 0.0698 - accuracy: 0.9822 - val_loss: 0.5438 - val_accuracy: 0.9452\n",
      "Epoch 263/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0708 - accuracy: 0.9822 - val_loss: 0.5451 - val_accuracy: 0.9452\n",
      "Epoch 264/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0700 - accuracy: 0.9822 - val_loss: 0.5456 - val_accuracy: 0.9452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 265/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0697 - accuracy: 0.9822 - val_loss: 0.5416 - val_accuracy: 0.9452\n",
      "Epoch 266/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0693 - accuracy: 0.9822 - val_loss: 0.5494 - val_accuracy: 0.9452\n",
      "Epoch 267/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0698 - accuracy: 0.9822 - val_loss: 0.5461 - val_accuracy: 0.9452\n",
      "Epoch 268/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0695 - accuracy: 0.9822 - val_loss: 0.5426 - val_accuracy: 0.9452\n",
      "Epoch 269/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0700 - accuracy: 0.9822 - val_loss: 0.5475 - val_accuracy: 0.9452\n",
      "Epoch 270/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0695 - accuracy: 0.9822 - val_loss: 0.5524 - val_accuracy: 0.9452\n",
      "Epoch 271/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0699 - accuracy: 0.9822 - val_loss: 0.5508 - val_accuracy: 0.9452\n",
      "Epoch 272/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0702 - accuracy: 0.9822 - val_loss: 0.5515 - val_accuracy: 0.9452\n",
      "Epoch 273/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0706 - accuracy: 0.9822 - val_loss: 0.5488 - val_accuracy: 0.9452\n",
      "Epoch 274/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0693 - accuracy: 0.9822 - val_loss: 0.5451 - val_accuracy: 0.9452\n",
      "Epoch 275/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0700 - accuracy: 0.9822 - val_loss: 0.5438 - val_accuracy: 0.9452\n",
      "Epoch 276/2000\n",
      "338/338 [==============================] - 0s 75us/step - loss: 0.0696 - accuracy: 0.9822 - val_loss: 0.5433 - val_accuracy: 0.9452\n",
      "Epoch 277/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0698 - accuracy: 0.9822 - val_loss: 0.5472 - val_accuracy: 0.9452\n",
      "Epoch 278/2000\n",
      "338/338 [==============================] - 0s 75us/step - loss: 0.0695 - accuracy: 0.9822 - val_loss: 0.5508 - val_accuracy: 0.9452\n",
      "Epoch 279/2000\n",
      "338/338 [==============================] - 0s 65us/step - loss: 0.0695 - accuracy: 0.9822 - val_loss: 0.5504 - val_accuracy: 0.9452\n",
      "Epoch 280/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0695 - accuracy: 0.9822 - val_loss: 0.5517 - val_accuracy: 0.9452\n",
      "Epoch 281/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0697 - accuracy: 0.9822 - val_loss: 0.5476 - val_accuracy: 0.9452\n",
      "Epoch 282/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0698 - accuracy: 0.9822 - val_loss: 0.5460 - val_accuracy: 0.9452\n",
      "Epoch 283/2000\n",
      "338/338 [==============================] - 0s 75us/step - loss: 0.0694 - accuracy: 0.9822 - val_loss: 0.5486 - val_accuracy: 0.9452\n",
      "Epoch 284/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0697 - accuracy: 0.9822 - val_loss: 0.5454 - val_accuracy: 0.9452\n",
      "Epoch 285/2000\n",
      "338/338 [==============================] - 0s 74us/step - loss: 0.0700 - accuracy: 0.9822 - val_loss: 0.5493 - val_accuracy: 0.9452\n",
      "Epoch 286/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0691 - accuracy: 0.9822 - val_loss: 0.5550 - val_accuracy: 0.9452\n",
      "Epoch 287/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0698 - accuracy: 0.9822 - val_loss: 0.5549 - val_accuracy: 0.9452\n",
      "Epoch 288/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0697 - accuracy: 0.9822 - val_loss: 0.5506 - val_accuracy: 0.9452\n",
      "Epoch 289/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0709 - accuracy: 0.9822 - val_loss: 0.5516 - val_accuracy: 0.9452\n",
      "Epoch 290/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0693 - accuracy: 0.9822 - val_loss: 0.5535 - val_accuracy: 0.9452\n",
      "Epoch 291/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0702 - accuracy: 0.9822 - val_loss: 0.5514 - val_accuracy: 0.9452\n",
      "Epoch 292/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0698 - accuracy: 0.9822 - val_loss: 0.5509 - val_accuracy: 0.9452\n",
      "Epoch 293/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0693 - accuracy: 0.9822 - val_loss: 0.5482 - val_accuracy: 0.9452\n",
      "Epoch 294/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0695 - accuracy: 0.9822 - val_loss: 0.5484 - val_accuracy: 0.9452\n",
      "Epoch 295/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0697 - accuracy: 0.9822 - val_loss: 0.5497 - val_accuracy: 0.9452\n",
      "Epoch 296/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0691 - accuracy: 0.9822 - val_loss: 0.5527 - val_accuracy: 0.9452\n",
      "Epoch 297/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0694 - accuracy: 0.9822 - val_loss: 0.5542 - val_accuracy: 0.9452\n",
      "Epoch 298/2000\n",
      "338/338 [==============================] - 0s 74us/step - loss: 0.0696 - accuracy: 0.9822 - val_loss: 0.5548 - val_accuracy: 0.9452\n",
      "Epoch 299/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0699 - accuracy: 0.9822 - val_loss: 0.5539 - val_accuracy: 0.9452\n",
      "Epoch 300/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0692 - accuracy: 0.9822 - val_loss: 0.5542 - val_accuracy: 0.9452\n",
      "Epoch 301/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0694 - accuracy: 0.9822 - val_loss: 0.5553 - val_accuracy: 0.9452\n",
      "Epoch 302/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0693 - accuracy: 0.9822 - val_loss: 0.5477 - val_accuracy: 0.9452\n",
      "Epoch 303/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0695 - accuracy: 0.9822 - val_loss: 0.5500 - val_accuracy: 0.9452\n",
      "Epoch 304/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0693 - accuracy: 0.9822 - val_loss: 0.5504 - val_accuracy: 0.9452\n",
      "Epoch 305/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0691 - accuracy: 0.9822 - val_loss: 0.5542 - val_accuracy: 0.9452\n",
      "Epoch 306/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0694 - accuracy: 0.9822 - val_loss: 0.5518 - val_accuracy: 0.9452\n",
      "Epoch 307/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0713 - accuracy: 0.9822 - val_loss: 0.5536 - val_accuracy: 0.9452\n",
      "Epoch 308/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0690 - accuracy: 0.9822 - val_loss: 0.5560 - val_accuracy: 0.9452\n",
      "Epoch 309/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0697 - accuracy: 0.9822 - val_loss: 0.5581 - val_accuracy: 0.9452\n",
      "Epoch 310/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0697 - accuracy: 0.9822 - val_loss: 0.5529 - val_accuracy: 0.9452\n",
      "Epoch 311/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0686 - accuracy: 0.9822 - val_loss: 0.5584 - val_accuracy: 0.9452\n",
      "Epoch 312/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0696 - accuracy: 0.9822 - val_loss: 0.5570 - val_accuracy: 0.9452\n",
      "Epoch 313/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0694 - accuracy: 0.9822 - val_loss: 0.5537 - val_accuracy: 0.9452\n",
      "Epoch 314/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0695 - accuracy: 0.9822 - val_loss: 0.5568 - val_accuracy: 0.9452\n",
      "Epoch 315/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0691 - accuracy: 0.9822 - val_loss: 0.5554 - val_accuracy: 0.9452\n",
      "Epoch 316/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0691 - accuracy: 0.9822 - val_loss: 0.5568 - val_accuracy: 0.9452\n",
      "Epoch 317/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0692 - accuracy: 0.9822 - val_loss: 0.5530 - val_accuracy: 0.9452\n",
      "Epoch 318/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0694 - accuracy: 0.9822 - val_loss: 0.5537 - val_accuracy: 0.9452\n",
      "Epoch 319/2000\n",
      "338/338 [==============================] - 0s 74us/step - loss: 0.0693 - accuracy: 0.9822 - val_loss: 0.5540 - val_accuracy: 0.9452\n",
      "Epoch 320/2000\n",
      "338/338 [==============================] - 0s 63us/step - loss: 0.0692 - accuracy: 0.9822 - val_loss: 0.5513 - val_accuracy: 0.9452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 321/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0700 - accuracy: 0.9822 - val_loss: 0.5536 - val_accuracy: 0.9452\n",
      "Epoch 322/2000\n",
      "338/338 [==============================] - 0s 75us/step - loss: 0.0695 - accuracy: 0.9822 - val_loss: 0.5527 - val_accuracy: 0.9452\n",
      "Epoch 323/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0691 - accuracy: 0.9822 - val_loss: 0.5516 - val_accuracy: 0.9452\n",
      "Epoch 324/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0691 - accuracy: 0.9822 - val_loss: 0.5552 - val_accuracy: 0.9452\n",
      "Epoch 325/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0688 - accuracy: 0.9822 - val_loss: 0.5583 - val_accuracy: 0.9452\n",
      "Epoch 326/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0700 - accuracy: 0.9822 - val_loss: 0.5555 - val_accuracy: 0.9452\n",
      "Epoch 327/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0691 - accuracy: 0.9822 - val_loss: 0.5555 - val_accuracy: 0.9452\n",
      "Epoch 328/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0697 - accuracy: 0.9822 - val_loss: 0.5545 - val_accuracy: 0.9452\n",
      "Epoch 329/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0687 - accuracy: 0.9822 - val_loss: 0.5570 - val_accuracy: 0.9452\n",
      "Epoch 330/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0687 - accuracy: 0.9822 - val_loss: 0.5582 - val_accuracy: 0.9452\n",
      "Epoch 331/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0693 - accuracy: 0.9822 - val_loss: 0.5562 - val_accuracy: 0.9452\n",
      "Epoch 332/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0693 - accuracy: 0.9822 - val_loss: 0.5583 - val_accuracy: 0.9452\n",
      "Epoch 333/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0693 - accuracy: 0.9822 - val_loss: 0.5540 - val_accuracy: 0.9452\n",
      "Epoch 334/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0692 - accuracy: 0.9822 - val_loss: 0.5517 - val_accuracy: 0.9384\n",
      "Epoch 335/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0692 - accuracy: 0.9822 - val_loss: 0.5523 - val_accuracy: 0.9452\n",
      "Epoch 336/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0693 - accuracy: 0.9822 - val_loss: 0.5537 - val_accuracy: 0.9452\n",
      "Epoch 337/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0687 - accuracy: 0.9822 - val_loss: 0.5506 - val_accuracy: 0.9384\n",
      "Epoch 338/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0701 - accuracy: 0.9822 - val_loss: 0.5517 - val_accuracy: 0.9384\n",
      "Epoch 339/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0691 - accuracy: 0.9822 - val_loss: 0.5532 - val_accuracy: 0.9384\n",
      "Epoch 340/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0692 - accuracy: 0.9822 - val_loss: 0.5535 - val_accuracy: 0.9384\n",
      "Epoch 341/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0687 - accuracy: 0.9822 - val_loss: 0.5584 - val_accuracy: 0.9452\n",
      "Epoch 342/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0686 - accuracy: 0.9822 - val_loss: 0.5607 - val_accuracy: 0.9452\n",
      "Epoch 343/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0696 - accuracy: 0.9822 - val_loss: 0.5563 - val_accuracy: 0.9452\n",
      "Epoch 344/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0689 - accuracy: 0.9822 - val_loss: 0.5521 - val_accuracy: 0.9384\n",
      "Epoch 345/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0692 - accuracy: 0.9822 - val_loss: 0.5546 - val_accuracy: 0.9384\n",
      "Epoch 346/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0701 - accuracy: 0.9822 - val_loss: 0.5540 - val_accuracy: 0.9384\n",
      "Epoch 347/2000\n",
      "338/338 [==============================] - 0s 74us/step - loss: 0.0692 - accuracy: 0.9822 - val_loss: 0.5555 - val_accuracy: 0.9384\n",
      "Epoch 348/2000\n",
      "338/338 [==============================] - 0s 77us/step - loss: 0.0691 - accuracy: 0.9822 - val_loss: 0.5564 - val_accuracy: 0.9384\n",
      "Epoch 349/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0692 - accuracy: 0.9822 - val_loss: 0.5556 - val_accuracy: 0.9384\n",
      "Epoch 350/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0690 - accuracy: 0.9822 - val_loss: 0.5523 - val_accuracy: 0.9384\n",
      "Epoch 351/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0688 - accuracy: 0.9822 - val_loss: 0.5552 - val_accuracy: 0.9384\n",
      "Epoch 352/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0686 - accuracy: 0.9822 - val_loss: 0.5575 - val_accuracy: 0.9384\n",
      "Epoch 353/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0689 - accuracy: 0.9822 - val_loss: 0.5574 - val_accuracy: 0.9384\n",
      "Epoch 354/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0686 - accuracy: 0.9822 - val_loss: 0.5615 - val_accuracy: 0.9452\n",
      "Epoch 355/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0697 - accuracy: 0.9822 - val_loss: 0.5598 - val_accuracy: 0.9384\n",
      "Epoch 356/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0698 - accuracy: 0.9822 - val_loss: 0.5584 - val_accuracy: 0.9384\n",
      "Epoch 357/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0693 - accuracy: 0.9822 - val_loss: 0.5568 - val_accuracy: 0.9384\n",
      "Epoch 358/2000\n",
      "338/338 [==============================] - 0s 63us/step - loss: 0.0690 - accuracy: 0.9822 - val_loss: 0.5537 - val_accuracy: 0.9384\n",
      "Epoch 359/2000\n",
      "338/338 [==============================] - 0s 75us/step - loss: 0.0687 - accuracy: 0.9822 - val_loss: 0.5541 - val_accuracy: 0.9384\n",
      "Epoch 360/2000\n",
      "338/338 [==============================] - 0s 62us/step - loss: 0.0686 - accuracy: 0.9822 - val_loss: 0.5558 - val_accuracy: 0.9384\n",
      "Epoch 361/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0695 - accuracy: 0.9822 - val_loss: 0.5559 - val_accuracy: 0.9384\n",
      "Epoch 362/2000\n",
      "338/338 [==============================] - 0s 76us/step - loss: 0.0691 - accuracy: 0.9822 - val_loss: 0.5555 - val_accuracy: 0.9384\n",
      "Epoch 363/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0690 - accuracy: 0.9822 - val_loss: 0.5562 - val_accuracy: 0.9384\n",
      "Epoch 364/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0689 - accuracy: 0.9822 - val_loss: 0.5580 - val_accuracy: 0.9384\n",
      "Epoch 365/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0698 - accuracy: 0.9822 - val_loss: 0.5581 - val_accuracy: 0.9384\n",
      "Epoch 366/2000\n",
      "338/338 [==============================] - 0s 76us/step - loss: 0.0687 - accuracy: 0.9822 - val_loss: 0.5589 - val_accuracy: 0.9384\n",
      "Epoch 367/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0690 - accuracy: 0.9822 - val_loss: 0.5564 - val_accuracy: 0.9384\n",
      "Epoch 368/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0691 - accuracy: 0.9822 - val_loss: 0.5557 - val_accuracy: 0.9384\n",
      "Epoch 369/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0687 - accuracy: 0.9822 - val_loss: 0.5573 - val_accuracy: 0.9384\n",
      "Epoch 370/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0686 - accuracy: 0.9822 - val_loss: 0.5539 - val_accuracy: 0.9384\n",
      "Epoch 371/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0685 - accuracy: 0.9822 - val_loss: 0.5572 - val_accuracy: 0.9384\n",
      "Epoch 372/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0687 - accuracy: 0.9822 - val_loss: 0.5579 - val_accuracy: 0.9384\n",
      "Epoch 373/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0690 - accuracy: 0.9822 - val_loss: 0.5581 - val_accuracy: 0.9384\n",
      "Epoch 374/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0693 - accuracy: 0.9822 - val_loss: 0.5577 - val_accuracy: 0.9384\n",
      "Epoch 375/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0690 - accuracy: 0.9822 - val_loss: 0.5559 - val_accuracy: 0.9384\n",
      "Epoch 376/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0686 - accuracy: 0.9822 - val_loss: 0.5559 - val_accuracy: 0.9384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 377/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0690 - accuracy: 0.9822 - val_loss: 0.5555 - val_accuracy: 0.9384\n",
      "Epoch 378/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0691 - accuracy: 0.9822 - val_loss: 0.5568 - val_accuracy: 0.9384\n",
      "Epoch 379/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0695 - accuracy: 0.9822 - val_loss: 0.5564 - val_accuracy: 0.9384\n",
      "Epoch 380/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0683 - accuracy: 0.9822 - val_loss: 0.5522 - val_accuracy: 0.9384\n",
      "Epoch 381/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0682 - accuracy: 0.9822 - val_loss: 0.5573 - val_accuracy: 0.9384\n",
      "Epoch 382/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0688 - accuracy: 0.9822 - val_loss: 0.5528 - val_accuracy: 0.9384\n",
      "Epoch 383/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0693 - accuracy: 0.9822 - val_loss: 0.5537 - val_accuracy: 0.9384\n",
      "Epoch 384/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0686 - accuracy: 0.9822 - val_loss: 0.5573 - val_accuracy: 0.9384\n",
      "Epoch 385/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0698 - accuracy: 0.9822 - val_loss: 0.5559 - val_accuracy: 0.9384\n",
      "Epoch 386/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0688 - accuracy: 0.9822 - val_loss: 0.5532 - val_accuracy: 0.9384\n",
      "Epoch 387/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0686 - accuracy: 0.9822 - val_loss: 0.5530 - val_accuracy: 0.9384\n",
      "Epoch 388/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0685 - accuracy: 0.9822 - val_loss: 0.5548 - val_accuracy: 0.9384\n",
      "Epoch 389/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0681 - accuracy: 0.9822 - val_loss: 0.5577 - val_accuracy: 0.9384\n",
      "Epoch 390/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0697 - accuracy: 0.9822 - val_loss: 0.5563 - val_accuracy: 0.9384\n",
      "Epoch 391/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0685 - accuracy: 0.9822 - val_loss: 0.5557 - val_accuracy: 0.9384\n",
      "Epoch 392/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0687 - accuracy: 0.9822 - val_loss: 0.5523 - val_accuracy: 0.9384\n",
      "Epoch 393/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0692 - accuracy: 0.9822 - val_loss: 0.5530 - val_accuracy: 0.9384\n",
      "Epoch 394/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0682 - accuracy: 0.9822 - val_loss: 0.5503 - val_accuracy: 0.9384\n",
      "Epoch 395/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0686 - accuracy: 0.9822 - val_loss: 0.5515 - val_accuracy: 0.9384\n",
      "Epoch 396/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0689 - accuracy: 0.9822 - val_loss: 0.5516 - val_accuracy: 0.9384\n",
      "Epoch 397/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0686 - accuracy: 0.9822 - val_loss: 0.5528 - val_accuracy: 0.9384\n",
      "Epoch 398/2000\n",
      "338/338 [==============================] - 0s 91us/step - loss: 0.0680 - accuracy: 0.9822 - val_loss: 0.5533 - val_accuracy: 0.9384\n",
      "Epoch 399/2000\n",
      "338/338 [==============================] - 0s 91us/step - loss: 0.0690 - accuracy: 0.9822 - val_loss: 0.5546 - val_accuracy: 0.9384\n",
      "Epoch 400/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0692 - accuracy: 0.9822 - val_loss: 0.5535 - val_accuracy: 0.9384\n",
      "Epoch 401/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0684 - accuracy: 0.9822 - val_loss: 0.5524 - val_accuracy: 0.9384\n",
      "Epoch 402/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0689 - accuracy: 0.9822 - val_loss: 0.5539 - val_accuracy: 0.9384\n",
      "Epoch 403/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0682 - accuracy: 0.9822 - val_loss: 0.5553 - val_accuracy: 0.9384\n",
      "Epoch 404/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0688 - accuracy: 0.9822 - val_loss: 0.5556 - val_accuracy: 0.9384\n",
      "Epoch 405/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0684 - accuracy: 0.9822 - val_loss: 0.5540 - val_accuracy: 0.9384\n",
      "Epoch 406/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0687 - accuracy: 0.9822 - val_loss: 0.5510 - val_accuracy: 0.9384\n",
      "Epoch 407/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0681 - accuracy: 0.9822 - val_loss: 0.5530 - val_accuracy: 0.9384\n",
      "Epoch 408/2000\n",
      "338/338 [==============================] - 0s 74us/step - loss: 0.0683 - accuracy: 0.9822 - val_loss: 0.5559 - val_accuracy: 0.9384\n",
      "Epoch 409/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0687 - accuracy: 0.9822 - val_loss: 0.5536 - val_accuracy: 0.9384\n",
      "Epoch 410/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0681 - accuracy: 0.9822 - val_loss: 0.5558 - val_accuracy: 0.9384\n",
      "Epoch 411/2000\n",
      "338/338 [==============================] - 0s 74us/step - loss: 0.0690 - accuracy: 0.9822 - val_loss: 0.5540 - val_accuracy: 0.9384\n",
      "Epoch 412/2000\n",
      "338/338 [==============================] - 0s 77us/step - loss: 0.0684 - accuracy: 0.9822 - val_loss: 0.5536 - val_accuracy: 0.9384\n",
      "Epoch 413/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0689 - accuracy: 0.9822 - val_loss: 0.5540 - val_accuracy: 0.9384\n",
      "Epoch 414/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0681 - accuracy: 0.9822 - val_loss: 0.5502 - val_accuracy: 0.9384\n",
      "Epoch 415/2000\n",
      "338/338 [==============================] - 0s 74us/step - loss: 0.0676 - accuracy: 0.9822 - val_loss: 0.5541 - val_accuracy: 0.9384\n",
      "Epoch 416/2000\n",
      "338/338 [==============================] - 0s 79us/step - loss: 0.0684 - accuracy: 0.9822 - val_loss: 0.5514 - val_accuracy: 0.9384\n",
      "Epoch 417/2000\n",
      "338/338 [==============================] - 0s 81us/step - loss: 0.0684 - accuracy: 0.9822 - val_loss: 0.5513 - val_accuracy: 0.9384\n",
      "Epoch 418/2000\n",
      "338/338 [==============================] - 0s 84us/step - loss: 0.0690 - accuracy: 0.9822 - val_loss: 0.5524 - val_accuracy: 0.9384\n",
      "Epoch 419/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0680 - accuracy: 0.9822 - val_loss: 0.5521 - val_accuracy: 0.9384\n",
      "Epoch 420/2000\n",
      "338/338 [==============================] - 0s 74us/step - loss: 0.0682 - accuracy: 0.9822 - val_loss: 0.5518 - val_accuracy: 0.9384\n",
      "Epoch 421/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0686 - accuracy: 0.9822 - val_loss: 0.5514 - val_accuracy: 0.9384\n",
      "Epoch 422/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0690 - accuracy: 0.9822 - val_loss: 0.5538 - val_accuracy: 0.9384\n",
      "Epoch 423/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0680 - accuracy: 0.9822 - val_loss: 0.5551 - val_accuracy: 0.9384\n",
      "Epoch 424/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0682 - accuracy: 0.9822 - val_loss: 0.5549 - val_accuracy: 0.9384\n",
      "Epoch 425/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0690 - accuracy: 0.9822 - val_loss: 0.5539 - val_accuracy: 0.9384\n",
      "Epoch 426/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0683 - accuracy: 0.9822 - val_loss: 0.5519 - val_accuracy: 0.9384\n",
      "Epoch 427/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0684 - accuracy: 0.9822 - val_loss: 0.5512 - val_accuracy: 0.9384\n",
      "Epoch 428/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0684 - accuracy: 0.9822 - val_loss: 0.5507 - val_accuracy: 0.9384\n",
      "Epoch 429/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0679 - accuracy: 0.9822 - val_loss: 0.5518 - val_accuracy: 0.9384\n",
      "Epoch 430/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0688 - accuracy: 0.9822 - val_loss: 0.5528 - val_accuracy: 0.9384\n",
      "Epoch 431/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0678 - accuracy: 0.9822 - val_loss: 0.5505 - val_accuracy: 0.9384\n",
      "Epoch 432/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0677 - accuracy: 0.9822 - val_loss: 0.5533 - val_accuracy: 0.9384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 433/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0685 - accuracy: 0.9822 - val_loss: 0.5503 - val_accuracy: 0.9384\n",
      "Epoch 434/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0675 - accuracy: 0.9822 - val_loss: 0.5521 - val_accuracy: 0.9384\n",
      "Epoch 435/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0686 - accuracy: 0.9822 - val_loss: 0.5536 - val_accuracy: 0.9384\n",
      "Epoch 436/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0693 - accuracy: 0.9822 - val_loss: 0.5522 - val_accuracy: 0.9384\n",
      "Epoch 437/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0679 - accuracy: 0.9822 - val_loss: 0.5504 - val_accuracy: 0.9384\n",
      "Epoch 438/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0682 - accuracy: 0.9822 - val_loss: 0.5505 - val_accuracy: 0.9384\n",
      "Epoch 439/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0679 - accuracy: 0.9822 - val_loss: 0.5500 - val_accuracy: 0.9384\n",
      "Epoch 440/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0679 - accuracy: 0.9822 - val_loss: 0.5522 - val_accuracy: 0.9384\n",
      "Epoch 441/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0690 - accuracy: 0.9822 - val_loss: 0.5510 - val_accuracy: 0.9384\n",
      "Epoch 442/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0673 - accuracy: 0.9822 - val_loss: 0.5535 - val_accuracy: 0.9384\n",
      "Epoch 443/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0685 - accuracy: 0.9822 - val_loss: 0.5500 - val_accuracy: 0.9384\n",
      "Epoch 444/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0681 - accuracy: 0.9822 - val_loss: 0.5496 - val_accuracy: 0.9384\n",
      "Epoch 445/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0679 - accuracy: 0.9822 - val_loss: 0.5497 - val_accuracy: 0.9384\n",
      "Epoch 446/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0678 - accuracy: 0.9822 - val_loss: 0.5506 - val_accuracy: 0.9384\n",
      "Epoch 447/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0684 - accuracy: 0.9822 - val_loss: 0.5484 - val_accuracy: 0.9384\n",
      "Epoch 448/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0675 - accuracy: 0.9822 - val_loss: 0.5502 - val_accuracy: 0.9384\n",
      "Epoch 449/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0682 - accuracy: 0.9822 - val_loss: 0.5498 - val_accuracy: 0.9384\n",
      "Epoch 450/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0683 - accuracy: 0.9822 - val_loss: 0.5486 - val_accuracy: 0.9384\n",
      "Epoch 451/2000\n",
      "338/338 [==============================] - 0s 74us/step - loss: 0.0674 - accuracy: 0.9822 - val_loss: 0.5520 - val_accuracy: 0.9384\n",
      "Epoch 452/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0676 - accuracy: 0.9822 - val_loss: 0.5483 - val_accuracy: 0.9384\n",
      "Epoch 453/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0676 - accuracy: 0.9822 - val_loss: 0.5457 - val_accuracy: 0.9315\n",
      "Epoch 454/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0679 - accuracy: 0.9822 - val_loss: 0.5481 - val_accuracy: 0.9384\n",
      "Epoch 455/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0677 - accuracy: 0.9822 - val_loss: 0.5498 - val_accuracy: 0.9384\n",
      "Epoch 456/2000\n",
      "338/338 [==============================] - 0s 77us/step - loss: 0.0683 - accuracy: 0.9822 - val_loss: 0.5492 - val_accuracy: 0.9384\n",
      "Epoch 457/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0674 - accuracy: 0.9822 - val_loss: 0.5507 - val_accuracy: 0.9384\n",
      "Epoch 458/2000\n",
      "338/338 [==============================] - 0s 78us/step - loss: 0.0679 - accuracy: 0.9822 - val_loss: 0.5479 - val_accuracy: 0.9384\n",
      "Epoch 459/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0676 - accuracy: 0.9822 - val_loss: 0.5482 - val_accuracy: 0.9384\n",
      "Epoch 460/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0676 - accuracy: 0.9822 - val_loss: 0.5481 - val_accuracy: 0.9384\n",
      "Epoch 461/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0676 - accuracy: 0.9822 - val_loss: 0.5490 - val_accuracy: 0.9384\n",
      "Epoch 462/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0675 - accuracy: 0.9822 - val_loss: 0.5479 - val_accuracy: 0.9384\n",
      "Epoch 463/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0675 - accuracy: 0.9822 - val_loss: 0.5476 - val_accuracy: 0.9384\n",
      "Epoch 464/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0680 - accuracy: 0.9822 - val_loss: 0.5463 - val_accuracy: 0.9384\n",
      "Epoch 465/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0676 - accuracy: 0.9822 - val_loss: 0.5456 - val_accuracy: 0.9384\n",
      "Epoch 466/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0677 - accuracy: 0.9822 - val_loss: 0.5464 - val_accuracy: 0.9384\n",
      "Epoch 467/2000\n",
      "338/338 [==============================] - 0s 77us/step - loss: 0.0674 - accuracy: 0.9822 - val_loss: 0.5472 - val_accuracy: 0.9384\n",
      "Epoch 468/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0676 - accuracy: 0.9822 - val_loss: 0.5452 - val_accuracy: 0.9315\n",
      "Epoch 469/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0674 - accuracy: 0.9822 - val_loss: 0.5469 - val_accuracy: 0.9384\n",
      "Epoch 470/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0677 - accuracy: 0.9822 - val_loss: 0.5460 - val_accuracy: 0.9384\n",
      "Epoch 471/2000\n",
      "338/338 [==============================] - 0s 65us/step - loss: 0.0673 - accuracy: 0.9822 - val_loss: 0.5484 - val_accuracy: 0.9384\n",
      "Epoch 472/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0677 - accuracy: 0.9822 - val_loss: 0.5471 - val_accuracy: 0.9384\n",
      "Epoch 473/2000\n",
      "338/338 [==============================] - 0s 65us/step - loss: 0.0669 - accuracy: 0.9822 - val_loss: 0.5445 - val_accuracy: 0.9315\n",
      "Epoch 474/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0675 - accuracy: 0.9822 - val_loss: 0.5459 - val_accuracy: 0.9384\n",
      "Epoch 475/2000\n",
      "338/338 [==============================] - 0s 65us/step - loss: 0.0673 - accuracy: 0.9822 - val_loss: 0.5449 - val_accuracy: 0.9384\n",
      "Epoch 476/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0673 - accuracy: 0.9822 - val_loss: 0.5469 - val_accuracy: 0.9384\n",
      "Epoch 477/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0667 - accuracy: 0.9822 - val_loss: 0.5489 - val_accuracy: 0.9384\n",
      "Epoch 478/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0676 - accuracy: 0.9822 - val_loss: 0.5465 - val_accuracy: 0.9384\n",
      "Epoch 479/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0675 - accuracy: 0.9822 - val_loss: 0.5447 - val_accuracy: 0.9384\n",
      "Epoch 480/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0675 - accuracy: 0.9822 - val_loss: 0.5451 - val_accuracy: 0.9384\n",
      "Epoch 481/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0669 - accuracy: 0.9822 - val_loss: 0.5470 - val_accuracy: 0.9384\n",
      "Epoch 482/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0674 - accuracy: 0.9822 - val_loss: 0.5485 - val_accuracy: 0.9384\n",
      "Epoch 483/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0675 - accuracy: 0.9822 - val_loss: 0.5474 - val_accuracy: 0.9384\n",
      "Epoch 484/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0671 - accuracy: 0.9822 - val_loss: 0.5466 - val_accuracy: 0.9384\n",
      "Epoch 485/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0672 - accuracy: 0.9822 - val_loss: 0.5454 - val_accuracy: 0.9384\n",
      "Epoch 486/2000\n",
      "338/338 [==============================] - 0s 63us/step - loss: 0.0672 - accuracy: 0.9822 - val_loss: 0.5457 - val_accuracy: 0.9384\n",
      "Epoch 487/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0669 - accuracy: 0.9822 - val_loss: 0.5476 - val_accuracy: 0.9384\n",
      "Epoch 488/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0671 - accuracy: 0.9822 - val_loss: 0.5436 - val_accuracy: 0.9384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 489/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0672 - accuracy: 0.9822 - val_loss: 0.5446 - val_accuracy: 0.9384\n",
      "Epoch 490/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0672 - accuracy: 0.9822 - val_loss: 0.5436 - val_accuracy: 0.9384\n",
      "Epoch 491/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0666 - accuracy: 0.9822 - val_loss: 0.5461 - val_accuracy: 0.9384\n",
      "Epoch 492/2000\n",
      "338/338 [==============================] - 0s 64us/step - loss: 0.0674 - accuracy: 0.9822 - val_loss: 0.5454 - val_accuracy: 0.9384\n",
      "Epoch 493/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0670 - accuracy: 0.9822 - val_loss: 0.5419 - val_accuracy: 0.9247\n",
      "Epoch 494/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0675 - accuracy: 0.9822 - val_loss: 0.5427 - val_accuracy: 0.9384\n",
      "Epoch 495/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0672 - accuracy: 0.9822 - val_loss: 0.5431 - val_accuracy: 0.9384\n",
      "Epoch 496/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0671 - accuracy: 0.9822 - val_loss: 0.5434 - val_accuracy: 0.9384\n",
      "Epoch 497/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0674 - accuracy: 0.9822 - val_loss: 0.5429 - val_accuracy: 0.9384\n",
      "Epoch 498/2000\n",
      "338/338 [==============================] - 0s 64us/step - loss: 0.0669 - accuracy: 0.9822 - val_loss: 0.5433 - val_accuracy: 0.9384\n",
      "Epoch 499/2000\n",
      "338/338 [==============================] - 0s 75us/step - loss: 0.0668 - accuracy: 0.9822 - val_loss: 0.5439 - val_accuracy: 0.9384\n",
      "Epoch 500/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0669 - accuracy: 0.9822 - val_loss: 0.5445 - val_accuracy: 0.9384\n",
      "Epoch 501/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0678 - accuracy: 0.9822 - val_loss: 0.5439 - val_accuracy: 0.9384\n",
      "Epoch 502/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0668 - accuracy: 0.9822 - val_loss: 0.5439 - val_accuracy: 0.9384\n",
      "Epoch 503/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0665 - accuracy: 0.9822 - val_loss: 0.5441 - val_accuracy: 0.9384\n",
      "Epoch 504/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0680 - accuracy: 0.9822 - val_loss: 0.5429 - val_accuracy: 0.9384\n",
      "Epoch 505/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0664 - accuracy: 0.9822 - val_loss: 0.5438 - val_accuracy: 0.9384\n",
      "Epoch 506/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0668 - accuracy: 0.9822 - val_loss: 0.5411 - val_accuracy: 0.9110\n",
      "Epoch 507/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0664 - accuracy: 0.9822 - val_loss: 0.5405 - val_accuracy: 0.9041\n",
      "Epoch 508/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0664 - accuracy: 0.9822 - val_loss: 0.5421 - val_accuracy: 0.9384\n",
      "Epoch 509/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0679 - accuracy: 0.9822 - val_loss: 0.5420 - val_accuracy: 0.9384\n",
      "Epoch 510/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0664 - accuracy: 0.9822 - val_loss: 0.5419 - val_accuracy: 0.9384\n",
      "Epoch 511/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0667 - accuracy: 0.9822 - val_loss: 0.5418 - val_accuracy: 0.9384\n",
      "Epoch 512/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0671 - accuracy: 0.9822 - val_loss: 0.5434 - val_accuracy: 0.9384\n",
      "Epoch 513/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0666 - accuracy: 0.9822 - val_loss: 0.5434 - val_accuracy: 0.9384\n",
      "Epoch 514/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0668 - accuracy: 0.9822 - val_loss: 0.5431 - val_accuracy: 0.9384\n",
      "Epoch 515/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0663 - accuracy: 0.9822 - val_loss: 0.5436 - val_accuracy: 0.9384\n",
      "Epoch 516/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0670 - accuracy: 0.9822 - val_loss: 0.5416 - val_accuracy: 0.9384\n",
      "Epoch 517/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0668 - accuracy: 0.9822 - val_loss: 0.5408 - val_accuracy: 0.9110\n",
      "Epoch 518/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0662 - accuracy: 0.9822 - val_loss: 0.5409 - val_accuracy: 0.9315\n",
      "Epoch 519/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0665 - accuracy: 0.9822 - val_loss: 0.5418 - val_accuracy: 0.9384\n",
      "Epoch 520/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0666 - accuracy: 0.9822 - val_loss: 0.5414 - val_accuracy: 0.9384\n",
      "Epoch 521/2000\n",
      "338/338 [==============================] - 0s 65us/step - loss: 0.0666 - accuracy: 0.9822 - val_loss: 0.5415 - val_accuracy: 0.9384\n",
      "Epoch 522/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0667 - accuracy: 0.9822 - val_loss: 0.5417 - val_accuracy: 0.9384\n",
      "Epoch 523/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0666 - accuracy: 0.9822 - val_loss: 0.5408 - val_accuracy: 0.9110\n",
      "Epoch 524/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0658 - accuracy: 0.9822 - val_loss: 0.5425 - val_accuracy: 0.9384\n",
      "Epoch 525/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0666 - accuracy: 0.9822 - val_loss: 0.5417 - val_accuracy: 0.9384\n",
      "Epoch 526/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0667 - accuracy: 0.9822 - val_loss: 0.5417 - val_accuracy: 0.9384\n",
      "Epoch 527/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0669 - accuracy: 0.9822 - val_loss: 0.5411 - val_accuracy: 0.9384\n",
      "Epoch 528/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0664 - accuracy: 0.9822 - val_loss: 0.5398 - val_accuracy: 0.9041\n",
      "Epoch 529/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0659 - accuracy: 0.9822 - val_loss: 0.5407 - val_accuracy: 0.9384\n",
      "Epoch 530/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0662 - accuracy: 0.9822 - val_loss: 0.5412 - val_accuracy: 0.9384\n",
      "Epoch 531/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0661 - accuracy: 0.9822 - val_loss: 0.5409 - val_accuracy: 0.9384\n",
      "Epoch 532/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0659 - accuracy: 0.9822 - val_loss: 0.5421 - val_accuracy: 0.9384\n",
      "Epoch 533/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0661 - accuracy: 0.9822 - val_loss: 0.5438 - val_accuracy: 0.9384\n",
      "Epoch 534/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0667 - accuracy: 0.9822 - val_loss: 0.5422 - val_accuracy: 0.9384\n",
      "Epoch 535/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0659 - accuracy: 0.9822 - val_loss: 0.5420 - val_accuracy: 0.9384\n",
      "Epoch 536/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0661 - accuracy: 0.9822 - val_loss: 0.5399 - val_accuracy: 0.9110\n",
      "Epoch 537/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0655 - accuracy: 0.9822 - val_loss: 0.5410 - val_accuracy: 0.9384\n",
      "Epoch 538/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0664 - accuracy: 0.9822 - val_loss: 0.5400 - val_accuracy: 0.9384\n",
      "Epoch 539/2000\n",
      "338/338 [==============================] - 0s 76us/step - loss: 0.0659 - accuracy: 0.9822 - val_loss: 0.5401 - val_accuracy: 0.9384\n",
      "Epoch 540/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0660 - accuracy: 0.9822 - val_loss: 0.5383 - val_accuracy: 0.9041\n",
      "Epoch 541/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0657 - accuracy: 0.9822 - val_loss: 0.5389 - val_accuracy: 0.9110\n",
      "Epoch 542/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0662 - accuracy: 0.9822 - val_loss: 0.5390 - val_accuracy: 0.9110\n",
      "Epoch 543/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0653 - accuracy: 0.9822 - val_loss: 0.5404 - val_accuracy: 0.9384\n",
      "Epoch 544/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0660 - accuracy: 0.9822 - val_loss: 0.5398 - val_accuracy: 0.9384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 545/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0661 - accuracy: 0.9822 - val_loss: 0.5389 - val_accuracy: 0.9178\n",
      "Epoch 546/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0656 - accuracy: 0.9822 - val_loss: 0.5390 - val_accuracy: 0.9178\n",
      "Epoch 547/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0654 - accuracy: 0.9822 - val_loss: 0.5409 - val_accuracy: 0.9384\n",
      "Epoch 548/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0663 - accuracy: 0.9822 - val_loss: 0.5399 - val_accuracy: 0.9384\n",
      "Epoch 549/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0658 - accuracy: 0.9822 - val_loss: 0.5393 - val_accuracy: 0.9384\n",
      "Epoch 550/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0654 - accuracy: 0.9822 - val_loss: 0.5407 - val_accuracy: 0.9384\n",
      "Epoch 551/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0666 - accuracy: 0.9822 - val_loss: 0.5405 - val_accuracy: 0.9384\n",
      "Epoch 552/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0658 - accuracy: 0.9822 - val_loss: 0.5388 - val_accuracy: 0.9178\n",
      "Epoch 553/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0659 - accuracy: 0.9822 - val_loss: 0.5392 - val_accuracy: 0.9178\n",
      "Epoch 554/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0656 - accuracy: 0.9822 - val_loss: 0.5380 - val_accuracy: 0.9110\n",
      "Epoch 555/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0658 - accuracy: 0.9822 - val_loss: 0.5369 - val_accuracy: 0.9041\n",
      "Epoch 556/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0657 - accuracy: 0.9822 - val_loss: 0.5369 - val_accuracy: 0.9041\n",
      "Epoch 557/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0652 - accuracy: 0.9822 - val_loss: 0.5360 - val_accuracy: 0.8973\n",
      "Epoch 558/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0651 - accuracy: 0.9822 - val_loss: 0.5356 - val_accuracy: 0.8973\n",
      "Epoch 559/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0657 - accuracy: 0.9822 - val_loss: 0.5362 - val_accuracy: 0.8973\n",
      "Epoch 560/2000\n",
      "338/338 [==============================] - 0s 74us/step - loss: 0.0653 - accuracy: 0.9822 - val_loss: 0.5369 - val_accuracy: 0.9110\n",
      "Epoch 561/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0659 - accuracy: 0.9822 - val_loss: 0.5367 - val_accuracy: 0.9041\n",
      "Epoch 562/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0653 - accuracy: 0.9822 - val_loss: 0.5367 - val_accuracy: 0.9041\n",
      "Epoch 563/2000\n",
      "338/338 [==============================] - 0s 74us/step - loss: 0.0650 - accuracy: 0.9822 - val_loss: 0.5370 - val_accuracy: 0.9041\n",
      "Epoch 564/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0658 - accuracy: 0.9822 - val_loss: 0.5369 - val_accuracy: 0.9041\n",
      "Epoch 565/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0649 - accuracy: 0.9822 - val_loss: 0.5363 - val_accuracy: 0.8973\n",
      "Epoch 566/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0655 - accuracy: 0.9822 - val_loss: 0.5365 - val_accuracy: 0.9041\n",
      "Epoch 567/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0669 - accuracy: 0.9822 - val_loss: 0.5387 - val_accuracy: 0.9178\n",
      "Epoch 568/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0649 - accuracy: 0.9822 - val_loss: 0.5373 - val_accuracy: 0.9110\n",
      "Epoch 569/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0649 - accuracy: 0.9822 - val_loss: 0.5361 - val_accuracy: 0.8973\n",
      "Epoch 570/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0659 - accuracy: 0.9822 - val_loss: 0.5364 - val_accuracy: 0.8973\n",
      "Epoch 571/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0647 - accuracy: 0.9822 - val_loss: 0.5376 - val_accuracy: 0.9178\n",
      "Epoch 572/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0651 - accuracy: 0.9822 - val_loss: 0.5376 - val_accuracy: 0.9178\n",
      "Epoch 573/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0657 - accuracy: 0.9822 - val_loss: 0.5367 - val_accuracy: 0.9110\n",
      "Epoch 574/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0648 - accuracy: 0.9822 - val_loss: 0.5362 - val_accuracy: 0.9110\n",
      "Epoch 575/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0650 - accuracy: 0.9822 - val_loss: 0.5372 - val_accuracy: 0.9178\n",
      "Epoch 576/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0648 - accuracy: 0.9822 - val_loss: 0.5363 - val_accuracy: 0.9041\n",
      "Epoch 577/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0650 - accuracy: 0.9822 - val_loss: 0.5354 - val_accuracy: 0.8973\n",
      "Epoch 578/2000\n",
      "338/338 [==============================] - 0s 74us/step - loss: 0.0645 - accuracy: 0.9822 - val_loss: 0.5359 - val_accuracy: 0.9110\n",
      "Epoch 579/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0649 - accuracy: 0.9822 - val_loss: 0.5351 - val_accuracy: 0.8973\n",
      "Epoch 580/2000\n",
      "338/338 [==============================] - 0s 74us/step - loss: 0.0646 - accuracy: 0.9822 - val_loss: 0.5349 - val_accuracy: 0.8973\n",
      "Epoch 581/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0646 - accuracy: 0.9822 - val_loss: 0.5347 - val_accuracy: 0.8973\n",
      "Epoch 582/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0655 - accuracy: 0.9822 - val_loss: 0.5354 - val_accuracy: 0.9110\n",
      "Epoch 583/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0646 - accuracy: 0.9822 - val_loss: 0.5356 - val_accuracy: 0.9110\n",
      "Epoch 584/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0647 - accuracy: 0.9822 - val_loss: 0.5356 - val_accuracy: 0.9178\n",
      "Epoch 585/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0649 - accuracy: 0.9822 - val_loss: 0.5350 - val_accuracy: 0.9110\n",
      "Epoch 586/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0644 - accuracy: 0.9822 - val_loss: 0.5342 - val_accuracy: 0.8973\n",
      "Epoch 587/2000\n",
      "338/338 [==============================] - 0s 64us/step - loss: 0.0646 - accuracy: 0.9822 - val_loss: 0.5338 - val_accuracy: 0.8973\n",
      "Epoch 588/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0644 - accuracy: 0.9822 - val_loss: 0.5338 - val_accuracy: 0.8973\n",
      "Epoch 589/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0652 - accuracy: 0.9822 - val_loss: 0.5346 - val_accuracy: 0.9110\n",
      "Epoch 590/2000\n",
      "338/338 [==============================] - 0s 76us/step - loss: 0.0641 - accuracy: 0.9822 - val_loss: 0.5347 - val_accuracy: 0.9110\n",
      "Epoch 591/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0645 - accuracy: 0.9822 - val_loss: 0.5338 - val_accuracy: 0.8973\n",
      "Epoch 592/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0644 - accuracy: 0.9822 - val_loss: 0.5339 - val_accuracy: 0.9041\n",
      "Epoch 593/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0646 - accuracy: 0.9822 - val_loss: 0.5333 - val_accuracy: 0.8973\n",
      "Epoch 594/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0643 - accuracy: 0.9822 - val_loss: 0.5345 - val_accuracy: 0.9178\n",
      "Epoch 595/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0644 - accuracy: 0.9822 - val_loss: 0.5340 - val_accuracy: 0.9041\n",
      "Epoch 596/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0638 - accuracy: 0.9822 - val_loss: 0.5351 - val_accuracy: 0.9178\n",
      "Epoch 597/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0648 - accuracy: 0.9822 - val_loss: 0.5338 - val_accuracy: 0.9110\n",
      "Epoch 598/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0647 - accuracy: 0.9822 - val_loss: 0.5335 - val_accuracy: 0.8973\n",
      "Epoch 599/2000\n",
      "338/338 [==============================] - 0s 65us/step - loss: 0.0640 - accuracy: 0.9822 - val_loss: 0.5332 - val_accuracy: 0.8973\n",
      "Epoch 600/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0646 - accuracy: 0.9822 - val_loss: 0.5329 - val_accuracy: 0.8973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 601/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0639 - accuracy: 0.9822 - val_loss: 0.5333 - val_accuracy: 0.8973\n",
      "Epoch 602/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0641 - accuracy: 0.9822 - val_loss: 0.5322 - val_accuracy: 0.8973\n",
      "Epoch 603/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0636 - accuracy: 0.9822 - val_loss: 0.5330 - val_accuracy: 0.9041\n",
      "Epoch 604/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0639 - accuracy: 0.9822 - val_loss: 0.5334 - val_accuracy: 0.9178\n",
      "Epoch 605/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0640 - accuracy: 0.9822 - val_loss: 0.5331 - val_accuracy: 0.9041\n",
      "Epoch 606/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0642 - accuracy: 0.9822 - val_loss: 0.5321 - val_accuracy: 0.8973\n",
      "Epoch 607/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0639 - accuracy: 0.9822 - val_loss: 0.5322 - val_accuracy: 0.8973\n",
      "Epoch 608/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0640 - accuracy: 0.9822 - val_loss: 0.5317 - val_accuracy: 0.8973\n",
      "Epoch 609/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0639 - accuracy: 0.9822 - val_loss: 0.5329 - val_accuracy: 0.9041\n",
      "Epoch 610/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0636 - accuracy: 0.9822 - val_loss: 0.5319 - val_accuracy: 0.8973\n",
      "Epoch 611/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0640 - accuracy: 0.9822 - val_loss: 0.5320 - val_accuracy: 0.8973\n",
      "Epoch 612/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0634 - accuracy: 0.9822 - val_loss: 0.5323 - val_accuracy: 0.9041\n",
      "Epoch 613/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0631 - accuracy: 0.9822 - val_loss: 0.5336 - val_accuracy: 0.9178\n",
      "Epoch 614/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0637 - accuracy: 0.9822 - val_loss: 0.5319 - val_accuracy: 0.9041\n",
      "Epoch 615/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0636 - accuracy: 0.9822 - val_loss: 0.5316 - val_accuracy: 0.9041\n",
      "Epoch 616/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0630 - accuracy: 0.9822 - val_loss: 0.5333 - val_accuracy: 0.9178\n",
      "Epoch 617/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0641 - accuracy: 0.9822 - val_loss: 0.5323 - val_accuracy: 0.9041\n",
      "Epoch 618/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0633 - accuracy: 0.9822 - val_loss: 0.5328 - val_accuracy: 0.9178\n",
      "Epoch 619/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0638 - accuracy: 0.9822 - val_loss: 0.5318 - val_accuracy: 0.8973\n",
      "Epoch 620/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0635 - accuracy: 0.9822 - val_loss: 0.5313 - val_accuracy: 0.8973\n",
      "Epoch 621/2000\n",
      "338/338 [==============================] - 0s 81us/step - loss: 0.0634 - accuracy: 0.9822 - val_loss: 0.5316 - val_accuracy: 0.8973\n",
      "Epoch 622/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0631 - accuracy: 0.9822 - val_loss: 0.5320 - val_accuracy: 0.9041\n",
      "Epoch 623/2000\n",
      "338/338 [==============================] - 0s 74us/step - loss: 0.0631 - accuracy: 0.9822 - val_loss: 0.5324 - val_accuracy: 0.9110\n",
      "Epoch 624/2000\n",
      "338/338 [==============================] - 0s 76us/step - loss: 0.0636 - accuracy: 0.9822 - val_loss: 0.5326 - val_accuracy: 0.9110\n",
      "Epoch 625/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0634 - accuracy: 0.9822 - val_loss: 0.5319 - val_accuracy: 0.9041\n",
      "Epoch 626/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0632 - accuracy: 0.9822 - val_loss: 0.5314 - val_accuracy: 0.8973\n",
      "Epoch 627/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0631 - accuracy: 0.9822 - val_loss: 0.5307 - val_accuracy: 0.8904\n",
      "Epoch 628/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0633 - accuracy: 0.9822 - val_loss: 0.5306 - val_accuracy: 0.8904\n",
      "Epoch 629/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0629 - accuracy: 0.9822 - val_loss: 0.5308 - val_accuracy: 0.8973\n",
      "Epoch 630/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0635 - accuracy: 0.9822 - val_loss: 0.5311 - val_accuracy: 0.8973\n",
      "Epoch 631/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0637 - accuracy: 0.9822 - val_loss: 0.5313 - val_accuracy: 0.8973\n",
      "Epoch 632/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0632 - accuracy: 0.9822 - val_loss: 0.5306 - val_accuracy: 0.8973\n",
      "Epoch 633/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0629 - accuracy: 0.9822 - val_loss: 0.5310 - val_accuracy: 0.8973\n",
      "Epoch 634/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0626 - accuracy: 0.9822 - val_loss: 0.5305 - val_accuracy: 0.8904\n",
      "Epoch 635/2000\n",
      "338/338 [==============================] - 0s 75us/step - loss: 0.0630 - accuracy: 0.9822 - val_loss: 0.5310 - val_accuracy: 0.8973\n",
      "Epoch 636/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0629 - accuracy: 0.9822 - val_loss: 0.5308 - val_accuracy: 0.8973\n",
      "Epoch 637/2000\n",
      "338/338 [==============================] - 0s 65us/step - loss: 0.0633 - accuracy: 0.9822 - val_loss: 0.5313 - val_accuracy: 0.8973\n",
      "Epoch 638/2000\n",
      "338/338 [==============================] - 0s 74us/step - loss: 0.0626 - accuracy: 0.9822 - val_loss: 0.5310 - val_accuracy: 0.8973\n",
      "Epoch 639/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0636 - accuracy: 0.9822 - val_loss: 0.5313 - val_accuracy: 0.8973\n",
      "Epoch 640/2000\n",
      "338/338 [==============================] - 0s 77us/step - loss: 0.0621 - accuracy: 0.9822 - val_loss: 0.5310 - val_accuracy: 0.8973\n",
      "Epoch 641/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0627 - accuracy: 0.9822 - val_loss: 0.5310 - val_accuracy: 0.8973\n",
      "Epoch 642/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0625 - accuracy: 0.9822 - val_loss: 0.5308 - val_accuracy: 0.8904\n",
      "Epoch 643/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0625 - accuracy: 0.9822 - val_loss: 0.5309 - val_accuracy: 0.8973\n",
      "Epoch 644/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0624 - accuracy: 0.9822 - val_loss: 0.5313 - val_accuracy: 0.9041\n",
      "Epoch 645/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0623 - accuracy: 0.9822 - val_loss: 0.5313 - val_accuracy: 0.9041\n",
      "Epoch 646/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0630 - accuracy: 0.9822 - val_loss: 0.5316 - val_accuracy: 0.9110\n",
      "Epoch 647/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0623 - accuracy: 0.9822 - val_loss: 0.5310 - val_accuracy: 0.8973\n",
      "Epoch 648/2000\n",
      "338/338 [==============================] - 0s 65us/step - loss: 0.0619 - accuracy: 0.9822 - val_loss: 0.5315 - val_accuracy: 0.9110\n",
      "Epoch 649/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0623 - accuracy: 0.9822 - val_loss: 0.5304 - val_accuracy: 0.8973\n",
      "Epoch 650/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0623 - accuracy: 0.9822 - val_loss: 0.5301 - val_accuracy: 0.8904\n",
      "Epoch 651/2000\n",
      "338/338 [==============================] - 0s 74us/step - loss: 0.0628 - accuracy: 0.9822 - val_loss: 0.5299 - val_accuracy: 0.8904\n",
      "Epoch 652/2000\n",
      "338/338 [==============================] - 0s 62us/step - loss: 0.0619 - accuracy: 0.9822 - val_loss: 0.5303 - val_accuracy: 0.8973\n",
      "Epoch 653/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0623 - accuracy: 0.9822 - val_loss: 0.5307 - val_accuracy: 0.9041\n",
      "Epoch 654/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0623 - accuracy: 0.9822 - val_loss: 0.5305 - val_accuracy: 0.9041\n",
      "Epoch 655/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0630 - accuracy: 0.9822 - val_loss: 0.5311 - val_accuracy: 0.9110\n",
      "Epoch 656/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0623 - accuracy: 0.9822 - val_loss: 0.5307 - val_accuracy: 0.8973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 657/2000\n",
      "338/338 [==============================] - 0s 74us/step - loss: 0.0623 - accuracy: 0.9822 - val_loss: 0.5308 - val_accuracy: 0.9041\n",
      "Epoch 658/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0620 - accuracy: 0.9822 - val_loss: 0.5302 - val_accuracy: 0.8904\n",
      "Epoch 659/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0620 - accuracy: 0.9822 - val_loss: 0.5306 - val_accuracy: 0.8904\n",
      "Epoch 660/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0626 - accuracy: 0.9822 - val_loss: 0.5309 - val_accuracy: 0.8904\n",
      "Epoch 661/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0617 - accuracy: 0.9822 - val_loss: 0.5310 - val_accuracy: 0.8904\n",
      "Epoch 662/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0613 - accuracy: 0.9822 - val_loss: 0.5312 - val_accuracy: 0.8904\n",
      "Epoch 663/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0615 - accuracy: 0.9822 - val_loss: 0.5317 - val_accuracy: 0.9110\n",
      "Epoch 664/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0618 - accuracy: 0.9822 - val_loss: 0.5312 - val_accuracy: 0.9041\n",
      "Epoch 665/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0621 - accuracy: 0.9822 - val_loss: 0.5311 - val_accuracy: 0.8904\n",
      "Epoch 666/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0615 - accuracy: 0.9822 - val_loss: 0.5319 - val_accuracy: 0.9041\n",
      "Epoch 667/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0617 - accuracy: 0.9822 - val_loss: 0.5317 - val_accuracy: 0.9041\n",
      "Epoch 668/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0629 - accuracy: 0.9822 - val_loss: 0.5323 - val_accuracy: 0.9041\n",
      "Epoch 669/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0621 - accuracy: 0.9822 - val_loss: 0.5322 - val_accuracy: 0.8904\n",
      "Epoch 670/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0613 - accuracy: 0.9822 - val_loss: 0.5324 - val_accuracy: 0.8904\n",
      "Epoch 671/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0617 - accuracy: 0.9822 - val_loss: 0.5322 - val_accuracy: 0.8904\n",
      "Epoch 672/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0609 - accuracy: 0.9822 - val_loss: 0.5327 - val_accuracy: 0.9041\n",
      "Epoch 673/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0613 - accuracy: 0.9822 - val_loss: 0.5323 - val_accuracy: 0.8904\n",
      "Epoch 674/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0614 - accuracy: 0.9822 - val_loss: 0.5321 - val_accuracy: 0.8904\n",
      "Epoch 675/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0606 - accuracy: 0.9822 - val_loss: 0.5327 - val_accuracy: 0.8973\n",
      "Epoch 676/2000\n",
      "338/338 [==============================] - 0s 63us/step - loss: 0.0614 - accuracy: 0.9822 - val_loss: 0.5330 - val_accuracy: 0.9041\n",
      "Epoch 677/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0616 - accuracy: 0.9822 - val_loss: 0.5326 - val_accuracy: 0.8904\n",
      "Epoch 678/2000\n",
      "338/338 [==============================] - 0s 63us/step - loss: 0.0610 - accuracy: 0.9822 - val_loss: 0.5328 - val_accuracy: 0.8973\n",
      "Epoch 679/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0611 - accuracy: 0.9822 - val_loss: 0.5327 - val_accuracy: 0.8904\n",
      "Epoch 680/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0610 - accuracy: 0.9822 - val_loss: 0.5324 - val_accuracy: 0.8904\n",
      "Epoch 681/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0609 - accuracy: 0.9822 - val_loss: 0.5324 - val_accuracy: 0.8904\n",
      "Epoch 682/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0606 - accuracy: 0.9822 - val_loss: 0.5329 - val_accuracy: 0.9041\n",
      "Epoch 683/2000\n",
      "338/338 [==============================] - 0s 63us/step - loss: 0.0608 - accuracy: 0.9822 - val_loss: 0.5324 - val_accuracy: 0.8904\n",
      "Epoch 684/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0608 - accuracy: 0.9822 - val_loss: 0.5325 - val_accuracy: 0.8904\n",
      "Epoch 685/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0608 - accuracy: 0.9822 - val_loss: 0.5324 - val_accuracy: 0.8904\n",
      "Epoch 686/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0606 - accuracy: 0.9822 - val_loss: 0.5321 - val_accuracy: 0.8904\n",
      "Epoch 687/2000\n",
      "338/338 [==============================] - 0s 65us/step - loss: 0.0609 - accuracy: 0.9822 - val_loss: 0.5323 - val_accuracy: 0.8904\n",
      "Epoch 688/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0610 - accuracy: 0.9822 - val_loss: 0.5324 - val_accuracy: 0.8904\n",
      "Epoch 689/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0606 - accuracy: 0.9822 - val_loss: 0.5327 - val_accuracy: 0.8904\n",
      "Epoch 690/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0602 - accuracy: 0.9822 - val_loss: 0.5328 - val_accuracy: 0.8904\n",
      "Epoch 691/2000\n",
      "338/338 [==============================] - 0s 63us/step - loss: 0.0606 - accuracy: 0.9822 - val_loss: 0.5326 - val_accuracy: 0.8904\n",
      "Epoch 692/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0607 - accuracy: 0.9822 - val_loss: 0.5325 - val_accuracy: 0.8904\n",
      "Epoch 693/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0606 - accuracy: 0.9822 - val_loss: 0.5328 - val_accuracy: 0.8904\n",
      "Epoch 694/2000\n",
      "338/338 [==============================] - 0s 65us/step - loss: 0.0608 - accuracy: 0.9822 - val_loss: 0.5329 - val_accuracy: 0.8904\n",
      "Epoch 695/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0604 - accuracy: 0.9822 - val_loss: 0.5327 - val_accuracy: 0.8904\n",
      "Epoch 696/2000\n",
      "338/338 [==============================] - 0s 65us/step - loss: 0.0601 - accuracy: 0.9822 - val_loss: 0.5328 - val_accuracy: 0.8904\n",
      "Epoch 697/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0602 - accuracy: 0.9822 - val_loss: 0.5327 - val_accuracy: 0.8904\n",
      "Epoch 698/2000\n",
      "338/338 [==============================] - 0s 63us/step - loss: 0.0606 - accuracy: 0.9822 - val_loss: 0.5328 - val_accuracy: 0.8904\n",
      "Epoch 699/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0604 - accuracy: 0.9822 - val_loss: 0.5328 - val_accuracy: 0.8904\n",
      "Epoch 700/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0600 - accuracy: 0.9822 - val_loss: 0.5327 - val_accuracy: 0.8904\n",
      "Epoch 701/2000\n",
      "338/338 [==============================] - 0s 76us/step - loss: 0.0599 - accuracy: 0.9822 - val_loss: 0.5327 - val_accuracy: 0.8904\n",
      "Epoch 702/2000\n",
      "338/338 [==============================] - 0s 64us/step - loss: 0.0604 - accuracy: 0.9822 - val_loss: 0.5328 - val_accuracy: 0.8904\n",
      "Epoch 703/2000\n",
      "338/338 [==============================] - 0s 75us/step - loss: 0.0605 - accuracy: 0.9822 - val_loss: 0.5334 - val_accuracy: 0.8904\n",
      "Epoch 704/2000\n",
      "338/338 [==============================] - 0s 63us/step - loss: 0.0598 - accuracy: 0.9822 - val_loss: 0.5334 - val_accuracy: 0.8904\n",
      "Epoch 705/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0600 - accuracy: 0.9822 - val_loss: 0.5333 - val_accuracy: 0.8904\n",
      "Epoch 706/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0598 - accuracy: 0.9822 - val_loss: 0.5333 - val_accuracy: 0.8904\n",
      "Epoch 707/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0602 - accuracy: 0.9822 - val_loss: 0.5335 - val_accuracy: 0.8904\n",
      "Epoch 708/2000\n",
      "338/338 [==============================] - 0s 65us/step - loss: 0.0595 - accuracy: 0.9822 - val_loss: 0.5334 - val_accuracy: 0.8904\n",
      "Epoch 709/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0601 - accuracy: 0.9822 - val_loss: 0.5332 - val_accuracy: 0.8904\n",
      "Epoch 710/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0597 - accuracy: 0.9822 - val_loss: 0.5332 - val_accuracy: 0.8904\n",
      "Epoch 711/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0592 - accuracy: 0.9822 - val_loss: 0.5336 - val_accuracy: 0.8973\n",
      "Epoch 712/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0598 - accuracy: 0.9822 - val_loss: 0.5334 - val_accuracy: 0.8973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 713/2000\n",
      "338/338 [==============================] - 0s 74us/step - loss: 0.0597 - accuracy: 0.9822 - val_loss: 0.5333 - val_accuracy: 0.8973\n",
      "Epoch 714/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0607 - accuracy: 0.9822 - val_loss: 0.5331 - val_accuracy: 0.8973\n",
      "Epoch 715/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0594 - accuracy: 0.9822 - val_loss: 0.5331 - val_accuracy: 0.8904\n",
      "Epoch 716/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0598 - accuracy: 0.9822 - val_loss: 0.5332 - val_accuracy: 0.8904\n",
      "Epoch 717/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0590 - accuracy: 0.9822 - val_loss: 0.5334 - val_accuracy: 0.8973\n",
      "Epoch 718/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0595 - accuracy: 0.9822 - val_loss: 0.5332 - val_accuracy: 0.8904\n",
      "Epoch 719/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0593 - accuracy: 0.9822 - val_loss: 0.5330 - val_accuracy: 0.8904\n",
      "Epoch 720/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0602 - accuracy: 0.9822 - val_loss: 0.5335 - val_accuracy: 0.8904\n",
      "Epoch 721/2000\n",
      "338/338 [==============================] - 0s 74us/step - loss: 0.0590 - accuracy: 0.9822 - val_loss: 0.5336 - val_accuracy: 0.8904\n",
      "Epoch 722/2000\n",
      "338/338 [==============================] - 0s 63us/step - loss: 0.0591 - accuracy: 0.9822 - val_loss: 0.5337 - val_accuracy: 0.8904\n",
      "Epoch 723/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0598 - accuracy: 0.9822 - val_loss: 0.5333 - val_accuracy: 0.8904\n",
      "Epoch 724/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0591 - accuracy: 0.9822 - val_loss: 0.5335 - val_accuracy: 0.8904\n",
      "Epoch 725/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0587 - accuracy: 0.9822 - val_loss: 0.5336 - val_accuracy: 0.8904\n",
      "Epoch 726/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0591 - accuracy: 0.9822 - val_loss: 0.5336 - val_accuracy: 0.8904\n",
      "Epoch 727/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0592 - accuracy: 0.9822 - val_loss: 0.5340 - val_accuracy: 0.8973\n",
      "Epoch 728/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0589 - accuracy: 0.9822 - val_loss: 0.5346 - val_accuracy: 0.9041\n",
      "Epoch 729/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0598 - accuracy: 0.9822 - val_loss: 0.5342 - val_accuracy: 0.8904\n",
      "Epoch 730/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0585 - accuracy: 0.9822 - val_loss: 0.5343 - val_accuracy: 0.8904\n",
      "Epoch 731/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0593 - accuracy: 0.9822 - val_loss: 0.5347 - val_accuracy: 0.8904\n",
      "Epoch 732/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0588 - accuracy: 0.9822 - val_loss: 0.5351 - val_accuracy: 0.8904\n",
      "Epoch 733/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0590 - accuracy: 0.9822 - val_loss: 0.5352 - val_accuracy: 0.8904\n",
      "Epoch 734/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0589 - accuracy: 0.9822 - val_loss: 0.5352 - val_accuracy: 0.8904\n",
      "Epoch 735/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0586 - accuracy: 0.9822 - val_loss: 0.5351 - val_accuracy: 0.8973\n",
      "Epoch 736/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0586 - accuracy: 0.9822 - val_loss: 0.5355 - val_accuracy: 0.8904\n",
      "Epoch 737/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0584 - accuracy: 0.9822 - val_loss: 0.5358 - val_accuracy: 0.8973\n",
      "Epoch 738/2000\n",
      "338/338 [==============================] - 0s 63us/step - loss: 0.0584 - accuracy: 0.9822 - val_loss: 0.5360 - val_accuracy: 0.8973\n",
      "Epoch 739/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0589 - accuracy: 0.9822 - val_loss: 0.5355 - val_accuracy: 0.8973\n",
      "Epoch 740/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0582 - accuracy: 0.9822 - val_loss: 0.5359 - val_accuracy: 0.8973\n",
      "Epoch 741/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0593 - accuracy: 0.9822 - val_loss: 0.5358 - val_accuracy: 0.8973\n",
      "Epoch 742/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0588 - accuracy: 0.9822 - val_loss: 0.5359 - val_accuracy: 0.8973\n",
      "Epoch 743/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0580 - accuracy: 0.9822 - val_loss: 0.5360 - val_accuracy: 0.8973\n",
      "Epoch 744/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0588 - accuracy: 0.9822 - val_loss: 0.5361 - val_accuracy: 0.8904\n",
      "Epoch 745/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0579 - accuracy: 0.9822 - val_loss: 0.5361 - val_accuracy: 0.8904\n",
      "Epoch 746/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0579 - accuracy: 0.9822 - val_loss: 0.5365 - val_accuracy: 0.8904\n",
      "Epoch 747/2000\n",
      "338/338 [==============================] - 0s 79us/step - loss: 0.0584 - accuracy: 0.9822 - val_loss: 0.5364 - val_accuracy: 0.8973\n",
      "Epoch 748/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0581 - accuracy: 0.9822 - val_loss: 0.5366 - val_accuracy: 0.8973\n",
      "Epoch 749/2000\n",
      "338/338 [==============================] - 0s 78us/step - loss: 0.0580 - accuracy: 0.9822 - val_loss: 0.5369 - val_accuracy: 0.8904\n",
      "Epoch 750/2000\n",
      "338/338 [==============================] - 0s 76us/step - loss: 0.0582 - accuracy: 0.9822 - val_loss: 0.5371 - val_accuracy: 0.8904\n",
      "Epoch 751/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0580 - accuracy: 0.9822 - val_loss: 0.5373 - val_accuracy: 0.8904\n",
      "Epoch 752/2000\n",
      "338/338 [==============================] - 0s 65us/step - loss: 0.0576 - accuracy: 0.9822 - val_loss: 0.5368 - val_accuracy: 0.8973\n",
      "Epoch 753/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0580 - accuracy: 0.9822 - val_loss: 0.5370 - val_accuracy: 0.8904\n",
      "Epoch 754/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0581 - accuracy: 0.9822 - val_loss: 0.5373 - val_accuracy: 0.8904\n",
      "Epoch 755/2000\n",
      "338/338 [==============================] - 0s 65us/step - loss: 0.0577 - accuracy: 0.9822 - val_loss: 0.5372 - val_accuracy: 0.8904\n",
      "Epoch 756/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0573 - accuracy: 0.9822 - val_loss: 0.5371 - val_accuracy: 0.8973\n",
      "Epoch 757/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0577 - accuracy: 0.9822 - val_loss: 0.5372 - val_accuracy: 0.9041\n",
      "Epoch 758/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0585 - accuracy: 0.9822 - val_loss: 0.5362 - val_accuracy: 0.9041\n",
      "Epoch 759/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0574 - accuracy: 0.9822 - val_loss: 0.5364 - val_accuracy: 0.8904\n",
      "Epoch 760/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0575 - accuracy: 0.9822 - val_loss: 0.5366 - val_accuracy: 0.8904\n",
      "Epoch 761/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0568 - accuracy: 0.9852 - val_loss: 0.5366 - val_accuracy: 0.9041\n",
      "Epoch 762/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0583 - accuracy: 0.9822 - val_loss: 0.5379 - val_accuracy: 0.8973\n",
      "Epoch 763/2000\n",
      "338/338 [==============================] - 0s 76us/step - loss: 0.0572 - accuracy: 0.9822 - val_loss: 0.5383 - val_accuracy: 0.8904\n",
      "Epoch 764/2000\n",
      "338/338 [==============================] - 0s 88us/step - loss: 0.0571 - accuracy: 0.9822 - val_loss: 0.5383 - val_accuracy: 0.8973\n",
      "Epoch 765/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0576 - accuracy: 0.9822 - val_loss: 0.5387 - val_accuracy: 0.9041\n",
      "Epoch 766/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0572 - accuracy: 0.9822 - val_loss: 0.5390 - val_accuracy: 0.8973\n",
      "Epoch 767/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0570 - accuracy: 0.9822 - val_loss: 0.5390 - val_accuracy: 0.9041\n",
      "Epoch 768/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0574 - accuracy: 0.9822 - val_loss: 0.5392 - val_accuracy: 0.8973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 769/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0570 - accuracy: 0.9822 - val_loss: 0.5390 - val_accuracy: 0.9041\n",
      "Epoch 770/2000\n",
      "338/338 [==============================] - 0s 64us/step - loss: 0.0572 - accuracy: 0.9822 - val_loss: 0.5394 - val_accuracy: 0.9041\n",
      "Epoch 771/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0577 - accuracy: 0.9822 - val_loss: 0.5399 - val_accuracy: 0.8973\n",
      "Epoch 772/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0565 - accuracy: 0.9822 - val_loss: 0.5398 - val_accuracy: 0.9041\n",
      "Epoch 773/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0568 - accuracy: 0.9822 - val_loss: 0.5400 - val_accuracy: 0.9041\n",
      "Epoch 774/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0574 - accuracy: 0.9822 - val_loss: 0.5398 - val_accuracy: 0.9041\n",
      "Epoch 775/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0578 - accuracy: 0.9822 - val_loss: 0.5406 - val_accuracy: 0.8973\n",
      "Epoch 776/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0562 - accuracy: 0.9822 - val_loss: 0.5409 - val_accuracy: 0.8973\n",
      "Epoch 777/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0566 - accuracy: 0.9822 - val_loss: 0.5409 - val_accuracy: 0.9041\n",
      "Epoch 778/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0566 - accuracy: 0.9822 - val_loss: 0.5411 - val_accuracy: 0.8973\n",
      "Epoch 779/2000\n",
      "338/338 [==============================] - 0s 77us/step - loss: 0.0566 - accuracy: 0.9822 - val_loss: 0.5411 - val_accuracy: 0.9041\n",
      "Epoch 780/2000\n",
      "338/338 [==============================] - 0s 77us/step - loss: 0.0569 - accuracy: 0.9822 - val_loss: 0.5413 - val_accuracy: 0.8904\n",
      "Epoch 781/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0560 - accuracy: 0.9852 - val_loss: 0.5414 - val_accuracy: 0.9041\n",
      "Epoch 782/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0571 - accuracy: 0.9822 - val_loss: 0.5418 - val_accuracy: 0.8973\n",
      "Epoch 783/2000\n",
      "338/338 [==============================] - 0s 64us/step - loss: 0.0565 - accuracy: 0.9822 - val_loss: 0.5423 - val_accuracy: 0.8973\n",
      "Epoch 784/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0567 - accuracy: 0.9822 - val_loss: 0.5427 - val_accuracy: 0.8973\n",
      "Epoch 785/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0562 - accuracy: 0.9822 - val_loss: 0.5435 - val_accuracy: 0.8904\n",
      "Epoch 786/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0564 - accuracy: 0.9822 - val_loss: 0.5430 - val_accuracy: 0.8973\n",
      "Epoch 787/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0561 - accuracy: 0.9822 - val_loss: 0.5435 - val_accuracy: 0.8973\n",
      "Epoch 788/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0561 - accuracy: 0.9822 - val_loss: 0.5430 - val_accuracy: 0.9041\n",
      "Epoch 789/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0564 - accuracy: 0.9822 - val_loss: 0.5439 - val_accuracy: 0.8973\n",
      "Epoch 790/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0560 - accuracy: 0.9822 - val_loss: 0.5446 - val_accuracy: 0.8904\n",
      "Epoch 791/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0555 - accuracy: 0.9852 - val_loss: 0.5436 - val_accuracy: 0.9041\n",
      "Epoch 792/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0560 - accuracy: 0.9822 - val_loss: 0.5441 - val_accuracy: 0.8973\n",
      "Epoch 793/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0563 - accuracy: 0.9852 - val_loss: 0.5440 - val_accuracy: 0.9041\n",
      "Epoch 794/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0560 - accuracy: 0.9822 - val_loss: 0.5443 - val_accuracy: 0.9041\n",
      "Epoch 795/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0562 - accuracy: 0.9822 - val_loss: 0.5447 - val_accuracy: 0.9041\n",
      "Epoch 796/2000\n",
      "338/338 [==============================] - 0s 65us/step - loss: 0.0556 - accuracy: 0.9822 - val_loss: 0.5450 - val_accuracy: 0.9041\n",
      "Epoch 797/2000\n",
      "338/338 [==============================] - 0s 64us/step - loss: 0.0558 - accuracy: 0.9822 - val_loss: 0.5451 - val_accuracy: 0.9041\n",
      "Epoch 798/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0561 - accuracy: 0.9822 - val_loss: 0.5453 - val_accuracy: 0.9041\n",
      "Epoch 799/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0558 - accuracy: 0.9852 - val_loss: 0.5455 - val_accuracy: 0.9041\n",
      "Epoch 800/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0560 - accuracy: 0.9822 - val_loss: 0.5458 - val_accuracy: 0.9041\n",
      "Epoch 801/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0557 - accuracy: 0.9822 - val_loss: 0.5464 - val_accuracy: 0.9041\n",
      "Epoch 802/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0557 - accuracy: 0.9822 - val_loss: 0.5466 - val_accuracy: 0.9041\n",
      "Epoch 803/2000\n",
      "338/338 [==============================] - 0s 64us/step - loss: 0.0558 - accuracy: 0.9822 - val_loss: 0.5477 - val_accuracy: 0.8904\n",
      "Epoch 804/2000\n",
      "338/338 [==============================] - 0s 64us/step - loss: 0.0560 - accuracy: 0.9822 - val_loss: 0.5471 - val_accuracy: 0.8973\n",
      "Epoch 805/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0553 - accuracy: 0.9852 - val_loss: 0.5474 - val_accuracy: 0.8973\n",
      "Epoch 806/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0549 - accuracy: 0.9852 - val_loss: 0.5470 - val_accuracy: 0.9041\n",
      "Epoch 807/2000\n",
      "338/338 [==============================] - 0s 65us/step - loss: 0.0555 - accuracy: 0.9822 - val_loss: 0.5469 - val_accuracy: 0.9041\n",
      "Epoch 808/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0555 - accuracy: 0.9822 - val_loss: 0.5475 - val_accuracy: 0.9041\n",
      "Epoch 809/2000\n",
      "338/338 [==============================] - 0s 81us/step - loss: 0.0554 - accuracy: 0.9822 - val_loss: 0.5481 - val_accuracy: 0.8973\n",
      "Epoch 810/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0549 - accuracy: 0.9852 - val_loss: 0.5477 - val_accuracy: 0.9041\n",
      "Epoch 811/2000\n",
      "338/338 [==============================] - 0s 65us/step - loss: 0.0552 - accuracy: 0.9852 - val_loss: 0.5481 - val_accuracy: 0.9041\n",
      "Epoch 812/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0556 - accuracy: 0.9822 - val_loss: 0.5483 - val_accuracy: 0.9041\n",
      "Epoch 813/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0550 - accuracy: 0.9852 - val_loss: 0.5480 - val_accuracy: 0.9041\n",
      "Epoch 814/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0552 - accuracy: 0.9822 - val_loss: 0.5487 - val_accuracy: 0.9041\n",
      "Epoch 815/2000\n",
      "338/338 [==============================] - 0s 65us/step - loss: 0.0548 - accuracy: 0.9822 - val_loss: 0.5495 - val_accuracy: 0.8973\n",
      "Epoch 816/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0556 - accuracy: 0.9852 - val_loss: 0.5492 - val_accuracy: 0.9041\n",
      "Epoch 817/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0548 - accuracy: 0.9822 - val_loss: 0.5497 - val_accuracy: 0.9041\n",
      "Epoch 818/2000\n",
      "338/338 [==============================] - 0s 65us/step - loss: 0.0550 - accuracy: 0.9852 - val_loss: 0.5506 - val_accuracy: 0.8973\n",
      "Epoch 819/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0544 - accuracy: 0.9852 - val_loss: 0.5504 - val_accuracy: 0.9041\n",
      "Epoch 820/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0547 - accuracy: 0.9822 - val_loss: 0.5508 - val_accuracy: 0.9041\n",
      "Epoch 821/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0550 - accuracy: 0.9822 - val_loss: 0.5520 - val_accuracy: 0.8973\n",
      "Epoch 822/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0550 - accuracy: 0.9822 - val_loss: 0.5527 - val_accuracy: 0.8973\n",
      "Epoch 823/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0544 - accuracy: 0.9852 - val_loss: 0.5531 - val_accuracy: 0.8973\n",
      "Epoch 824/2000\n",
      "338/338 [==============================] - 0s 65us/step - loss: 0.0543 - accuracy: 0.9852 - val_loss: 0.5526 - val_accuracy: 0.9041\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 825/2000\n",
      "338/338 [==============================] - 0s 65us/step - loss: 0.0546 - accuracy: 0.9852 - val_loss: 0.5526 - val_accuracy: 0.9041\n",
      "Epoch 826/2000\n",
      "338/338 [==============================] - 0s 65us/step - loss: 0.0544 - accuracy: 0.9852 - val_loss: 0.5525 - val_accuracy: 0.9041\n",
      "Epoch 827/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0547 - accuracy: 0.9822 - val_loss: 0.5525 - val_accuracy: 0.9041\n",
      "Epoch 828/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0545 - accuracy: 0.9822 - val_loss: 0.5533 - val_accuracy: 0.9041\n",
      "Epoch 829/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0543 - accuracy: 0.9852 - val_loss: 0.5527 - val_accuracy: 0.9041\n",
      "Epoch 830/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0550 - accuracy: 0.9822 - val_loss: 0.5530 - val_accuracy: 0.9041\n",
      "Epoch 831/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0543 - accuracy: 0.9852 - val_loss: 0.5533 - val_accuracy: 0.9041\n",
      "Epoch 832/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0540 - accuracy: 0.9822 - val_loss: 0.5547 - val_accuracy: 0.8973\n",
      "Epoch 833/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0543 - accuracy: 0.9822 - val_loss: 0.5539 - val_accuracy: 0.9041\n",
      "Epoch 834/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0542 - accuracy: 0.9852 - val_loss: 0.5533 - val_accuracy: 0.9041\n",
      "Epoch 835/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0539 - accuracy: 0.9822 - val_loss: 0.5542 - val_accuracy: 0.9041\n",
      "Epoch 836/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0538 - accuracy: 0.9852 - val_loss: 0.5542 - val_accuracy: 0.9041\n",
      "Epoch 837/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0538 - accuracy: 0.9822 - val_loss: 0.5551 - val_accuracy: 0.9041\n",
      "Epoch 838/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0544 - accuracy: 0.9852 - val_loss: 0.5549 - val_accuracy: 0.9041\n",
      "Epoch 839/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0536 - accuracy: 0.9852 - val_loss: 0.5550 - val_accuracy: 0.9041\n",
      "Epoch 840/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0536 - accuracy: 0.9852 - val_loss: 0.5552 - val_accuracy: 0.9041\n",
      "Epoch 841/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0537 - accuracy: 0.9852 - val_loss: 0.5559 - val_accuracy: 0.9041\n",
      "Epoch 842/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0537 - accuracy: 0.9852 - val_loss: 0.5554 - val_accuracy: 0.9041\n",
      "Epoch 843/2000\n",
      "338/338 [==============================] - 0s 76us/step - loss: 0.0536 - accuracy: 0.9852 - val_loss: 0.5567 - val_accuracy: 0.9041\n",
      "Epoch 844/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0535 - accuracy: 0.9852 - val_loss: 0.5562 - val_accuracy: 0.9041\n",
      "Epoch 845/2000\n",
      "338/338 [==============================] - 0s 75us/step - loss: 0.0537 - accuracy: 0.9822 - val_loss: 0.5562 - val_accuracy: 0.9041\n",
      "Epoch 846/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0540 - accuracy: 0.9822 - val_loss: 0.5580 - val_accuracy: 0.9041\n",
      "Epoch 847/2000\n",
      "338/338 [==============================] - 0s 65us/step - loss: 0.0538 - accuracy: 0.9822 - val_loss: 0.5594 - val_accuracy: 0.9041\n",
      "Epoch 848/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0529 - accuracy: 0.9852 - val_loss: 0.5584 - val_accuracy: 0.9041\n",
      "Epoch 849/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0532 - accuracy: 0.9852 - val_loss: 0.5581 - val_accuracy: 0.9041\n",
      "Epoch 850/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0530 - accuracy: 0.9852 - val_loss: 0.5583 - val_accuracy: 0.9041\n",
      "Epoch 851/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0537 - accuracy: 0.9822 - val_loss: 0.5591 - val_accuracy: 0.9041\n",
      "Epoch 852/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0529 - accuracy: 0.9852 - val_loss: 0.5591 - val_accuracy: 0.9041\n",
      "Epoch 853/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0537 - accuracy: 0.9822 - val_loss: 0.5599 - val_accuracy: 0.9041\n",
      "Epoch 854/2000\n",
      "338/338 [==============================] - 0s 64us/step - loss: 0.0532 - accuracy: 0.9852 - val_loss: 0.5601 - val_accuracy: 0.9041\n",
      "Epoch 855/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0529 - accuracy: 0.9852 - val_loss: 0.5602 - val_accuracy: 0.9041\n",
      "Epoch 856/2000\n",
      "338/338 [==============================] - 0s 65us/step - loss: 0.0534 - accuracy: 0.9852 - val_loss: 0.5603 - val_accuracy: 0.9041\n",
      "Epoch 857/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0531 - accuracy: 0.9852 - val_loss: 0.5611 - val_accuracy: 0.9041\n",
      "Epoch 858/2000\n",
      "338/338 [==============================] - 0s 80us/step - loss: 0.0528 - accuracy: 0.9852 - val_loss: 0.5609 - val_accuracy: 0.9041\n",
      "Epoch 859/2000\n",
      "338/338 [==============================] - 0s 87us/step - loss: 0.0527 - accuracy: 0.9852 - val_loss: 0.5612 - val_accuracy: 0.9041\n",
      "Epoch 860/2000\n",
      "338/338 [==============================] - 0s 77us/step - loss: 0.0534 - accuracy: 0.9822 - val_loss: 0.5622 - val_accuracy: 0.9041\n",
      "Epoch 861/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0527 - accuracy: 0.9852 - val_loss: 0.5637 - val_accuracy: 0.9041\n",
      "Epoch 862/2000\n",
      "338/338 [==============================] - 0s 74us/step - loss: 0.0527 - accuracy: 0.9852 - val_loss: 0.5632 - val_accuracy: 0.9041\n",
      "Epoch 863/2000\n",
      "338/338 [==============================] - 0s 80us/step - loss: 0.0524 - accuracy: 0.9852 - val_loss: 0.5643 - val_accuracy: 0.9041\n",
      "Epoch 864/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0524 - accuracy: 0.9852 - val_loss: 0.5632 - val_accuracy: 0.9041\n",
      "Epoch 865/2000\n",
      "338/338 [==============================] - 0s 65us/step - loss: 0.0524 - accuracy: 0.9852 - val_loss: 0.5630 - val_accuracy: 0.9041\n",
      "Epoch 866/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0524 - accuracy: 0.9852 - val_loss: 0.5623 - val_accuracy: 0.9041\n",
      "Epoch 867/2000\n",
      "338/338 [==============================] - 0s 65us/step - loss: 0.0531 - accuracy: 0.9852 - val_loss: 0.5629 - val_accuracy: 0.9041\n",
      "Epoch 868/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0525 - accuracy: 0.9852 - val_loss: 0.5630 - val_accuracy: 0.9041\n",
      "Epoch 869/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0530 - accuracy: 0.9852 - val_loss: 0.5651 - val_accuracy: 0.9041\n",
      "Epoch 870/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0534 - accuracy: 0.9852 - val_loss: 0.5637 - val_accuracy: 0.9041\n",
      "Epoch 871/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0521 - accuracy: 0.9852 - val_loss: 0.5652 - val_accuracy: 0.9041\n",
      "Epoch 872/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0520 - accuracy: 0.9852 - val_loss: 0.5655 - val_accuracy: 0.9041\n",
      "Epoch 873/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0528 - accuracy: 0.9822 - val_loss: 0.5667 - val_accuracy: 0.9041\n",
      "Epoch 874/2000\n",
      "338/338 [==============================] - 0s 89us/step - loss: 0.0518 - accuracy: 0.9852 - val_loss: 0.5665 - val_accuracy: 0.9041\n",
      "Epoch 875/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0526 - accuracy: 0.9852 - val_loss: 0.5654 - val_accuracy: 0.9041\n",
      "Epoch 876/2000\n",
      "338/338 [==============================] - 0s 63us/step - loss: 0.0518 - accuracy: 0.9852 - val_loss: 0.5672 - val_accuracy: 0.9041\n",
      "Epoch 877/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0522 - accuracy: 0.9852 - val_loss: 0.5671 - val_accuracy: 0.9041\n",
      "Epoch 878/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0517 - accuracy: 0.9852 - val_loss: 0.5681 - val_accuracy: 0.9041\n",
      "Epoch 879/2000\n",
      "338/338 [==============================] - 0s 64us/step - loss: 0.0522 - accuracy: 0.9852 - val_loss: 0.5678 - val_accuracy: 0.9041\n",
      "Epoch 880/2000\n",
      "338/338 [==============================] - 0s 65us/step - loss: 0.0517 - accuracy: 0.9852 - val_loss: 0.5685 - val_accuracy: 0.9041\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 881/2000\n",
      "338/338 [==============================] - 0s 65us/step - loss: 0.0515 - accuracy: 0.9852 - val_loss: 0.5688 - val_accuracy: 0.9041\n",
      "Epoch 882/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0520 - accuracy: 0.9852 - val_loss: 0.5689 - val_accuracy: 0.9041\n",
      "Epoch 883/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0520 - accuracy: 0.9852 - val_loss: 0.5695 - val_accuracy: 0.9041\n",
      "Epoch 884/2000\n",
      "338/338 [==============================] - 0s 74us/step - loss: 0.0513 - accuracy: 0.9852 - val_loss: 0.5705 - val_accuracy: 0.9041\n",
      "Epoch 885/2000\n",
      "338/338 [==============================] - 0s 90us/step - loss: 0.0514 - accuracy: 0.9852 - val_loss: 0.5702 - val_accuracy: 0.9041\n",
      "Epoch 886/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0518 - accuracy: 0.9852 - val_loss: 0.5710 - val_accuracy: 0.9041\n",
      "Epoch 887/2000\n",
      "338/338 [==============================] - 0s 78us/step - loss: 0.0515 - accuracy: 0.9852 - val_loss: 0.5711 - val_accuracy: 0.9041\n",
      "Epoch 888/2000\n",
      "338/338 [==============================] - 0s 80us/step - loss: 0.0512 - accuracy: 0.9852 - val_loss: 0.5709 - val_accuracy: 0.9041\n",
      "Epoch 889/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0510 - accuracy: 0.9852 - val_loss: 0.5710 - val_accuracy: 0.9041\n",
      "Epoch 890/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0515 - accuracy: 0.9852 - val_loss: 0.5724 - val_accuracy: 0.9041\n",
      "Epoch 891/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0510 - accuracy: 0.9852 - val_loss: 0.5735 - val_accuracy: 0.9041\n",
      "Epoch 892/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0510 - accuracy: 0.9852 - val_loss: 0.5744 - val_accuracy: 0.9041\n",
      "Epoch 893/2000\n",
      "338/338 [==============================] - 0s 65us/step - loss: 0.0507 - accuracy: 0.9852 - val_loss: 0.5738 - val_accuracy: 0.9041\n",
      "Epoch 894/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0515 - accuracy: 0.9852 - val_loss: 0.5738 - val_accuracy: 0.9041\n",
      "Epoch 895/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0506 - accuracy: 0.9852 - val_loss: 0.5745 - val_accuracy: 0.9041\n",
      "Epoch 896/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0507 - accuracy: 0.9852 - val_loss: 0.5751 - val_accuracy: 0.9041\n",
      "Epoch 897/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0504 - accuracy: 0.9852 - val_loss: 0.5740 - val_accuracy: 0.9041\n",
      "Epoch 898/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0510 - accuracy: 0.9852 - val_loss: 0.5744 - val_accuracy: 0.9041\n",
      "Epoch 899/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0513 - accuracy: 0.9852 - val_loss: 0.5753 - val_accuracy: 0.9041\n",
      "Epoch 900/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0508 - accuracy: 0.9852 - val_loss: 0.5750 - val_accuracy: 0.9041\n",
      "Epoch 901/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0510 - accuracy: 0.9852 - val_loss: 0.5765 - val_accuracy: 0.9041\n",
      "Epoch 902/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0506 - accuracy: 0.9852 - val_loss: 0.5771 - val_accuracy: 0.9041\n",
      "Epoch 903/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0505 - accuracy: 0.9852 - val_loss: 0.5779 - val_accuracy: 0.9041\n",
      "Epoch 904/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0504 - accuracy: 0.9852 - val_loss: 0.5789 - val_accuracy: 0.9041\n",
      "Epoch 905/2000\n",
      "338/338 [==============================] - 0s 65us/step - loss: 0.0501 - accuracy: 0.9852 - val_loss: 0.5774 - val_accuracy: 0.9041\n",
      "Epoch 906/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0504 - accuracy: 0.9852 - val_loss: 0.5788 - val_accuracy: 0.9041\n",
      "Epoch 907/2000\n",
      "338/338 [==============================] - 0s 65us/step - loss: 0.0502 - accuracy: 0.9852 - val_loss: 0.5783 - val_accuracy: 0.9041\n",
      "Epoch 908/2000\n",
      "338/338 [==============================] - 0s 74us/step - loss: 0.0503 - accuracy: 0.9852 - val_loss: 0.5790 - val_accuracy: 0.9041\n",
      "Epoch 909/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0500 - accuracy: 0.9852 - val_loss: 0.5775 - val_accuracy: 0.9041\n",
      "Epoch 910/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0500 - accuracy: 0.9852 - val_loss: 0.5775 - val_accuracy: 0.9041\n",
      "Epoch 911/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0504 - accuracy: 0.9852 - val_loss: 0.5780 - val_accuracy: 0.9041\n",
      "Epoch 912/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0502 - accuracy: 0.9852 - val_loss: 0.5781 - val_accuracy: 0.9041\n",
      "Epoch 913/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0502 - accuracy: 0.9852 - val_loss: 0.5790 - val_accuracy: 0.9041\n",
      "Epoch 914/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0500 - accuracy: 0.9852 - val_loss: 0.5806 - val_accuracy: 0.9041\n",
      "Epoch 915/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0495 - accuracy: 0.9852 - val_loss: 0.5816 - val_accuracy: 0.9041\n",
      "Epoch 916/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0506 - accuracy: 0.9852 - val_loss: 0.5814 - val_accuracy: 0.9041\n",
      "Epoch 917/2000\n",
      "338/338 [==============================] - 0s 76us/step - loss: 0.0494 - accuracy: 0.9852 - val_loss: 0.5821 - val_accuracy: 0.9041\n",
      "Epoch 918/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0492 - accuracy: 0.9852 - val_loss: 0.5806 - val_accuracy: 0.9041\n",
      "Epoch 919/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0496 - accuracy: 0.9852 - val_loss: 0.5817 - val_accuracy: 0.9041\n",
      "Epoch 920/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0493 - accuracy: 0.9852 - val_loss: 0.5813 - val_accuracy: 0.9041\n",
      "Epoch 921/2000\n",
      "338/338 [==============================] - 0s 65us/step - loss: 0.0497 - accuracy: 0.9852 - val_loss: 0.5819 - val_accuracy: 0.9041\n",
      "Epoch 922/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0505 - accuracy: 0.9852 - val_loss: 0.5825 - val_accuracy: 0.9041\n",
      "Epoch 923/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0500 - accuracy: 0.9852 - val_loss: 0.5836 - val_accuracy: 0.9041\n",
      "Epoch 924/2000\n",
      "338/338 [==============================] - 0s 79us/step - loss: 0.0493 - accuracy: 0.9852 - val_loss: 0.5845 - val_accuracy: 0.9041\n",
      "Epoch 925/2000\n",
      "338/338 [==============================] - 0s 78us/step - loss: 0.0496 - accuracy: 0.9852 - val_loss: 0.5850 - val_accuracy: 0.9041\n",
      "Epoch 926/2000\n",
      "338/338 [==============================] - 0s 78us/step - loss: 0.0488 - accuracy: 0.9852 - val_loss: 0.5849 - val_accuracy: 0.9041\n",
      "Epoch 927/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0496 - accuracy: 0.9852 - val_loss: 0.5868 - val_accuracy: 0.9041\n",
      "Epoch 928/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0488 - accuracy: 0.9852 - val_loss: 0.5872 - val_accuracy: 0.9041\n",
      "Epoch 929/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0491 - accuracy: 0.9852 - val_loss: 0.5863 - val_accuracy: 0.9041\n",
      "Epoch 930/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0492 - accuracy: 0.9852 - val_loss: 0.5877 - val_accuracy: 0.9041\n",
      "Epoch 931/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0488 - accuracy: 0.9852 - val_loss: 0.5892 - val_accuracy: 0.9041\n",
      "Epoch 932/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0486 - accuracy: 0.9852 - val_loss: 0.5888 - val_accuracy: 0.9041\n",
      "Epoch 933/2000\n",
      "338/338 [==============================] - 0s 74us/step - loss: 0.0496 - accuracy: 0.9852 - val_loss: 0.5900 - val_accuracy: 0.9041\n",
      "Epoch 934/2000\n",
      "338/338 [==============================] - 0s 80us/step - loss: 0.0487 - accuracy: 0.9852 - val_loss: 0.5903 - val_accuracy: 0.9041\n",
      "Epoch 935/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0490 - accuracy: 0.9852 - val_loss: 0.5910 - val_accuracy: 0.9041\n",
      "Epoch 936/2000\n",
      "338/338 [==============================] - 0s 74us/step - loss: 0.0486 - accuracy: 0.9852 - val_loss: 0.5919 - val_accuracy: 0.9041\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 937/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0483 - accuracy: 0.9852 - val_loss: 0.5899 - val_accuracy: 0.9041\n",
      "Epoch 938/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0488 - accuracy: 0.9852 - val_loss: 0.5902 - val_accuracy: 0.9041\n",
      "Epoch 939/2000\n",
      "338/338 [==============================] - 0s 65us/step - loss: 0.0492 - accuracy: 0.9852 - val_loss: 0.5918 - val_accuracy: 0.9041\n",
      "Epoch 940/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0484 - accuracy: 0.9852 - val_loss: 0.5918 - val_accuracy: 0.9041\n",
      "Epoch 941/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0482 - accuracy: 0.9852 - val_loss: 0.5940 - val_accuracy: 0.9041\n",
      "Epoch 942/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0480 - accuracy: 0.9852 - val_loss: 0.5929 - val_accuracy: 0.9041\n",
      "Epoch 943/2000\n",
      "338/338 [==============================] - 0s 76us/step - loss: 0.0489 - accuracy: 0.9852 - val_loss: 0.5947 - val_accuracy: 0.9041\n",
      "Epoch 944/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0482 - accuracy: 0.9852 - val_loss: 0.5954 - val_accuracy: 0.9041\n",
      "Epoch 945/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0479 - accuracy: 0.9852 - val_loss: 0.5932 - val_accuracy: 0.9041\n",
      "Epoch 946/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0482 - accuracy: 0.9852 - val_loss: 0.5948 - val_accuracy: 0.9041\n",
      "Epoch 947/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0483 - accuracy: 0.9852 - val_loss: 0.5944 - val_accuracy: 0.9041\n",
      "Epoch 948/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0482 - accuracy: 0.9852 - val_loss: 0.5938 - val_accuracy: 0.9041\n",
      "Epoch 949/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0476 - accuracy: 0.9852 - val_loss: 0.5934 - val_accuracy: 0.9041\n",
      "Epoch 950/2000\n",
      "338/338 [==============================] - 0s 74us/step - loss: 0.0486 - accuracy: 0.9852 - val_loss: 0.5938 - val_accuracy: 0.9041\n",
      "Epoch 951/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0481 - accuracy: 0.9852 - val_loss: 0.5954 - val_accuracy: 0.9041\n",
      "Epoch 952/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0481 - accuracy: 0.9852 - val_loss: 0.5957 - val_accuracy: 0.9041\n",
      "Epoch 953/2000\n",
      "338/338 [==============================] - 0s 76us/step - loss: 0.0477 - accuracy: 0.9852 - val_loss: 0.5960 - val_accuracy: 0.9041\n",
      "Epoch 954/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0477 - accuracy: 0.9852 - val_loss: 0.5984 - val_accuracy: 0.9041\n",
      "Epoch 955/2000\n",
      "338/338 [==============================] - 0s 75us/step - loss: 0.0475 - accuracy: 0.9852 - val_loss: 0.5982 - val_accuracy: 0.9041\n",
      "Epoch 956/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0480 - accuracy: 0.9852 - val_loss: 0.6000 - val_accuracy: 0.9041\n",
      "Epoch 957/2000\n",
      "338/338 [==============================] - 0s 75us/step - loss: 0.0475 - accuracy: 0.9852 - val_loss: 0.6014 - val_accuracy: 0.9041\n",
      "Epoch 958/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0473 - accuracy: 0.9852 - val_loss: 0.6005 - val_accuracy: 0.9041\n",
      "Epoch 959/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0474 - accuracy: 0.9852 - val_loss: 0.6021 - val_accuracy: 0.9041\n",
      "Epoch 960/2000\n",
      "338/338 [==============================] - 0s 65us/step - loss: 0.0474 - accuracy: 0.9852 - val_loss: 0.6021 - val_accuracy: 0.9041\n",
      "Epoch 961/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0473 - accuracy: 0.9852 - val_loss: 0.6012 - val_accuracy: 0.9041\n",
      "Epoch 962/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0477 - accuracy: 0.9852 - val_loss: 0.6012 - val_accuracy: 0.9041\n",
      "Epoch 963/2000\n",
      "338/338 [==============================] - 0s 77us/step - loss: 0.0475 - accuracy: 0.9852 - val_loss: 0.6012 - val_accuracy: 0.9041\n",
      "Epoch 964/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0472 - accuracy: 0.9852 - val_loss: 0.6009 - val_accuracy: 0.9041\n",
      "Epoch 965/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0470 - accuracy: 0.9852 - val_loss: 0.6027 - val_accuracy: 0.9041\n",
      "Epoch 966/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0470 - accuracy: 0.9852 - val_loss: 0.6030 - val_accuracy: 0.9041\n",
      "Epoch 967/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0465 - accuracy: 0.9852 - val_loss: 0.6018 - val_accuracy: 0.9041\n",
      "Epoch 968/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0472 - accuracy: 0.9852 - val_loss: 0.6026 - val_accuracy: 0.9041\n",
      "Epoch 969/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0468 - accuracy: 0.9852 - val_loss: 0.6048 - val_accuracy: 0.9041\n",
      "Epoch 970/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0469 - accuracy: 0.9852 - val_loss: 0.6034 - val_accuracy: 0.9041\n",
      "Epoch 971/2000\n",
      "338/338 [==============================] - 0s 74us/step - loss: 0.0469 - accuracy: 0.9852 - val_loss: 0.6040 - val_accuracy: 0.9041\n",
      "Epoch 972/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0468 - accuracy: 0.9852 - val_loss: 0.6051 - val_accuracy: 0.9041\n",
      "Epoch 973/2000\n",
      "338/338 [==============================] - 0s 75us/step - loss: 0.0466 - accuracy: 0.9852 - val_loss: 0.6044 - val_accuracy: 0.9041\n",
      "Epoch 974/2000\n",
      "338/338 [==============================] - 0s 74us/step - loss: 0.0467 - accuracy: 0.9852 - val_loss: 0.6055 - val_accuracy: 0.9041\n",
      "Epoch 975/2000\n",
      "338/338 [==============================] - 0s 75us/step - loss: 0.0468 - accuracy: 0.9852 - val_loss: 0.6058 - val_accuracy: 0.9041\n",
      "Epoch 976/2000\n",
      "338/338 [==============================] - 0s 77us/step - loss: 0.0472 - accuracy: 0.9852 - val_loss: 0.6062 - val_accuracy: 0.9041\n",
      "Epoch 977/2000\n",
      "338/338 [==============================] - 0s 79us/step - loss: 0.0463 - accuracy: 0.9852 - val_loss: 0.6066 - val_accuracy: 0.9041\n",
      "Epoch 978/2000\n",
      "338/338 [==============================] - 0s 77us/step - loss: 0.0465 - accuracy: 0.9852 - val_loss: 0.6071 - val_accuracy: 0.9041\n",
      "Epoch 979/2000\n",
      "338/338 [==============================] - 0s 82us/step - loss: 0.0461 - accuracy: 0.9852 - val_loss: 0.6069 - val_accuracy: 0.9041\n",
      "Epoch 980/2000\n",
      "338/338 [==============================] - 0s 76us/step - loss: 0.0463 - accuracy: 0.9852 - val_loss: 0.6061 - val_accuracy: 0.9041\n",
      "Epoch 981/2000\n",
      "338/338 [==============================] - 0s 76us/step - loss: 0.0467 - accuracy: 0.9852 - val_loss: 0.6078 - val_accuracy: 0.9041\n",
      "Epoch 982/2000\n",
      "338/338 [==============================] - 0s 94us/step - loss: 0.0463 - accuracy: 0.9852 - val_loss: 0.6094 - val_accuracy: 0.9041\n",
      "Epoch 983/2000\n",
      "338/338 [==============================] - 0s 78us/step - loss: 0.0460 - accuracy: 0.9852 - val_loss: 0.6095 - val_accuracy: 0.9041\n",
      "Epoch 984/2000\n",
      "338/338 [==============================] - 0s 89us/step - loss: 0.0463 - accuracy: 0.9852 - val_loss: 0.6113 - val_accuracy: 0.9041\n",
      "Epoch 985/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0460 - accuracy: 0.9852 - val_loss: 0.6128 - val_accuracy: 0.9041\n",
      "Epoch 986/2000\n",
      "338/338 [==============================] - 0s 77us/step - loss: 0.0459 - accuracy: 0.9852 - val_loss: 0.6123 - val_accuracy: 0.9041\n",
      "Epoch 987/2000\n",
      "338/338 [==============================] - 0s 75us/step - loss: 0.0463 - accuracy: 0.9852 - val_loss: 0.6122 - val_accuracy: 0.9041\n",
      "Epoch 988/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0454 - accuracy: 0.9852 - val_loss: 0.6101 - val_accuracy: 0.9041\n",
      "Epoch 989/2000\n",
      "338/338 [==============================] - 0s 74us/step - loss: 0.0460 - accuracy: 0.9852 - val_loss: 0.6109 - val_accuracy: 0.9041\n",
      "Epoch 990/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0469 - accuracy: 0.9852 - val_loss: 0.6127 - val_accuracy: 0.9041\n",
      "Epoch 991/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0460 - accuracy: 0.9852 - val_loss: 0.6139 - val_accuracy: 0.9041\n",
      "Epoch 992/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0456 - accuracy: 0.9852 - val_loss: 0.6134 - val_accuracy: 0.9041\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 993/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0453 - accuracy: 0.9852 - val_loss: 0.6140 - val_accuracy: 0.9041\n",
      "Epoch 994/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0456 - accuracy: 0.9852 - val_loss: 0.6161 - val_accuracy: 0.9041\n",
      "Epoch 995/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0453 - accuracy: 0.9852 - val_loss: 0.6155 - val_accuracy: 0.9041\n",
      "Epoch 996/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0462 - accuracy: 0.9852 - val_loss: 0.6187 - val_accuracy: 0.9041\n",
      "Epoch 997/2000\n",
      "338/338 [==============================] - 0s 74us/step - loss: 0.0450 - accuracy: 0.9852 - val_loss: 0.6207 - val_accuracy: 0.9041\n",
      "Epoch 998/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0455 - accuracy: 0.9852 - val_loss: 0.6190 - val_accuracy: 0.9041\n",
      "Epoch 999/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0451 - accuracy: 0.9852 - val_loss: 0.6185 - val_accuracy: 0.9041\n",
      "Epoch 1000/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0452 - accuracy: 0.9852 - val_loss: 0.6185 - val_accuracy: 0.9041\n",
      "Epoch 1001/2000\n",
      "338/338 [==============================] - 0s 74us/step - loss: 0.0448 - accuracy: 0.9852 - val_loss: 0.6187 - val_accuracy: 0.9041\n",
      "Epoch 1002/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0453 - accuracy: 0.9852 - val_loss: 0.6196 - val_accuracy: 0.9041\n",
      "Epoch 1003/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0453 - accuracy: 0.9852 - val_loss: 0.6214 - val_accuracy: 0.9041\n",
      "Epoch 1004/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0451 - accuracy: 0.9852 - val_loss: 0.6230 - val_accuracy: 0.9041\n",
      "Epoch 1005/2000\n",
      "338/338 [==============================] - 0s 80us/step - loss: 0.0451 - accuracy: 0.9852 - val_loss: 0.6239 - val_accuracy: 0.9041\n",
      "Epoch 1006/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0448 - accuracy: 0.9852 - val_loss: 0.6226 - val_accuracy: 0.9041\n",
      "Epoch 1007/2000\n",
      "338/338 [==============================] - 0s 80us/step - loss: 0.0450 - accuracy: 0.9852 - val_loss: 0.6240 - val_accuracy: 0.9041\n",
      "Epoch 1008/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0449 - accuracy: 0.9852 - val_loss: 0.6242 - val_accuracy: 0.9041\n",
      "Epoch 1009/2000\n",
      "338/338 [==============================] - 0s 74us/step - loss: 0.0448 - accuracy: 0.9852 - val_loss: 0.6244 - val_accuracy: 0.9041\n",
      "Epoch 1010/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0446 - accuracy: 0.9852 - val_loss: 0.6253 - val_accuracy: 0.9041\n",
      "Epoch 1011/2000\n",
      "338/338 [==============================] - 0s 74us/step - loss: 0.0441 - accuracy: 0.9852 - val_loss: 0.6237 - val_accuracy: 0.9041\n",
      "Epoch 1012/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0446 - accuracy: 0.9852 - val_loss: 0.6247 - val_accuracy: 0.9041\n",
      "Epoch 1013/2000\n",
      "338/338 [==============================] - 0s 75us/step - loss: 0.0446 - accuracy: 0.9852 - val_loss: 0.6255 - val_accuracy: 0.9041\n",
      "Epoch 1014/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0444 - accuracy: 0.9852 - val_loss: 0.6254 - val_accuracy: 0.9041\n",
      "Epoch 1015/2000\n",
      "338/338 [==============================] - 0s 76us/step - loss: 0.0445 - accuracy: 0.9852 - val_loss: 0.6255 - val_accuracy: 0.9041\n",
      "Epoch 1016/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0444 - accuracy: 0.9852 - val_loss: 0.6257 - val_accuracy: 0.9041\n",
      "Epoch 1017/2000\n",
      "338/338 [==============================] - 0s 78us/step - loss: 0.0450 - accuracy: 0.9852 - val_loss: 0.6277 - val_accuracy: 0.9041\n",
      "Epoch 1018/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0444 - accuracy: 0.9852 - val_loss: 0.6282 - val_accuracy: 0.9041\n",
      "Epoch 1019/2000\n",
      "338/338 [==============================] - 0s 76us/step - loss: 0.0444 - accuracy: 0.9852 - val_loss: 0.6282 - val_accuracy: 0.9041\n",
      "Epoch 1020/2000\n",
      "338/338 [==============================] - 0s 77us/step - loss: 0.0438 - accuracy: 0.9852 - val_loss: 0.6275 - val_accuracy: 0.9041\n",
      "Epoch 1021/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0441 - accuracy: 0.9852 - val_loss: 0.6277 - val_accuracy: 0.9041\n",
      "Epoch 1022/2000\n",
      "338/338 [==============================] - 0s 74us/step - loss: 0.0444 - accuracy: 0.9852 - val_loss: 0.6297 - val_accuracy: 0.9041\n",
      "Epoch 1023/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0443 - accuracy: 0.9852 - val_loss: 0.6313 - val_accuracy: 0.9041\n",
      "Epoch 1024/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0444 - accuracy: 0.9852 - val_loss: 0.6325 - val_accuracy: 0.9041\n",
      "Epoch 1025/2000\n",
      "338/338 [==============================] - 0s 75us/step - loss: 0.0436 - accuracy: 0.9852 - val_loss: 0.6323 - val_accuracy: 0.9041\n",
      "Epoch 1026/2000\n",
      "338/338 [==============================] - 0s 74us/step - loss: 0.0439 - accuracy: 0.9852 - val_loss: 0.6332 - val_accuracy: 0.9041\n",
      "Epoch 1027/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0438 - accuracy: 0.9852 - val_loss: 0.6340 - val_accuracy: 0.9041\n",
      "Epoch 1028/2000\n",
      "338/338 [==============================] - 0s 75us/step - loss: 0.0435 - accuracy: 0.9852 - val_loss: 0.6350 - val_accuracy: 0.9041\n",
      "Epoch 1029/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0434 - accuracy: 0.9852 - val_loss: 0.6333 - val_accuracy: 0.9041\n",
      "Epoch 1030/2000\n",
      "338/338 [==============================] - 0s 81us/step - loss: 0.0442 - accuracy: 0.9852 - val_loss: 0.6331 - val_accuracy: 0.9041\n",
      "Epoch 1031/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0438 - accuracy: 0.9852 - val_loss: 0.6344 - val_accuracy: 0.9041\n",
      "Epoch 1032/2000\n",
      "338/338 [==============================] - 0s 79us/step - loss: 0.0432 - accuracy: 0.9852 - val_loss: 0.6334 - val_accuracy: 0.9041\n",
      "Epoch 1033/2000\n",
      "338/338 [==============================] - 0s 78us/step - loss: 0.0437 - accuracy: 0.9852 - val_loss: 0.6355 - val_accuracy: 0.9041\n",
      "Epoch 1034/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0442 - accuracy: 0.9852 - val_loss: 0.6354 - val_accuracy: 0.9041\n",
      "Epoch 1035/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0429 - accuracy: 0.9852 - val_loss: 0.6377 - val_accuracy: 0.9041\n",
      "Epoch 1036/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0434 - accuracy: 0.9852 - val_loss: 0.6401 - val_accuracy: 0.9041\n",
      "Epoch 1037/2000\n",
      "338/338 [==============================] - 0s 75us/step - loss: 0.0430 - accuracy: 0.9852 - val_loss: 0.6392 - val_accuracy: 0.9041\n",
      "Epoch 1038/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0423 - accuracy: 0.9852 - val_loss: 0.6357 - val_accuracy: 0.9041\n",
      "Epoch 1039/2000\n",
      "338/338 [==============================] - 0s 76us/step - loss: 0.0435 - accuracy: 0.9852 - val_loss: 0.6391 - val_accuracy: 0.9041\n",
      "Epoch 1040/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0430 - accuracy: 0.9852 - val_loss: 0.6404 - val_accuracy: 0.9041\n",
      "Epoch 1041/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0429 - accuracy: 0.9852 - val_loss: 0.6408 - val_accuracy: 0.9041\n",
      "Epoch 1042/2000\n",
      "338/338 [==============================] - 0s 65us/step - loss: 0.0428 - accuracy: 0.9852 - val_loss: 0.6390 - val_accuracy: 0.9041\n",
      "Epoch 1043/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0432 - accuracy: 0.9852 - val_loss: 0.6396 - val_accuracy: 0.9041\n",
      "Epoch 1044/2000\n",
      "338/338 [==============================] - 0s 74us/step - loss: 0.0426 - accuracy: 0.9852 - val_loss: 0.6394 - val_accuracy: 0.9041\n",
      "Epoch 1045/2000\n",
      "338/338 [==============================] - 0s 76us/step - loss: 0.0449 - accuracy: 0.9852 - val_loss: 0.6384 - val_accuracy: 0.9041\n",
      "Epoch 1046/2000\n",
      "338/338 [==============================] - 0s 77us/step - loss: 0.0425 - accuracy: 0.9852 - val_loss: 0.6398 - val_accuracy: 0.9041\n",
      "Epoch 1047/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0428 - accuracy: 0.9852 - val_loss: 0.6432 - val_accuracy: 0.9041\n",
      "Epoch 1048/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "338/338 [==============================] - 0s 71us/step - loss: 0.0424 - accuracy: 0.9852 - val_loss: 0.6444 - val_accuracy: 0.9041\n",
      "Epoch 1049/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0425 - accuracy: 0.9852 - val_loss: 0.6451 - val_accuracy: 0.9041\n",
      "Epoch 1050/2000\n",
      "338/338 [==============================] - 0s 76us/step - loss: 0.0424 - accuracy: 0.9852 - val_loss: 0.6444 - val_accuracy: 0.9041\n",
      "Epoch 1051/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0428 - accuracy: 0.9852 - val_loss: 0.6454 - val_accuracy: 0.9041\n",
      "Epoch 1052/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0429 - accuracy: 0.9852 - val_loss: 0.6451 - val_accuracy: 0.9041\n",
      "Epoch 1053/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0424 - accuracy: 0.9852 - val_loss: 0.6453 - val_accuracy: 0.9041\n",
      "Epoch 1054/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0423 - accuracy: 0.9852 - val_loss: 0.6453 - val_accuracy: 0.9041\n",
      "Epoch 1055/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0421 - accuracy: 0.9852 - val_loss: 0.6448 - val_accuracy: 0.9041\n",
      "Epoch 1056/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0427 - accuracy: 0.9852 - val_loss: 0.6454 - val_accuracy: 0.9041\n",
      "Epoch 1057/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0423 - accuracy: 0.9852 - val_loss: 0.6458 - val_accuracy: 0.9041\n",
      "Epoch 1058/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0417 - accuracy: 0.9852 - val_loss: 0.6474 - val_accuracy: 0.9041\n",
      "Epoch 1059/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0422 - accuracy: 0.9852 - val_loss: 0.6507 - val_accuracy: 0.9041\n",
      "Epoch 1060/2000\n",
      "338/338 [==============================] - 0s 80us/step - loss: 0.0420 - accuracy: 0.9852 - val_loss: 0.6498 - val_accuracy: 0.9041\n",
      "Epoch 1061/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0422 - accuracy: 0.9852 - val_loss: 0.6490 - val_accuracy: 0.9041\n",
      "Epoch 1062/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0422 - accuracy: 0.9852 - val_loss: 0.6490 - val_accuracy: 0.9041\n",
      "Epoch 1063/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0417 - accuracy: 0.9852 - val_loss: 0.6492 - val_accuracy: 0.9041\n",
      "Epoch 1064/2000\n",
      "338/338 [==============================] - 0s 74us/step - loss: 0.0420 - accuracy: 0.9852 - val_loss: 0.6497 - val_accuracy: 0.9041\n",
      "Epoch 1065/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0411 - accuracy: 0.9852 - val_loss: 0.6482 - val_accuracy: 0.9041\n",
      "Epoch 1066/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0424 - accuracy: 0.9852 - val_loss: 0.6514 - val_accuracy: 0.9041\n",
      "Epoch 1067/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0417 - accuracy: 0.9852 - val_loss: 0.6523 - val_accuracy: 0.9041\n",
      "Epoch 1068/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0417 - accuracy: 0.9852 - val_loss: 0.6530 - val_accuracy: 0.9041\n",
      "Epoch 1069/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0416 - accuracy: 0.9852 - val_loss: 0.6535 - val_accuracy: 0.9041\n",
      "Epoch 1070/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0418 - accuracy: 0.9852 - val_loss: 0.6537 - val_accuracy: 0.9041\n",
      "Epoch 1071/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0411 - accuracy: 0.9852 - val_loss: 0.6557 - val_accuracy: 0.9041\n",
      "Epoch 1072/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0414 - accuracy: 0.9852 - val_loss: 0.6575 - val_accuracy: 0.9041\n",
      "Epoch 1073/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0412 - accuracy: 0.9852 - val_loss: 0.6567 - val_accuracy: 0.9041\n",
      "Epoch 1074/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0406 - accuracy: 0.9882 - val_loss: 0.6536 - val_accuracy: 0.9041\n",
      "Epoch 1075/2000\n",
      "338/338 [==============================] - 0s 75us/step - loss: 0.0417 - accuracy: 0.9852 - val_loss: 0.6557 - val_accuracy: 0.9041\n",
      "Epoch 1076/2000\n",
      "338/338 [==============================] - 0s 62us/step - loss: 0.0407 - accuracy: 0.9882 - val_loss: 0.6535 - val_accuracy: 0.9041\n",
      "Epoch 1077/2000\n",
      "338/338 [==============================] - 0s 74us/step - loss: 0.0420 - accuracy: 0.9852 - val_loss: 0.6549 - val_accuracy: 0.9041\n",
      "Epoch 1078/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0408 - accuracy: 0.9852 - val_loss: 0.6546 - val_accuracy: 0.9041\n",
      "Epoch 1079/2000\n",
      "338/338 [==============================] - 0s 76us/step - loss: 0.0414 - accuracy: 0.9852 - val_loss: 0.6560 - val_accuracy: 0.9041\n",
      "Epoch 1080/2000\n",
      "338/338 [==============================] - 0s 74us/step - loss: 0.0412 - accuracy: 0.9852 - val_loss: 0.6584 - val_accuracy: 0.9041\n",
      "Epoch 1081/2000\n",
      "338/338 [==============================] - 0s 74us/step - loss: 0.0412 - accuracy: 0.9852 - val_loss: 0.6605 - val_accuracy: 0.9041\n",
      "Epoch 1082/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0409 - accuracy: 0.9852 - val_loss: 0.6613 - val_accuracy: 0.9041\n",
      "Epoch 1083/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0407 - accuracy: 0.9852 - val_loss: 0.6625 - val_accuracy: 0.9041\n",
      "Epoch 1084/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0409 - accuracy: 0.9852 - val_loss: 0.6620 - val_accuracy: 0.9041\n",
      "Epoch 1085/2000\n",
      "338/338 [==============================] - 0s 84us/step - loss: 0.0411 - accuracy: 0.9852 - val_loss: 0.6627 - val_accuracy: 0.9041\n",
      "Epoch 1086/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0407 - accuracy: 0.9852 - val_loss: 0.6621 - val_accuracy: 0.9041\n",
      "Epoch 1087/2000\n",
      "338/338 [==============================] - 0s 63us/step - loss: 0.0406 - accuracy: 0.9852 - val_loss: 0.6625 - val_accuracy: 0.9041\n",
      "Epoch 1088/2000\n",
      "338/338 [==============================] - 0s 74us/step - loss: 0.0409 - accuracy: 0.9852 - val_loss: 0.6631 - val_accuracy: 0.9041\n",
      "Epoch 1089/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0405 - accuracy: 0.9882 - val_loss: 0.6621 - val_accuracy: 0.9041\n",
      "Epoch 1090/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0408 - accuracy: 0.9852 - val_loss: 0.6626 - val_accuracy: 0.9041\n",
      "Epoch 1091/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0401 - accuracy: 0.9882 - val_loss: 0.6606 - val_accuracy: 0.9041\n",
      "Epoch 1092/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0402 - accuracy: 0.9852 - val_loss: 0.6605 - val_accuracy: 0.9041\n",
      "Epoch 1093/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0404 - accuracy: 0.9852 - val_loss: 0.6618 - val_accuracy: 0.9041\n",
      "Epoch 1094/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0411 - accuracy: 0.9852 - val_loss: 0.6653 - val_accuracy: 0.9041\n",
      "Epoch 1095/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0398 - accuracy: 0.9852 - val_loss: 0.6641 - val_accuracy: 0.9041\n",
      "Epoch 1096/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0403 - accuracy: 0.9852 - val_loss: 0.6650 - val_accuracy: 0.9041\n",
      "Epoch 1097/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0403 - accuracy: 0.9882 - val_loss: 0.6663 - val_accuracy: 0.9041\n",
      "Epoch 1098/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0400 - accuracy: 0.9852 - val_loss: 0.6652 - val_accuracy: 0.9041\n",
      "Epoch 1099/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0403 - accuracy: 0.9852 - val_loss: 0.6674 - val_accuracy: 0.9041\n",
      "Epoch 1100/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0402 - accuracy: 0.9852 - val_loss: 0.6694 - val_accuracy: 0.9041\n",
      "Epoch 1101/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0399 - accuracy: 0.9882 - val_loss: 0.6684 - val_accuracy: 0.9041\n",
      "Epoch 1102/2000\n",
      "338/338 [==============================] - 0s 74us/step - loss: 0.0399 - accuracy: 0.9852 - val_loss: 0.6707 - val_accuracy: 0.9041\n",
      "Epoch 1103/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "338/338 [==============================] - 0s 65us/step - loss: 0.0404 - accuracy: 0.9852 - val_loss: 0.6706 - val_accuracy: 0.9041\n",
      "Epoch 1104/2000\n",
      "338/338 [==============================] - 0s 76us/step - loss: 0.0397 - accuracy: 0.9852 - val_loss: 0.6718 - val_accuracy: 0.9041\n",
      "Epoch 1105/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0399 - accuracy: 0.9852 - val_loss: 0.6721 - val_accuracy: 0.9041\n",
      "Epoch 1106/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0395 - accuracy: 0.9882 - val_loss: 0.6704 - val_accuracy: 0.9041\n",
      "Epoch 1107/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0396 - accuracy: 0.9882 - val_loss: 0.6692 - val_accuracy: 0.9041\n",
      "Epoch 1108/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0399 - accuracy: 0.9852 - val_loss: 0.6719 - val_accuracy: 0.9041\n",
      "Epoch 1109/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0398 - accuracy: 0.9882 - val_loss: 0.6718 - val_accuracy: 0.9041\n",
      "Epoch 1110/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0394 - accuracy: 0.9882 - val_loss: 0.6708 - val_accuracy: 0.9041\n",
      "Epoch 1111/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0400 - accuracy: 0.9882 - val_loss: 0.6723 - val_accuracy: 0.9041\n",
      "Epoch 1112/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0399 - accuracy: 0.9852 - val_loss: 0.6707 - val_accuracy: 0.9041\n",
      "Epoch 1113/2000\n",
      "338/338 [==============================] - 0s 74us/step - loss: 0.0397 - accuracy: 0.9882 - val_loss: 0.6700 - val_accuracy: 0.9041\n",
      "Epoch 1114/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0394 - accuracy: 0.9882 - val_loss: 0.6700 - val_accuracy: 0.9041\n",
      "Epoch 1115/2000\n",
      "338/338 [==============================] - 0s 75us/step - loss: 0.0395 - accuracy: 0.9882 - val_loss: 0.6709 - val_accuracy: 0.9041\n",
      "Epoch 1116/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0395 - accuracy: 0.9852 - val_loss: 0.6699 - val_accuracy: 0.9041\n",
      "Epoch 1117/2000\n",
      "338/338 [==============================] - 0s 74us/step - loss: 0.0398 - accuracy: 0.9852 - val_loss: 0.6705 - val_accuracy: 0.9041\n",
      "Epoch 1118/2000\n",
      "338/338 [==============================] - 0s 65us/step - loss: 0.0396 - accuracy: 0.9852 - val_loss: 0.6742 - val_accuracy: 0.9041\n",
      "Epoch 1119/2000\n",
      "338/338 [==============================] - 0s 82us/step - loss: 0.0395 - accuracy: 0.9882 - val_loss: 0.6754 - val_accuracy: 0.9041\n",
      "Epoch 1120/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0394 - accuracy: 0.9852 - val_loss: 0.6779 - val_accuracy: 0.9041\n",
      "Epoch 1121/2000\n",
      "338/338 [==============================] - 0s 79us/step - loss: 0.0387 - accuracy: 0.9882 - val_loss: 0.6746 - val_accuracy: 0.9041\n",
      "Epoch 1122/2000\n",
      "338/338 [==============================] - 0s 78us/step - loss: 0.0399 - accuracy: 0.9882 - val_loss: 0.6734 - val_accuracy: 0.9041\n",
      "Epoch 1123/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0389 - accuracy: 0.9882 - val_loss: 0.6726 - val_accuracy: 0.9041\n",
      "Epoch 1124/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0396 - accuracy: 0.9852 - val_loss: 0.6725 - val_accuracy: 0.9041\n",
      "Epoch 1125/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0395 - accuracy: 0.9852 - val_loss: 0.6753 - val_accuracy: 0.9041\n",
      "Epoch 1126/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0389 - accuracy: 0.9882 - val_loss: 0.6778 - val_accuracy: 0.9041\n",
      "Epoch 1127/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0388 - accuracy: 0.9882 - val_loss: 0.6769 - val_accuracy: 0.9041\n",
      "Epoch 1128/2000\n",
      "338/338 [==============================] - 0s 77us/step - loss: 0.0392 - accuracy: 0.9882 - val_loss: 0.6762 - val_accuracy: 0.9041\n",
      "Epoch 1129/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0389 - accuracy: 0.9852 - val_loss: 0.6762 - val_accuracy: 0.9041\n",
      "Epoch 1130/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0394 - accuracy: 0.9882 - val_loss: 0.6775 - val_accuracy: 0.9041\n",
      "Epoch 1131/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0393 - accuracy: 0.9882 - val_loss: 0.6789 - val_accuracy: 0.9041\n",
      "Epoch 1132/2000\n",
      "338/338 [==============================] - 0s 74us/step - loss: 0.0386 - accuracy: 0.9882 - val_loss: 0.6790 - val_accuracy: 0.9041\n",
      "Epoch 1133/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0382 - accuracy: 0.9882 - val_loss: 0.6758 - val_accuracy: 0.9041\n",
      "Epoch 1134/2000\n",
      "338/338 [==============================] - 0s 75us/step - loss: 0.0390 - accuracy: 0.9882 - val_loss: 0.6774 - val_accuracy: 0.9041\n",
      "Epoch 1135/2000\n",
      "338/338 [==============================] - 0s 62us/step - loss: 0.0388 - accuracy: 0.9852 - val_loss: 0.6820 - val_accuracy: 0.9041\n",
      "Epoch 1136/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0385 - accuracy: 0.9882 - val_loss: 0.6842 - val_accuracy: 0.9041\n",
      "Epoch 1137/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0382 - accuracy: 0.9882 - val_loss: 0.6808 - val_accuracy: 0.9041\n",
      "Epoch 1138/2000\n",
      "338/338 [==============================] - 0s 74us/step - loss: 0.0397 - accuracy: 0.9852 - val_loss: 0.6817 - val_accuracy: 0.9041\n",
      "Epoch 1139/2000\n",
      "338/338 [==============================] - 0s 80us/step - loss: 0.0384 - accuracy: 0.9882 - val_loss: 0.6840 - val_accuracy: 0.9041\n",
      "Epoch 1140/2000\n",
      "338/338 [==============================] - 0s 75us/step - loss: 0.0391 - accuracy: 0.9852 - val_loss: 0.6855 - val_accuracy: 0.9041\n",
      "Epoch 1141/2000\n",
      "338/338 [==============================] - 0s 79us/step - loss: 0.0381 - accuracy: 0.9882 - val_loss: 0.6870 - val_accuracy: 0.9041\n",
      "Epoch 1142/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0382 - accuracy: 0.9882 - val_loss: 0.6855 - val_accuracy: 0.9041\n",
      "Epoch 1143/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0385 - accuracy: 0.9852 - val_loss: 0.6878 - val_accuracy: 0.9041\n",
      "Epoch 1144/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0382 - accuracy: 0.9882 - val_loss: 0.6851 - val_accuracy: 0.9041\n",
      "Epoch 1145/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0386 - accuracy: 0.9882 - val_loss: 0.6850 - val_accuracy: 0.9041\n",
      "Epoch 1146/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0384 - accuracy: 0.9882 - val_loss: 0.6856 - val_accuracy: 0.9041\n",
      "Epoch 1147/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0384 - accuracy: 0.9882 - val_loss: 0.6871 - val_accuracy: 0.9041\n",
      "Epoch 1148/2000\n",
      "338/338 [==============================] - 0s 79us/step - loss: 0.0381 - accuracy: 0.9882 - val_loss: 0.6848 - val_accuracy: 0.9041\n",
      "Epoch 1149/2000\n",
      "338/338 [==============================] - 0s 74us/step - loss: 0.0384 - accuracy: 0.9882 - val_loss: 0.6859 - val_accuracy: 0.9041\n",
      "Epoch 1150/2000\n",
      "338/338 [==============================] - 0s 75us/step - loss: 0.0381 - accuracy: 0.9882 - val_loss: 0.6881 - val_accuracy: 0.9041\n",
      "Epoch 1151/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0385 - accuracy: 0.9882 - val_loss: 0.6887 - val_accuracy: 0.9041\n",
      "Epoch 1152/2000\n",
      "338/338 [==============================] - 0s 82us/step - loss: 0.0384 - accuracy: 0.9882 - val_loss: 0.6895 - val_accuracy: 0.9041\n",
      "Epoch 1153/2000\n",
      "338/338 [==============================] - 0s 76us/step - loss: 0.0381 - accuracy: 0.9882 - val_loss: 0.6880 - val_accuracy: 0.9041\n",
      "Epoch 1154/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0379 - accuracy: 0.9882 - val_loss: 0.6890 - val_accuracy: 0.9041\n",
      "Epoch 1155/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0381 - accuracy: 0.9882 - val_loss: 0.6899 - val_accuracy: 0.9041\n",
      "Epoch 1156/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0380 - accuracy: 0.9882 - val_loss: 0.6900 - val_accuracy: 0.9041\n",
      "Epoch 1157/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0379 - accuracy: 0.9882 - val_loss: 0.6917 - val_accuracy: 0.9041\n",
      "Epoch 1158/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "338/338 [==============================] - 0s 72us/step - loss: 0.0381 - accuracy: 0.9882 - val_loss: 0.6936 - val_accuracy: 0.9041\n",
      "Epoch 1159/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0378 - accuracy: 0.9882 - val_loss: 0.6943 - val_accuracy: 0.9041\n",
      "Epoch 1160/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0375 - accuracy: 0.9882 - val_loss: 0.6934 - val_accuracy: 0.9041\n",
      "Epoch 1161/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0379 - accuracy: 0.9882 - val_loss: 0.6946 - val_accuracy: 0.9041\n",
      "Epoch 1162/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0374 - accuracy: 0.9882 - val_loss: 0.6935 - val_accuracy: 0.9041\n",
      "Epoch 1163/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0376 - accuracy: 0.9882 - val_loss: 0.6932 - val_accuracy: 0.9041\n",
      "Epoch 1164/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0372 - accuracy: 0.9882 - val_loss: 0.6916 - val_accuracy: 0.9041\n",
      "Epoch 1165/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0380 - accuracy: 0.9882 - val_loss: 0.6920 - val_accuracy: 0.9041\n",
      "Epoch 1166/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0376 - accuracy: 0.9882 - val_loss: 0.6953 - val_accuracy: 0.9041\n",
      "Epoch 1167/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0374 - accuracy: 0.9882 - val_loss: 0.6963 - val_accuracy: 0.9041\n",
      "Epoch 1168/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0378 - accuracy: 0.9882 - val_loss: 0.6960 - val_accuracy: 0.9041\n",
      "Epoch 1169/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0375 - accuracy: 0.9882 - val_loss: 0.6964 - val_accuracy: 0.9041\n",
      "Epoch 1170/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0376 - accuracy: 0.9882 - val_loss: 0.6948 - val_accuracy: 0.9041\n",
      "Epoch 1171/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0375 - accuracy: 0.9882 - val_loss: 0.6961 - val_accuracy: 0.9041\n",
      "Epoch 1172/2000\n",
      "338/338 [==============================] - 0s 74us/step - loss: 0.0371 - accuracy: 0.9882 - val_loss: 0.6970 - val_accuracy: 0.9041\n",
      "Epoch 1173/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0373 - accuracy: 0.9882 - val_loss: 0.6963 - val_accuracy: 0.9041\n",
      "Epoch 1174/2000\n",
      "338/338 [==============================] - 0s 81us/step - loss: 0.0373 - accuracy: 0.9882 - val_loss: 0.6980 - val_accuracy: 0.9041\n",
      "Epoch 1175/2000\n",
      "338/338 [==============================] - 0s 74us/step - loss: 0.0372 - accuracy: 0.9882 - val_loss: 0.6970 - val_accuracy: 0.9041\n",
      "Epoch 1176/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0375 - accuracy: 0.9882 - val_loss: 0.6963 - val_accuracy: 0.9041\n",
      "Epoch 1177/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0372 - accuracy: 0.9882 - val_loss: 0.6973 - val_accuracy: 0.9041\n",
      "Epoch 1178/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0369 - accuracy: 0.9882 - val_loss: 0.6983 - val_accuracy: 0.9041\n",
      "Epoch 1179/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0369 - accuracy: 0.9882 - val_loss: 0.6965 - val_accuracy: 0.9041\n",
      "Epoch 1180/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0386 - accuracy: 0.9852 - val_loss: 0.6966 - val_accuracy: 0.9041\n",
      "Epoch 1181/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0371 - accuracy: 0.9882 - val_loss: 0.6975 - val_accuracy: 0.9041\n",
      "Epoch 1182/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0373 - accuracy: 0.9882 - val_loss: 0.6989 - val_accuracy: 0.9041\n",
      "Epoch 1183/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0370 - accuracy: 0.9882 - val_loss: 0.7002 - val_accuracy: 0.9041\n",
      "Epoch 1184/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0370 - accuracy: 0.9882 - val_loss: 0.7000 - val_accuracy: 0.9041\n",
      "Epoch 1185/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0368 - accuracy: 0.9882 - val_loss: 0.7003 - val_accuracy: 0.9041\n",
      "Epoch 1186/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0370 - accuracy: 0.9882 - val_loss: 0.7017 - val_accuracy: 0.9041\n",
      "Epoch 1187/2000\n",
      "338/338 [==============================] - 0s 79us/step - loss: 0.0368 - accuracy: 0.9882 - val_loss: 0.7016 - val_accuracy: 0.9041\n",
      "Epoch 1188/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0367 - accuracy: 0.9882 - val_loss: 0.7022 - val_accuracy: 0.9041\n",
      "Epoch 1189/2000\n",
      "338/338 [==============================] - 0s 78us/step - loss: 0.0370 - accuracy: 0.9882 - val_loss: 0.7043 - val_accuracy: 0.9041\n",
      "Epoch 1190/2000\n",
      "338/338 [==============================] - 0s 78us/step - loss: 0.0368 - accuracy: 0.9882 - val_loss: 0.7061 - val_accuracy: 0.9041\n",
      "Epoch 1191/2000\n",
      "338/338 [==============================] - 0s 77us/step - loss: 0.0365 - accuracy: 0.9882 - val_loss: 0.7071 - val_accuracy: 0.9041\n",
      "Epoch 1192/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0365 - accuracy: 0.9882 - val_loss: 0.7060 - val_accuracy: 0.9041\n",
      "Epoch 1193/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0362 - accuracy: 0.9882 - val_loss: 0.7049 - val_accuracy: 0.9041\n",
      "Epoch 1194/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0366 - accuracy: 0.9882 - val_loss: 0.7064 - val_accuracy: 0.9041\n",
      "Epoch 1195/2000\n",
      "338/338 [==============================] - 0s 64us/step - loss: 0.0366 - accuracy: 0.9882 - val_loss: 0.7070 - val_accuracy: 0.9041\n",
      "Epoch 1196/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0366 - accuracy: 0.9882 - val_loss: 0.7098 - val_accuracy: 0.9041\n",
      "Epoch 1197/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0356 - accuracy: 0.9882 - val_loss: 0.7039 - val_accuracy: 0.9041\n",
      "Epoch 1198/2000\n",
      "338/338 [==============================] - 0s 74us/step - loss: 0.0367 - accuracy: 0.9882 - val_loss: 0.7069 - val_accuracy: 0.9041\n",
      "Epoch 1199/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0363 - accuracy: 0.9882 - val_loss: 0.7059 - val_accuracy: 0.9041\n",
      "Epoch 1200/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0371 - accuracy: 0.9882 - val_loss: 0.7068 - val_accuracy: 0.9041\n",
      "Epoch 1201/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0363 - accuracy: 0.9882 - val_loss: 0.7086 - val_accuracy: 0.9041\n",
      "Epoch 1202/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0362 - accuracy: 0.9882 - val_loss: 0.7056 - val_accuracy: 0.9041\n",
      "Epoch 1203/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0365 - accuracy: 0.9882 - val_loss: 0.7058 - val_accuracy: 0.9041\n",
      "Epoch 1204/2000\n",
      "338/338 [==============================] - 0s 65us/step - loss: 0.0361 - accuracy: 0.9882 - val_loss: 0.7078 - val_accuracy: 0.9041\n",
      "Epoch 1205/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0362 - accuracy: 0.9882 - val_loss: 0.7079 - val_accuracy: 0.9041\n",
      "Epoch 1206/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0361 - accuracy: 0.9882 - val_loss: 0.7058 - val_accuracy: 0.9041\n",
      "Epoch 1207/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0366 - accuracy: 0.9882 - val_loss: 0.7071 - val_accuracy: 0.9041\n",
      "Epoch 1208/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0362 - accuracy: 0.9882 - val_loss: 0.7077 - val_accuracy: 0.9041\n",
      "Epoch 1209/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0361 - accuracy: 0.9882 - val_loss: 0.7095 - val_accuracy: 0.9041\n",
      "Epoch 1210/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0359 - accuracy: 0.9882 - val_loss: 0.7093 - val_accuracy: 0.9041\n",
      "Epoch 1211/2000\n",
      "338/338 [==============================] - 0s 65us/step - loss: 0.0365 - accuracy: 0.9882 - val_loss: 0.7102 - val_accuracy: 0.9041\n",
      "Epoch 1212/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0364 - accuracy: 0.9882 - val_loss: 0.7124 - val_accuracy: 0.9041\n",
      "Epoch 1213/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "338/338 [==============================] - 0s 67us/step - loss: 0.0359 - accuracy: 0.9882 - val_loss: 0.7107 - val_accuracy: 0.9041\n",
      "Epoch 1214/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0358 - accuracy: 0.9882 - val_loss: 0.7110 - val_accuracy: 0.9041\n",
      "Epoch 1215/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0370 - accuracy: 0.9882 - val_loss: 0.7105 - val_accuracy: 0.9041\n",
      "Epoch 1216/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0357 - accuracy: 0.9882 - val_loss: 0.7112 - val_accuracy: 0.9041\n",
      "Epoch 1217/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0361 - accuracy: 0.9882 - val_loss: 0.7133 - val_accuracy: 0.9041\n",
      "Epoch 1218/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0369 - accuracy: 0.9882 - val_loss: 0.7123 - val_accuracy: 0.9041\n",
      "Epoch 1219/2000\n",
      "338/338 [==============================] - 0s 74us/step - loss: 0.0354 - accuracy: 0.9882 - val_loss: 0.7117 - val_accuracy: 0.9041\n",
      "Epoch 1220/2000\n",
      "338/338 [==============================] - 0s 65us/step - loss: 0.0359 - accuracy: 0.9882 - val_loss: 0.7133 - val_accuracy: 0.9041\n",
      "Epoch 1221/2000\n",
      "338/338 [==============================] - 0s 74us/step - loss: 0.0365 - accuracy: 0.9882 - val_loss: 0.7119 - val_accuracy: 0.9041\n",
      "Epoch 1222/2000\n",
      "338/338 [==============================] - 0s 78us/step - loss: 0.0359 - accuracy: 0.9882 - val_loss: 0.7136 - val_accuracy: 0.9041\n",
      "Epoch 1223/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0358 - accuracy: 0.9882 - val_loss: 0.7149 - val_accuracy: 0.9041\n",
      "Epoch 1224/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0356 - accuracy: 0.9882 - val_loss: 0.7156 - val_accuracy: 0.9041\n",
      "Epoch 1225/2000\n",
      "338/338 [==============================] - 0s 65us/step - loss: 0.0357 - accuracy: 0.9882 - val_loss: 0.7168 - val_accuracy: 0.9041\n",
      "Epoch 1226/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0354 - accuracy: 0.9882 - val_loss: 0.7181 - val_accuracy: 0.9041\n",
      "Epoch 1227/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0354 - accuracy: 0.9882 - val_loss: 0.7206 - val_accuracy: 0.9041\n",
      "Epoch 1228/2000\n",
      "338/338 [==============================] - 0s 78us/step - loss: 0.0351 - accuracy: 0.9882 - val_loss: 0.7171 - val_accuracy: 0.9041\n",
      "Epoch 1229/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0354 - accuracy: 0.9882 - val_loss: 0.7160 - val_accuracy: 0.9041\n",
      "Epoch 1230/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0356 - accuracy: 0.9882 - val_loss: 0.7181 - val_accuracy: 0.9041\n",
      "Epoch 1231/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0352 - accuracy: 0.9882 - val_loss: 0.7180 - val_accuracy: 0.9041\n",
      "Epoch 1232/2000\n",
      "338/338 [==============================] - 0s 77us/step - loss: 0.0356 - accuracy: 0.9882 - val_loss: 0.7179 - val_accuracy: 0.9041\n",
      "Epoch 1233/2000\n",
      "338/338 [==============================] - 0s 63us/step - loss: 0.0354 - accuracy: 0.9882 - val_loss: 0.7194 - val_accuracy: 0.9041\n",
      "Epoch 1234/2000\n",
      "338/338 [==============================] - 0s 74us/step - loss: 0.0353 - accuracy: 0.9882 - val_loss: 0.7195 - val_accuracy: 0.9041\n",
      "Epoch 1235/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0356 - accuracy: 0.9882 - val_loss: 0.7202 - val_accuracy: 0.9041\n",
      "Epoch 1236/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0352 - accuracy: 0.9882 - val_loss: 0.7197 - val_accuracy: 0.9041\n",
      "Epoch 1237/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0352 - accuracy: 0.9882 - val_loss: 0.7184 - val_accuracy: 0.9041\n",
      "Epoch 1238/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0360 - accuracy: 0.9882 - val_loss: 0.7190 - val_accuracy: 0.9041\n",
      "Epoch 1239/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0352 - accuracy: 0.9882 - val_loss: 0.7193 - val_accuracy: 0.9041\n",
      "Epoch 1240/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0354 - accuracy: 0.9882 - val_loss: 0.7210 - val_accuracy: 0.9041\n",
      "Epoch 1241/2000\n",
      "338/338 [==============================] - 0s 65us/step - loss: 0.0350 - accuracy: 0.9882 - val_loss: 0.7215 - val_accuracy: 0.9041\n",
      "Epoch 1242/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0348 - accuracy: 0.9882 - val_loss: 0.7218 - val_accuracy: 0.9041\n",
      "Epoch 1243/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0352 - accuracy: 0.9882 - val_loss: 0.7223 - val_accuracy: 0.9041\n",
      "Epoch 1244/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0355 - accuracy: 0.9882 - val_loss: 0.7226 - val_accuracy: 0.9041\n",
      "Epoch 1245/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0352 - accuracy: 0.9882 - val_loss: 0.7230 - val_accuracy: 0.9041\n",
      "Epoch 1246/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0350 - accuracy: 0.9882 - val_loss: 0.7234 - val_accuracy: 0.9041\n",
      "Epoch 1247/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0352 - accuracy: 0.9882 - val_loss: 0.7246 - val_accuracy: 0.9041\n",
      "Epoch 1248/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0346 - accuracy: 0.9882 - val_loss: 0.7274 - val_accuracy: 0.9041\n",
      "Epoch 1249/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0349 - accuracy: 0.9882 - val_loss: 0.7255 - val_accuracy: 0.9041\n",
      "Epoch 1250/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0351 - accuracy: 0.9882 - val_loss: 0.7260 - val_accuracy: 0.9041\n",
      "Epoch 1251/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0349 - accuracy: 0.9882 - val_loss: 0.7266 - val_accuracy: 0.9041\n",
      "Epoch 1252/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0343 - accuracy: 0.9882 - val_loss: 0.7241 - val_accuracy: 0.9041\n",
      "Epoch 1253/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0347 - accuracy: 0.9882 - val_loss: 0.7255 - val_accuracy: 0.9041\n",
      "Epoch 1254/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0348 - accuracy: 0.9882 - val_loss: 0.7284 - val_accuracy: 0.9041\n",
      "Epoch 1255/2000\n",
      "338/338 [==============================] - 0s 65us/step - loss: 0.0346 - accuracy: 0.9882 - val_loss: 0.7297 - val_accuracy: 0.9041\n",
      "Epoch 1256/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0348 - accuracy: 0.9882 - val_loss: 0.7295 - val_accuracy: 0.9041\n",
      "Epoch 1257/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0350 - accuracy: 0.9882 - val_loss: 0.7307 - val_accuracy: 0.9041\n",
      "Epoch 1258/2000\n",
      "338/338 [==============================] - 0s 65us/step - loss: 0.0350 - accuracy: 0.9882 - val_loss: 0.7300 - val_accuracy: 0.9041\n",
      "Epoch 1259/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0345 - accuracy: 0.9882 - val_loss: 0.7282 - val_accuracy: 0.9041\n",
      "Epoch 1260/2000\n",
      "338/338 [==============================] - 0s 63us/step - loss: 0.0344 - accuracy: 0.9882 - val_loss: 0.7288 - val_accuracy: 0.9041\n",
      "Epoch 1261/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0351 - accuracy: 0.9882 - val_loss: 0.7296 - val_accuracy: 0.9041\n",
      "Epoch 1262/2000\n",
      "338/338 [==============================] - 0s 78us/step - loss: 0.0347 - accuracy: 0.9882 - val_loss: 0.7307 - val_accuracy: 0.9041\n",
      "Epoch 1263/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0346 - accuracy: 0.9882 - val_loss: 0.7310 - val_accuracy: 0.9041\n",
      "Epoch 1264/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0344 - accuracy: 0.9882 - val_loss: 0.7334 - val_accuracy: 0.9041\n",
      "Epoch 1265/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0343 - accuracy: 0.9882 - val_loss: 0.7300 - val_accuracy: 0.9041\n",
      "Epoch 1266/2000\n",
      "338/338 [==============================] - 0s 75us/step - loss: 0.0348 - accuracy: 0.9882 - val_loss: 0.7300 - val_accuracy: 0.9041\n",
      "Epoch 1267/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0347 - accuracy: 0.9882 - val_loss: 0.7301 - val_accuracy: 0.9041\n",
      "Epoch 1268/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "338/338 [==============================] - 0s 68us/step - loss: 0.0346 - accuracy: 0.9882 - val_loss: 0.7314 - val_accuracy: 0.9041\n",
      "Epoch 1269/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0347 - accuracy: 0.9882 - val_loss: 0.7322 - val_accuracy: 0.9041\n",
      "Epoch 1270/2000\n",
      "338/338 [==============================] - 0s 64us/step - loss: 0.0341 - accuracy: 0.9882 - val_loss: 0.7307 - val_accuracy: 0.9041\n",
      "Epoch 1271/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0345 - accuracy: 0.9882 - val_loss: 0.7317 - val_accuracy: 0.9041\n",
      "Epoch 1272/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0342 - accuracy: 0.9882 - val_loss: 0.7287 - val_accuracy: 0.9041\n",
      "Epoch 1273/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0345 - accuracy: 0.9882 - val_loss: 0.7311 - val_accuracy: 0.9041\n",
      "Epoch 1274/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0344 - accuracy: 0.9882 - val_loss: 0.7345 - val_accuracy: 0.9041\n",
      "Epoch 1275/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0343 - accuracy: 0.9882 - val_loss: 0.7347 - val_accuracy: 0.9041\n",
      "Epoch 1276/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0347 - accuracy: 0.9882 - val_loss: 0.7336 - val_accuracy: 0.9041\n",
      "Epoch 1277/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0339 - accuracy: 0.9882 - val_loss: 0.7341 - val_accuracy: 0.9041\n",
      "Epoch 1278/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0343 - accuracy: 0.9882 - val_loss: 0.7341 - val_accuracy: 0.9041\n",
      "Epoch 1279/2000\n",
      "338/338 [==============================] - 0s 74us/step - loss: 0.0343 - accuracy: 0.9882 - val_loss: 0.7357 - val_accuracy: 0.9041\n",
      "Epoch 1280/2000\n",
      "338/338 [==============================] - 0s 65us/step - loss: 0.0336 - accuracy: 0.9882 - val_loss: 0.7330 - val_accuracy: 0.9041\n",
      "Epoch 1281/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0341 - accuracy: 0.9882 - val_loss: 0.7323 - val_accuracy: 0.9041\n",
      "Epoch 1282/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0345 - accuracy: 0.9882 - val_loss: 0.7340 - val_accuracy: 0.9041\n",
      "Epoch 1283/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0339 - accuracy: 0.9882 - val_loss: 0.7364 - val_accuracy: 0.9041\n",
      "Epoch 1284/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0341 - accuracy: 0.9882 - val_loss: 0.7365 - val_accuracy: 0.9041\n",
      "Epoch 1285/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0340 - accuracy: 0.9882 - val_loss: 0.7352 - val_accuracy: 0.9041\n",
      "Epoch 1286/2000\n",
      "338/338 [==============================] - 0s 64us/step - loss: 0.0341 - accuracy: 0.9882 - val_loss: 0.7369 - val_accuracy: 0.9041\n",
      "Epoch 1287/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0336 - accuracy: 0.9882 - val_loss: 0.7369 - val_accuracy: 0.9041\n",
      "Epoch 1288/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0342 - accuracy: 0.9882 - val_loss: 0.7394 - val_accuracy: 0.9041\n",
      "Epoch 1289/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0338 - accuracy: 0.9882 - val_loss: 0.7372 - val_accuracy: 0.9041\n",
      "Epoch 1290/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0337 - accuracy: 0.9882 - val_loss: 0.7376 - val_accuracy: 0.9041\n",
      "Epoch 1291/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0337 - accuracy: 0.9882 - val_loss: 0.7398 - val_accuracy: 0.9041\n",
      "Epoch 1292/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0335 - accuracy: 0.9882 - val_loss: 0.7389 - val_accuracy: 0.9041\n",
      "Epoch 1293/2000\n",
      "338/338 [==============================] - 0s 61us/step - loss: 0.0339 - accuracy: 0.9882 - val_loss: 0.7400 - val_accuracy: 0.9041\n",
      "Epoch 1294/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0343 - accuracy: 0.9882 - val_loss: 0.7417 - val_accuracy: 0.9041\n",
      "Epoch 1295/2000\n",
      "338/338 [==============================] - 0s 65us/step - loss: 0.0339 - accuracy: 0.9882 - val_loss: 0.7440 - val_accuracy: 0.9041\n",
      "Epoch 1296/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0331 - accuracy: 0.9882 - val_loss: 0.7411 - val_accuracy: 0.9041\n",
      "Epoch 1297/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0334 - accuracy: 0.9882 - val_loss: 0.7442 - val_accuracy: 0.9041\n",
      "Epoch 1298/2000\n",
      "338/338 [==============================] - 0s 65us/step - loss: 0.0339 - accuracy: 0.9882 - val_loss: 0.7424 - val_accuracy: 0.9041\n",
      "Epoch 1299/2000\n",
      "338/338 [==============================] - 0s 65us/step - loss: 0.0337 - accuracy: 0.9882 - val_loss: 0.7441 - val_accuracy: 0.9041\n",
      "Epoch 1300/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0340 - accuracy: 0.9882 - val_loss: 0.7435 - val_accuracy: 0.9041\n",
      "Epoch 1301/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0332 - accuracy: 0.9882 - val_loss: 0.7418 - val_accuracy: 0.9041\n",
      "Epoch 1302/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0337 - accuracy: 0.9882 - val_loss: 0.7412 - val_accuracy: 0.9041\n",
      "Epoch 1303/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0337 - accuracy: 0.9882 - val_loss: 0.7428 - val_accuracy: 0.9041\n",
      "Epoch 1304/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0337 - accuracy: 0.9882 - val_loss: 0.7447 - val_accuracy: 0.9041\n",
      "Epoch 1305/2000\n",
      "338/338 [==============================] - 0s 64us/step - loss: 0.0334 - accuracy: 0.9882 - val_loss: 0.7464 - val_accuracy: 0.9041\n",
      "Epoch 1306/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0336 - accuracy: 0.9882 - val_loss: 0.7471 - val_accuracy: 0.9041\n",
      "Epoch 1307/2000\n",
      "338/338 [==============================] - 0s 62us/step - loss: 0.0334 - accuracy: 0.9882 - val_loss: 0.7447 - val_accuracy: 0.9041\n",
      "Epoch 1308/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0332 - accuracy: 0.9882 - val_loss: 0.7468 - val_accuracy: 0.9041\n",
      "Epoch 1309/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0331 - accuracy: 0.9882 - val_loss: 0.7428 - val_accuracy: 0.9041\n",
      "Epoch 1310/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0337 - accuracy: 0.9882 - val_loss: 0.7420 - val_accuracy: 0.9041\n",
      "Epoch 1311/2000\n",
      "338/338 [==============================] - 0s 65us/step - loss: 0.0330 - accuracy: 0.9882 - val_loss: 0.7450 - val_accuracy: 0.9041\n",
      "Epoch 1312/2000\n",
      "338/338 [==============================] - 0s 65us/step - loss: 0.0335 - accuracy: 0.9882 - val_loss: 0.7448 - val_accuracy: 0.9041\n",
      "Epoch 1313/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0329 - accuracy: 0.9882 - val_loss: 0.7425 - val_accuracy: 0.9041\n",
      "Epoch 1314/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0336 - accuracy: 0.9882 - val_loss: 0.7436 - val_accuracy: 0.9041\n",
      "Epoch 1315/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0335 - accuracy: 0.9882 - val_loss: 0.7446 - val_accuracy: 0.9041\n",
      "Epoch 1316/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0334 - accuracy: 0.9882 - val_loss: 0.7449 - val_accuracy: 0.9041\n",
      "Epoch 1317/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0335 - accuracy: 0.9882 - val_loss: 0.7464 - val_accuracy: 0.9041\n",
      "Epoch 1318/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0330 - accuracy: 0.9882 - val_loss: 0.7469 - val_accuracy: 0.9041\n",
      "Epoch 1319/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0333 - accuracy: 0.9882 - val_loss: 0.7497 - val_accuracy: 0.9041\n",
      "Epoch 1320/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0331 - accuracy: 0.9882 - val_loss: 0.7500 - val_accuracy: 0.9041\n",
      "Epoch 1321/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0332 - accuracy: 0.9882 - val_loss: 0.7484 - val_accuracy: 0.9041\n",
      "Epoch 1322/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0328 - accuracy: 0.9882 - val_loss: 0.7469 - val_accuracy: 0.9041\n",
      "Epoch 1323/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "338/338 [==============================] - 0s 74us/step - loss: 0.0331 - accuracy: 0.9882 - val_loss: 0.7456 - val_accuracy: 0.9041\n",
      "Epoch 1324/2000\n",
      "338/338 [==============================] - 0s 63us/step - loss: 0.0331 - accuracy: 0.9882 - val_loss: 0.7469 - val_accuracy: 0.9041\n",
      "Epoch 1325/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0332 - accuracy: 0.9882 - val_loss: 0.7478 - val_accuracy: 0.9041\n",
      "Epoch 1326/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0330 - accuracy: 0.9882 - val_loss: 0.7498 - val_accuracy: 0.9041\n",
      "Epoch 1327/2000\n",
      "338/338 [==============================] - 0s 65us/step - loss: 0.0336 - accuracy: 0.9882 - val_loss: 0.7517 - val_accuracy: 0.9041\n",
      "Epoch 1328/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0331 - accuracy: 0.9882 - val_loss: 0.7531 - val_accuracy: 0.9041\n",
      "Epoch 1329/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0331 - accuracy: 0.9882 - val_loss: 0.7521 - val_accuracy: 0.9041\n",
      "Epoch 1330/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0329 - accuracy: 0.9882 - val_loss: 0.7536 - val_accuracy: 0.9041\n",
      "Epoch 1331/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0337 - accuracy: 0.9882 - val_loss: 0.7558 - val_accuracy: 0.9041\n",
      "Epoch 1332/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0327 - accuracy: 0.9882 - val_loss: 0.7554 - val_accuracy: 0.9041\n",
      "Epoch 1333/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0330 - accuracy: 0.9882 - val_loss: 0.7602 - val_accuracy: 0.9041\n",
      "Epoch 1334/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0324 - accuracy: 0.9882 - val_loss: 0.7602 - val_accuracy: 0.9041\n",
      "Epoch 1335/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0329 - accuracy: 0.9882 - val_loss: 0.7592 - val_accuracy: 0.9041\n",
      "Epoch 1336/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0324 - accuracy: 0.9882 - val_loss: 0.7550 - val_accuracy: 0.9041\n",
      "Epoch 1337/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0330 - accuracy: 0.9882 - val_loss: 0.7558 - val_accuracy: 0.9041\n",
      "Epoch 1338/2000\n",
      "338/338 [==============================] - 0s 74us/step - loss: 0.0329 - accuracy: 0.9882 - val_loss: 0.7567 - val_accuracy: 0.9041\n",
      "Epoch 1339/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0330 - accuracy: 0.9882 - val_loss: 0.7562 - val_accuracy: 0.9041\n",
      "Epoch 1340/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0327 - accuracy: 0.9882 - val_loss: 0.7585 - val_accuracy: 0.9041\n",
      "Epoch 1341/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0329 - accuracy: 0.9882 - val_loss: 0.7590 - val_accuracy: 0.9041\n",
      "Epoch 1342/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0326 - accuracy: 0.9882 - val_loss: 0.7575 - val_accuracy: 0.9041\n",
      "Epoch 1343/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0328 - accuracy: 0.9882 - val_loss: 0.7584 - val_accuracy: 0.9041\n",
      "Epoch 1344/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0326 - accuracy: 0.9882 - val_loss: 0.7581 - val_accuracy: 0.9041\n",
      "Epoch 1345/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0325 - accuracy: 0.9882 - val_loss: 0.7573 - val_accuracy: 0.9041\n",
      "Epoch 1346/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0325 - accuracy: 0.9882 - val_loss: 0.7602 - val_accuracy: 0.9041\n",
      "Epoch 1347/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0322 - accuracy: 0.9882 - val_loss: 0.7594 - val_accuracy: 0.9041\n",
      "Epoch 1348/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0325 - accuracy: 0.9882 - val_loss: 0.7589 - val_accuracy: 0.9041\n",
      "Epoch 1349/2000\n",
      "338/338 [==============================] - 0s 76us/step - loss: 0.0325 - accuracy: 0.9882 - val_loss: 0.7580 - val_accuracy: 0.9041\n",
      "Epoch 1350/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0327 - accuracy: 0.9882 - val_loss: 0.7569 - val_accuracy: 0.9041\n",
      "Epoch 1351/2000\n",
      "338/338 [==============================] - 0s 77us/step - loss: 0.0323 - accuracy: 0.9882 - val_loss: 0.7560 - val_accuracy: 0.9041\n",
      "Epoch 1352/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0327 - accuracy: 0.9882 - val_loss: 0.7552 - val_accuracy: 0.9041\n",
      "Epoch 1353/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0323 - accuracy: 0.9882 - val_loss: 0.7568 - val_accuracy: 0.9041\n",
      "Epoch 1354/2000\n",
      "338/338 [==============================] - 0s 75us/step - loss: 0.0324 - accuracy: 0.9882 - val_loss: 0.7587 - val_accuracy: 0.9041\n",
      "Epoch 1355/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0331 - accuracy: 0.9882 - val_loss: 0.7600 - val_accuracy: 0.9041\n",
      "Epoch 1356/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0320 - accuracy: 0.9882 - val_loss: 0.7592 - val_accuracy: 0.9041\n",
      "Epoch 1357/2000\n",
      "338/338 [==============================] - 0s 64us/step - loss: 0.0322 - accuracy: 0.9882 - val_loss: 0.7598 - val_accuracy: 0.9041\n",
      "Epoch 1358/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0325 - accuracy: 0.9882 - val_loss: 0.7595 - val_accuracy: 0.9041\n",
      "Epoch 1359/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0324 - accuracy: 0.9882 - val_loss: 0.7589 - val_accuracy: 0.9041\n",
      "Epoch 1360/2000\n",
      "338/338 [==============================] - 0s 74us/step - loss: 0.0323 - accuracy: 0.9882 - val_loss: 0.7586 - val_accuracy: 0.9041\n",
      "Epoch 1361/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0323 - accuracy: 0.9882 - val_loss: 0.7586 - val_accuracy: 0.9041\n",
      "Epoch 1362/2000\n",
      "338/338 [==============================] - 0s 75us/step - loss: 0.0321 - accuracy: 0.9882 - val_loss: 0.7594 - val_accuracy: 0.9041\n",
      "Epoch 1363/2000\n",
      "338/338 [==============================] - 0s 65us/step - loss: 0.0323 - accuracy: 0.9882 - val_loss: 0.7610 - val_accuracy: 0.9041\n",
      "Epoch 1364/2000\n",
      "338/338 [==============================] - 0s 76us/step - loss: 0.0322 - accuracy: 0.9882 - val_loss: 0.7624 - val_accuracy: 0.9041\n",
      "Epoch 1365/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0323 - accuracy: 0.9882 - val_loss: 0.7618 - val_accuracy: 0.9041\n",
      "Epoch 1366/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0320 - accuracy: 0.9882 - val_loss: 0.7626 - val_accuracy: 0.9041\n",
      "Epoch 1367/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0324 - accuracy: 0.9882 - val_loss: 0.7612 - val_accuracy: 0.9041\n",
      "Epoch 1368/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0325 - accuracy: 0.9882 - val_loss: 0.7617 - val_accuracy: 0.9041\n",
      "Epoch 1369/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0319 - accuracy: 0.9882 - val_loss: 0.7612 - val_accuracy: 0.9041\n",
      "Epoch 1370/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0320 - accuracy: 0.9882 - val_loss: 0.7615 - val_accuracy: 0.9041\n",
      "Epoch 1371/2000\n",
      "338/338 [==============================] - 0s 75us/step - loss: 0.0319 - accuracy: 0.9882 - val_loss: 0.7631 - val_accuracy: 0.9041\n",
      "Epoch 1372/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0322 - accuracy: 0.9882 - val_loss: 0.7634 - val_accuracy: 0.9041\n",
      "Epoch 1373/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0317 - accuracy: 0.9882 - val_loss: 0.7628 - val_accuracy: 0.9041\n",
      "Epoch 1374/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0318 - accuracy: 0.9882 - val_loss: 0.7644 - val_accuracy: 0.9041\n",
      "Epoch 1375/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0318 - accuracy: 0.9882 - val_loss: 0.7682 - val_accuracy: 0.9041\n",
      "Epoch 1376/2000\n",
      "338/338 [==============================] - 0s 78us/step - loss: 0.0324 - accuracy: 0.9882 - val_loss: 0.7678 - val_accuracy: 0.9041\n",
      "Epoch 1377/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0321 - accuracy: 0.9882 - val_loss: 0.7672 - val_accuracy: 0.9041\n",
      "Epoch 1378/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "338/338 [==============================] - 0s 65us/step - loss: 0.0319 - accuracy: 0.9882 - val_loss: 0.7675 - val_accuracy: 0.9041\n",
      "Epoch 1379/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0318 - accuracy: 0.9882 - val_loss: 0.7707 - val_accuracy: 0.9041\n",
      "Epoch 1380/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0318 - accuracy: 0.9882 - val_loss: 0.7708 - val_accuracy: 0.9041\n",
      "Epoch 1381/2000\n",
      "338/338 [==============================] - 0s 80us/step - loss: 0.0317 - accuracy: 0.9882 - val_loss: 0.7716 - val_accuracy: 0.9041\n",
      "Epoch 1382/2000\n",
      "338/338 [==============================] - 0s 64us/step - loss: 0.0315 - accuracy: 0.9882 - val_loss: 0.7690 - val_accuracy: 0.9041\n",
      "Epoch 1383/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0318 - accuracy: 0.9882 - val_loss: 0.7712 - val_accuracy: 0.9041\n",
      "Epoch 1384/2000\n",
      "338/338 [==============================] - 0s 65us/step - loss: 0.0317 - accuracy: 0.9882 - val_loss: 0.7701 - val_accuracy: 0.9041\n",
      "Epoch 1385/2000\n",
      "338/338 [==============================] - 0s 76us/step - loss: 0.0315 - accuracy: 0.9882 - val_loss: 0.7669 - val_accuracy: 0.9041\n",
      "Epoch 1386/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0324 - accuracy: 0.9882 - val_loss: 0.7676 - val_accuracy: 0.9041\n",
      "Epoch 1387/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0318 - accuracy: 0.9882 - val_loss: 0.7687 - val_accuracy: 0.9041\n",
      "Epoch 1388/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0317 - accuracy: 0.9882 - val_loss: 0.7679 - val_accuracy: 0.9041\n",
      "Epoch 1389/2000\n",
      "338/338 [==============================] - 0s 74us/step - loss: 0.0321 - accuracy: 0.9882 - val_loss: 0.7665 - val_accuracy: 0.9041\n",
      "Epoch 1390/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0313 - accuracy: 0.9882 - val_loss: 0.7672 - val_accuracy: 0.9041\n",
      "Epoch 1391/2000\n",
      "338/338 [==============================] - 0s 74us/step - loss: 0.0313 - accuracy: 0.9882 - val_loss: 0.7662 - val_accuracy: 0.9041\n",
      "Epoch 1392/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0315 - accuracy: 0.9882 - val_loss: 0.7669 - val_accuracy: 0.9041\n",
      "Epoch 1393/2000\n",
      "338/338 [==============================] - 0s 75us/step - loss: 0.0316 - accuracy: 0.9882 - val_loss: 0.7690 - val_accuracy: 0.9041\n",
      "Epoch 1394/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0319 - accuracy: 0.9882 - val_loss: 0.7704 - val_accuracy: 0.9041\n",
      "Epoch 1395/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0318 - accuracy: 0.9882 - val_loss: 0.7701 - val_accuracy: 0.9041\n",
      "Epoch 1396/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0312 - accuracy: 0.9882 - val_loss: 0.7676 - val_accuracy: 0.9041\n",
      "Epoch 1397/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0317 - accuracy: 0.9882 - val_loss: 0.7671 - val_accuracy: 0.9041\n",
      "Epoch 1398/2000\n",
      "338/338 [==============================] - 0s 65us/step - loss: 0.0312 - accuracy: 0.9882 - val_loss: 0.7679 - val_accuracy: 0.9041\n",
      "Epoch 1399/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0318 - accuracy: 0.9882 - val_loss: 0.7683 - val_accuracy: 0.9041\n",
      "Epoch 1400/2000\n",
      "338/338 [==============================] - 0s 64us/step - loss: 0.0316 - accuracy: 0.9882 - val_loss: 0.7688 - val_accuracy: 0.9041\n",
      "Epoch 1401/2000\n",
      "338/338 [==============================] - 0s 79us/step - loss: 0.0314 - accuracy: 0.9882 - val_loss: 0.7692 - val_accuracy: 0.9041\n",
      "Epoch 1402/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0317 - accuracy: 0.9882 - val_loss: 0.7705 - val_accuracy: 0.9041\n",
      "Epoch 1403/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0312 - accuracy: 0.9882 - val_loss: 0.7692 - val_accuracy: 0.9041\n",
      "Epoch 1404/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0319 - accuracy: 0.9882 - val_loss: 0.7687 - val_accuracy: 0.9041\n",
      "Epoch 1405/2000\n",
      "338/338 [==============================] - 0s 82us/step - loss: 0.0312 - accuracy: 0.9882 - val_loss: 0.7690 - val_accuracy: 0.9041\n",
      "Epoch 1406/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0318 - accuracy: 0.9882 - val_loss: 0.7717 - val_accuracy: 0.9041\n",
      "Epoch 1407/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0313 - accuracy: 0.9882 - val_loss: 0.7709 - val_accuracy: 0.9041\n",
      "Epoch 1408/2000\n",
      "338/338 [==============================] - 0s 65us/step - loss: 0.0313 - accuracy: 0.9882 - val_loss: 0.7710 - val_accuracy: 0.9041\n",
      "Epoch 1409/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0317 - accuracy: 0.9882 - val_loss: 0.7714 - val_accuracy: 0.9041\n",
      "Epoch 1410/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0311 - accuracy: 0.9882 - val_loss: 0.7714 - val_accuracy: 0.9041\n",
      "Epoch 1411/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0314 - accuracy: 0.9882 - val_loss: 0.7735 - val_accuracy: 0.9041\n",
      "Epoch 1412/2000\n",
      "338/338 [==============================] - 0s 64us/step - loss: 0.0312 - accuracy: 0.9882 - val_loss: 0.7761 - val_accuracy: 0.9041\n",
      "Epoch 1413/2000\n",
      "338/338 [==============================] - 0s 74us/step - loss: 0.0310 - accuracy: 0.9882 - val_loss: 0.7795 - val_accuracy: 0.9041\n",
      "Epoch 1414/2000\n",
      "338/338 [==============================] - 0s 65us/step - loss: 0.0314 - accuracy: 0.9882 - val_loss: 0.7765 - val_accuracy: 0.9041\n",
      "Epoch 1415/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0309 - accuracy: 0.9882 - val_loss: 0.7769 - val_accuracy: 0.9041\n",
      "Epoch 1416/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0313 - accuracy: 0.9882 - val_loss: 0.7748 - val_accuracy: 0.9041\n",
      "Epoch 1417/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0311 - accuracy: 0.9882 - val_loss: 0.7742 - val_accuracy: 0.9041\n",
      "Epoch 1418/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0312 - accuracy: 0.9882 - val_loss: 0.7736 - val_accuracy: 0.9041\n",
      "Epoch 1419/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0317 - accuracy: 0.9882 - val_loss: 0.7743 - val_accuracy: 0.9041\n",
      "Epoch 1420/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0311 - accuracy: 0.9882 - val_loss: 0.7761 - val_accuracy: 0.9041\n",
      "Epoch 1421/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0314 - accuracy: 0.9882 - val_loss: 0.7760 - val_accuracy: 0.9041\n",
      "Epoch 1422/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0307 - accuracy: 0.9882 - val_loss: 0.7746 - val_accuracy: 0.9041\n",
      "Epoch 1423/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0313 - accuracy: 0.9882 - val_loss: 0.7759 - val_accuracy: 0.9041\n",
      "Epoch 1424/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0309 - accuracy: 0.9882 - val_loss: 0.7753 - val_accuracy: 0.9041\n",
      "Epoch 1425/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0313 - accuracy: 0.9882 - val_loss: 0.7759 - val_accuracy: 0.9041\n",
      "Epoch 1426/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0317 - accuracy: 0.9882 - val_loss: 0.7763 - val_accuracy: 0.9041\n",
      "Epoch 1427/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0309 - accuracy: 0.9882 - val_loss: 0.7772 - val_accuracy: 0.9041\n",
      "Epoch 1428/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0314 - accuracy: 0.9882 - val_loss: 0.7768 - val_accuracy: 0.9041\n",
      "Epoch 1429/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0306 - accuracy: 0.9882 - val_loss: 0.7756 - val_accuracy: 0.9041\n",
      "Epoch 1430/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0316 - accuracy: 0.9882 - val_loss: 0.7777 - val_accuracy: 0.9041\n",
      "Epoch 1431/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0313 - accuracy: 0.9882 - val_loss: 0.7785 - val_accuracy: 0.9041\n",
      "Epoch 1432/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0308 - accuracy: 0.9882 - val_loss: 0.7778 - val_accuracy: 0.9041\n",
      "Epoch 1433/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "338/338 [==============================] - 0s 83us/step - loss: 0.0310 - accuracy: 0.9882 - val_loss: 0.7782 - val_accuracy: 0.9041\n",
      "Epoch 1434/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0309 - accuracy: 0.9882 - val_loss: 0.7775 - val_accuracy: 0.9041\n",
      "Epoch 1435/2000\n",
      "338/338 [==============================] - 0s 75us/step - loss: 0.0310 - accuracy: 0.9882 - val_loss: 0.7794 - val_accuracy: 0.9041\n",
      "Epoch 1436/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0308 - accuracy: 0.9882 - val_loss: 0.7782 - val_accuracy: 0.9041\n",
      "Epoch 1437/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0310 - accuracy: 0.9882 - val_loss: 0.7784 - val_accuracy: 0.9041\n",
      "Epoch 1438/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0307 - accuracy: 0.9882 - val_loss: 0.7807 - val_accuracy: 0.9041\n",
      "Epoch 1439/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0308 - accuracy: 0.9882 - val_loss: 0.7821 - val_accuracy: 0.9041\n",
      "Epoch 1440/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0303 - accuracy: 0.9882 - val_loss: 0.7780 - val_accuracy: 0.9041\n",
      "Epoch 1441/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0308 - accuracy: 0.9882 - val_loss: 0.7783 - val_accuracy: 0.9041\n",
      "Epoch 1442/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0307 - accuracy: 0.9882 - val_loss: 0.7774 - val_accuracy: 0.9041\n",
      "Epoch 1443/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0308 - accuracy: 0.9882 - val_loss: 0.7800 - val_accuracy: 0.9041\n",
      "Epoch 1444/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0311 - accuracy: 0.9882 - val_loss: 0.7805 - val_accuracy: 0.9041\n",
      "Epoch 1445/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0309 - accuracy: 0.9882 - val_loss: 0.7816 - val_accuracy: 0.9041\n",
      "Epoch 1446/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0306 - accuracy: 0.9882 - val_loss: 0.7813 - val_accuracy: 0.9041\n",
      "Epoch 1447/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0307 - accuracy: 0.9882 - val_loss: 0.7808 - val_accuracy: 0.9041\n",
      "Epoch 1448/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0306 - accuracy: 0.9882 - val_loss: 0.7788 - val_accuracy: 0.9041\n",
      "Epoch 1449/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0306 - accuracy: 0.9882 - val_loss: 0.7775 - val_accuracy: 0.9041\n",
      "Epoch 1450/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0305 - accuracy: 0.9882 - val_loss: 0.7769 - val_accuracy: 0.9041\n",
      "Epoch 1451/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0309 - accuracy: 0.9882 - val_loss: 0.7783 - val_accuracy: 0.9041\n",
      "Epoch 1452/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0305 - accuracy: 0.9882 - val_loss: 0.7778 - val_accuracy: 0.9041\n",
      "Epoch 1453/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0307 - accuracy: 0.9882 - val_loss: 0.7786 - val_accuracy: 0.9041\n",
      "Epoch 1454/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0310 - accuracy: 0.9882 - val_loss: 0.7785 - val_accuracy: 0.9041\n",
      "Epoch 1455/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0303 - accuracy: 0.9882 - val_loss: 0.7789 - val_accuracy: 0.9041\n",
      "Epoch 1456/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0307 - accuracy: 0.9882 - val_loss: 0.7802 - val_accuracy: 0.9041\n",
      "Epoch 1457/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0305 - accuracy: 0.9882 - val_loss: 0.7798 - val_accuracy: 0.9041\n",
      "Epoch 1458/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0309 - accuracy: 0.9882 - val_loss: 0.7818 - val_accuracy: 0.9041\n",
      "Epoch 1459/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0305 - accuracy: 0.9882 - val_loss: 0.7835 - val_accuracy: 0.9041\n",
      "Epoch 1460/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0304 - accuracy: 0.9882 - val_loss: 0.7818 - val_accuracy: 0.9041\n",
      "Epoch 1461/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0305 - accuracy: 0.9882 - val_loss: 0.7826 - val_accuracy: 0.9041\n",
      "Epoch 1462/2000\n",
      "338/338 [==============================] - 0s 75us/step - loss: 0.0304 - accuracy: 0.9882 - val_loss: 0.7829 - val_accuracy: 0.9041\n",
      "Epoch 1463/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0305 - accuracy: 0.9882 - val_loss: 0.7828 - val_accuracy: 0.9041\n",
      "Epoch 1464/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0306 - accuracy: 0.9882 - val_loss: 0.7821 - val_accuracy: 0.9041\n",
      "Epoch 1465/2000\n",
      "338/338 [==============================] - 0s 76us/step - loss: 0.0303 - accuracy: 0.9882 - val_loss: 0.7828 - val_accuracy: 0.9041\n",
      "Epoch 1466/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0308 - accuracy: 0.9882 - val_loss: 0.7818 - val_accuracy: 0.9041\n",
      "Epoch 1467/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0307 - accuracy: 0.9882 - val_loss: 0.7820 - val_accuracy: 0.9041\n",
      "Epoch 1468/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0301 - accuracy: 0.9882 - val_loss: 0.7831 - val_accuracy: 0.9041\n",
      "Epoch 1469/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0305 - accuracy: 0.9882 - val_loss: 0.7841 - val_accuracy: 0.9041\n",
      "Epoch 1470/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0305 - accuracy: 0.9882 - val_loss: 0.7846 - val_accuracy: 0.9041\n",
      "Epoch 1471/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0303 - accuracy: 0.9882 - val_loss: 0.7855 - val_accuracy: 0.9041\n",
      "Epoch 1472/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0298 - accuracy: 0.9882 - val_loss: 0.7831 - val_accuracy: 0.9041\n",
      "Epoch 1473/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0305 - accuracy: 0.9882 - val_loss: 0.7849 - val_accuracy: 0.9041\n",
      "Epoch 1474/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0311 - accuracy: 0.9882 - val_loss: 0.7861 - val_accuracy: 0.9041\n",
      "Epoch 1475/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0301 - accuracy: 0.9882 - val_loss: 0.7863 - val_accuracy: 0.9041\n",
      "Epoch 1476/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0301 - accuracy: 0.9882 - val_loss: 0.7867 - val_accuracy: 0.9041\n",
      "Epoch 1477/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0301 - accuracy: 0.9882 - val_loss: 0.7849 - val_accuracy: 0.9041\n",
      "Epoch 1478/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0304 - accuracy: 0.9882 - val_loss: 0.7868 - val_accuracy: 0.9041\n",
      "Epoch 1479/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0302 - accuracy: 0.9882 - val_loss: 0.7860 - val_accuracy: 0.9041\n",
      "Epoch 1480/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0301 - accuracy: 0.9882 - val_loss: 0.7855 - val_accuracy: 0.9041\n",
      "Epoch 1481/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0301 - accuracy: 0.9882 - val_loss: 0.7858 - val_accuracy: 0.9041\n",
      "Epoch 1482/2000\n",
      "338/338 [==============================] - 0s 77us/step - loss: 0.0304 - accuracy: 0.9882 - val_loss: 0.7850 - val_accuracy: 0.9041\n",
      "Epoch 1483/2000\n",
      "338/338 [==============================] - 0s 74us/step - loss: 0.0305 - accuracy: 0.9882 - val_loss: 0.7857 - val_accuracy: 0.9041\n",
      "Epoch 1484/2000\n",
      "338/338 [==============================] - 0s 78us/step - loss: 0.0298 - accuracy: 0.9882 - val_loss: 0.7838 - val_accuracy: 0.9041\n",
      "Epoch 1485/2000\n",
      "338/338 [==============================] - 0s 76us/step - loss: 0.0305 - accuracy: 0.9882 - val_loss: 0.7862 - val_accuracy: 0.9041\n",
      "Epoch 1486/2000\n",
      "338/338 [==============================] - 0s 76us/step - loss: 0.0301 - accuracy: 0.9882 - val_loss: 0.7857 - val_accuracy: 0.9041\n",
      "Epoch 1487/2000\n",
      "338/338 [==============================] - 0s 74us/step - loss: 0.0299 - accuracy: 0.9882 - val_loss: 0.7866 - val_accuracy: 0.9041\n",
      "Epoch 1488/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "338/338 [==============================] - 0s 67us/step - loss: 0.0300 - accuracy: 0.9882 - val_loss: 0.7860 - val_accuracy: 0.9041\n",
      "Epoch 1489/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0300 - accuracy: 0.9882 - val_loss: 0.7880 - val_accuracy: 0.9041\n",
      "Epoch 1490/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0302 - accuracy: 0.9882 - val_loss: 0.7891 - val_accuracy: 0.9041\n",
      "Epoch 1491/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0301 - accuracy: 0.9882 - val_loss: 0.7893 - val_accuracy: 0.9041\n",
      "Epoch 1492/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0299 - accuracy: 0.9882 - val_loss: 0.7902 - val_accuracy: 0.9041\n",
      "Epoch 1493/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0302 - accuracy: 0.9882 - val_loss: 0.7897 - val_accuracy: 0.9041\n",
      "Epoch 1494/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0298 - accuracy: 0.9882 - val_loss: 0.7888 - val_accuracy: 0.9041\n",
      "Epoch 1495/2000\n",
      "338/338 [==============================] - 0s 77us/step - loss: 0.0299 - accuracy: 0.9882 - val_loss: 0.7866 - val_accuracy: 0.9041\n",
      "Epoch 1496/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0301 - accuracy: 0.9882 - val_loss: 0.7882 - val_accuracy: 0.9041\n",
      "Epoch 1497/2000\n",
      "338/338 [==============================] - 0s 74us/step - loss: 0.0299 - accuracy: 0.9882 - val_loss: 0.7882 - val_accuracy: 0.9041\n",
      "Epoch 1498/2000\n",
      "338/338 [==============================] - 0s 79us/step - loss: 0.0300 - accuracy: 0.9882 - val_loss: 0.7896 - val_accuracy: 0.9041\n",
      "Epoch 1499/2000\n",
      "338/338 [==============================] - 0s 81us/step - loss: 0.0305 - accuracy: 0.9882 - val_loss: 0.7887 - val_accuracy: 0.9041\n",
      "Epoch 1500/2000\n",
      "338/338 [==============================] - 0s 75us/step - loss: 0.0297 - accuracy: 0.9882 - val_loss: 0.7904 - val_accuracy: 0.9041\n",
      "Epoch 1501/2000\n",
      "338/338 [==============================] - 0s 75us/step - loss: 0.0298 - accuracy: 0.9882 - val_loss: 0.7917 - val_accuracy: 0.9041\n",
      "Epoch 1502/2000\n",
      "338/338 [==============================] - 0s 75us/step - loss: 0.0296 - accuracy: 0.9882 - val_loss: 0.7910 - val_accuracy: 0.9041\n",
      "Epoch 1503/2000\n",
      "338/338 [==============================] - 0s 75us/step - loss: 0.0299 - accuracy: 0.9882 - val_loss: 0.7898 - val_accuracy: 0.9041\n",
      "Epoch 1504/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0298 - accuracy: 0.9882 - val_loss: 0.7915 - val_accuracy: 0.9041\n",
      "Epoch 1505/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0302 - accuracy: 0.9882 - val_loss: 0.7922 - val_accuracy: 0.9041\n",
      "Epoch 1506/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0299 - accuracy: 0.9882 - val_loss: 0.7922 - val_accuracy: 0.9041\n",
      "Epoch 1507/2000\n",
      "338/338 [==============================] - 0s 74us/step - loss: 0.0295 - accuracy: 0.9882 - val_loss: 0.7930 - val_accuracy: 0.9041\n",
      "Epoch 1508/2000\n",
      "338/338 [==============================] - 0s 64us/step - loss: 0.0299 - accuracy: 0.9882 - val_loss: 0.7929 - val_accuracy: 0.9041\n",
      "Epoch 1509/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0295 - accuracy: 0.9882 - val_loss: 0.7957 - val_accuracy: 0.9041\n",
      "Epoch 1510/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0297 - accuracy: 0.9882 - val_loss: 0.7936 - val_accuracy: 0.9041\n",
      "Epoch 1511/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0299 - accuracy: 0.9882 - val_loss: 0.7935 - val_accuracy: 0.9041\n",
      "Epoch 1512/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0296 - accuracy: 0.9882 - val_loss: 0.7916 - val_accuracy: 0.9041\n",
      "Epoch 1513/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0298 - accuracy: 0.9882 - val_loss: 0.7935 - val_accuracy: 0.9041\n",
      "Epoch 1514/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0303 - accuracy: 0.9882 - val_loss: 0.7924 - val_accuracy: 0.9041\n",
      "Epoch 1515/2000\n",
      "338/338 [==============================] - 0s 76us/step - loss: 0.0297 - accuracy: 0.9882 - val_loss: 0.7940 - val_accuracy: 0.9041\n",
      "Epoch 1516/2000\n",
      "338/338 [==============================] - 0s 65us/step - loss: 0.0297 - accuracy: 0.9882 - val_loss: 0.7945 - val_accuracy: 0.9041\n",
      "Epoch 1517/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0296 - accuracy: 0.9882 - val_loss: 0.7947 - val_accuracy: 0.9041\n",
      "Epoch 1518/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0298 - accuracy: 0.9882 - val_loss: 0.7955 - val_accuracy: 0.9041\n",
      "Epoch 1519/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0297 - accuracy: 0.9882 - val_loss: 0.7958 - val_accuracy: 0.9041\n",
      "Epoch 1520/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0298 - accuracy: 0.9882 - val_loss: 0.7952 - val_accuracy: 0.9041\n",
      "Epoch 1521/2000\n",
      "338/338 [==============================] - 0s 76us/step - loss: 0.0295 - accuracy: 0.9882 - val_loss: 0.7972 - val_accuracy: 0.9041\n",
      "Epoch 1522/2000\n",
      "338/338 [==============================] - 0s 65us/step - loss: 0.0294 - accuracy: 0.9882 - val_loss: 0.7961 - val_accuracy: 0.9041\n",
      "Epoch 1523/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0296 - accuracy: 0.9882 - val_loss: 0.7991 - val_accuracy: 0.9041\n",
      "Epoch 1524/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0295 - accuracy: 0.9882 - val_loss: 0.7981 - val_accuracy: 0.9041\n",
      "Epoch 1525/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0299 - accuracy: 0.9882 - val_loss: 0.7971 - val_accuracy: 0.9041\n",
      "Epoch 1526/2000\n",
      "338/338 [==============================] - 0s 65us/step - loss: 0.0292 - accuracy: 0.9882 - val_loss: 0.7955 - val_accuracy: 0.9041\n",
      "Epoch 1527/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0292 - accuracy: 0.9882 - val_loss: 0.7947 - val_accuracy: 0.9041\n",
      "Epoch 1528/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0299 - accuracy: 0.9882 - val_loss: 0.7967 - val_accuracy: 0.9041\n",
      "Epoch 1529/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0299 - accuracy: 0.9882 - val_loss: 0.7966 - val_accuracy: 0.9041\n",
      "Epoch 1530/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0295 - accuracy: 0.9882 - val_loss: 0.7974 - val_accuracy: 0.9041\n",
      "Epoch 1531/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0295 - accuracy: 0.9882 - val_loss: 0.7991 - val_accuracy: 0.9041\n",
      "Epoch 1532/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0294 - accuracy: 0.9882 - val_loss: 0.7984 - val_accuracy: 0.9041\n",
      "Epoch 1533/2000\n",
      "338/338 [==============================] - 0s 65us/step - loss: 0.0297 - accuracy: 0.9882 - val_loss: 0.8001 - val_accuracy: 0.9041\n",
      "Epoch 1534/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0298 - accuracy: 0.9882 - val_loss: 0.8010 - val_accuracy: 0.9041\n",
      "Epoch 1535/2000\n",
      "338/338 [==============================] - 0s 65us/step - loss: 0.0295 - accuracy: 0.9882 - val_loss: 0.8030 - val_accuracy: 0.9041\n",
      "Epoch 1536/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0291 - accuracy: 0.9882 - val_loss: 0.8033 - val_accuracy: 0.9041\n",
      "Epoch 1537/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0292 - accuracy: 0.9882 - val_loss: 0.8011 - val_accuracy: 0.9041\n",
      "Epoch 1538/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0293 - accuracy: 0.9882 - val_loss: 0.8018 - val_accuracy: 0.9041\n",
      "Epoch 1539/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0289 - accuracy: 0.9882 - val_loss: 0.7979 - val_accuracy: 0.9041\n",
      "Epoch 1540/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0295 - accuracy: 0.9882 - val_loss: 0.8009 - val_accuracy: 0.9041\n",
      "Epoch 1541/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0294 - accuracy: 0.9882 - val_loss: 0.8027 - val_accuracy: 0.9041\n",
      "Epoch 1542/2000\n",
      "338/338 [==============================] - 0s 80us/step - loss: 0.0299 - accuracy: 0.9882 - val_loss: 0.8033 - val_accuracy: 0.9041\n",
      "Epoch 1543/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "338/338 [==============================] - 0s 69us/step - loss: 0.0292 - accuracy: 0.9882 - val_loss: 0.8047 - val_accuracy: 0.9041\n",
      "Epoch 1544/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0292 - accuracy: 0.9882 - val_loss: 0.8035 - val_accuracy: 0.9041\n",
      "Epoch 1545/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0292 - accuracy: 0.9882 - val_loss: 0.8031 - val_accuracy: 0.9041\n",
      "Epoch 1546/2000\n",
      "338/338 [==============================] - 0s 65us/step - loss: 0.0294 - accuracy: 0.9882 - val_loss: 0.8052 - val_accuracy: 0.9041\n",
      "Epoch 1547/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0294 - accuracy: 0.9882 - val_loss: 0.8050 - val_accuracy: 0.9041\n",
      "Epoch 1548/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0296 - accuracy: 0.9882 - val_loss: 0.8045 - val_accuracy: 0.9041\n",
      "Epoch 1549/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0290 - accuracy: 0.9882 - val_loss: 0.8056 - val_accuracy: 0.9041\n",
      "Epoch 1550/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0294 - accuracy: 0.9882 - val_loss: 0.8058 - val_accuracy: 0.9041\n",
      "Epoch 1551/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0291 - accuracy: 0.9882 - val_loss: 0.8063 - val_accuracy: 0.9041\n",
      "Epoch 1552/2000\n",
      "338/338 [==============================] - 0s 62us/step - loss: 0.0292 - accuracy: 0.9882 - val_loss: 0.8079 - val_accuracy: 0.9041\n",
      "Epoch 1553/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0291 - accuracy: 0.9882 - val_loss: 0.8052 - val_accuracy: 0.9041\n",
      "Epoch 1554/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0293 - accuracy: 0.9882 - val_loss: 0.8067 - val_accuracy: 0.9041\n",
      "Epoch 1555/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0290 - accuracy: 0.9882 - val_loss: 0.8098 - val_accuracy: 0.9041\n",
      "Epoch 1556/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0291 - accuracy: 0.9882 - val_loss: 0.8082 - val_accuracy: 0.9041\n",
      "Epoch 1557/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0295 - accuracy: 0.9882 - val_loss: 0.8073 - val_accuracy: 0.9041\n",
      "Epoch 1558/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0288 - accuracy: 0.9882 - val_loss: 0.8063 - val_accuracy: 0.9041\n",
      "Epoch 1559/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0287 - accuracy: 0.9882 - val_loss: 0.8074 - val_accuracy: 0.9041\n",
      "Epoch 1560/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0293 - accuracy: 0.9882 - val_loss: 0.8112 - val_accuracy: 0.9041\n",
      "Epoch 1561/2000\n",
      "338/338 [==============================] - 0s 65us/step - loss: 0.0292 - accuracy: 0.9882 - val_loss: 0.8107 - val_accuracy: 0.9041\n",
      "Epoch 1562/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0292 - accuracy: 0.9882 - val_loss: 0.8101 - val_accuracy: 0.9041\n",
      "Epoch 1563/2000\n",
      "338/338 [==============================] - 0s 64us/step - loss: 0.0291 - accuracy: 0.9882 - val_loss: 0.8112 - val_accuracy: 0.9041\n",
      "Epoch 1564/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0289 - accuracy: 0.9882 - val_loss: 0.8115 - val_accuracy: 0.9041\n",
      "Epoch 1565/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0288 - accuracy: 0.9882 - val_loss: 0.8095 - val_accuracy: 0.9041\n",
      "Epoch 1566/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0291 - accuracy: 0.9882 - val_loss: 0.8099 - val_accuracy: 0.9041\n",
      "Epoch 1567/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0296 - accuracy: 0.9882 - val_loss: 0.8095 - val_accuracy: 0.9041\n",
      "Epoch 1568/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0288 - accuracy: 0.9882 - val_loss: 0.8116 - val_accuracy: 0.9041\n",
      "Epoch 1569/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0285 - accuracy: 0.9882 - val_loss: 0.8134 - val_accuracy: 0.9041\n",
      "Epoch 1570/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0293 - accuracy: 0.9882 - val_loss: 0.8133 - val_accuracy: 0.9041\n",
      "Epoch 1571/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0287 - accuracy: 0.9882 - val_loss: 0.8106 - val_accuracy: 0.9041\n",
      "Epoch 1572/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0291 - accuracy: 0.9882 - val_loss: 0.8106 - val_accuracy: 0.9041\n",
      "Epoch 1573/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0288 - accuracy: 0.9882 - val_loss: 0.8125 - val_accuracy: 0.9041\n",
      "Epoch 1574/2000\n",
      "338/338 [==============================] - 0s 64us/step - loss: 0.0285 - accuracy: 0.9882 - val_loss: 0.8086 - val_accuracy: 0.9041\n",
      "Epoch 1575/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0289 - accuracy: 0.9882 - val_loss: 0.8086 - val_accuracy: 0.9041\n",
      "Epoch 1576/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0290 - accuracy: 0.9882 - val_loss: 0.8113 - val_accuracy: 0.9041\n",
      "Epoch 1577/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0293 - accuracy: 0.9882 - val_loss: 0.8129 - val_accuracy: 0.9041\n",
      "Epoch 1578/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0283 - accuracy: 0.9882 - val_loss: 0.8106 - val_accuracy: 0.9041\n",
      "Epoch 1579/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0291 - accuracy: 0.9882 - val_loss: 0.8096 - val_accuracy: 0.9041\n",
      "Epoch 1580/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0289 - accuracy: 0.9882 - val_loss: 0.8087 - val_accuracy: 0.9041\n",
      "Epoch 1581/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0285 - accuracy: 0.9882 - val_loss: 0.8108 - val_accuracy: 0.9041\n",
      "Epoch 1582/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0290 - accuracy: 0.9882 - val_loss: 0.8104 - val_accuracy: 0.9041\n",
      "Epoch 1583/2000\n",
      "338/338 [==============================] - 0s 75us/step - loss: 0.0288 - accuracy: 0.9882 - val_loss: 0.8129 - val_accuracy: 0.9041\n",
      "Epoch 1584/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0289 - accuracy: 0.9882 - val_loss: 0.8112 - val_accuracy: 0.9041\n",
      "Epoch 1585/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0290 - accuracy: 0.9882 - val_loss: 0.8114 - val_accuracy: 0.9041\n",
      "Epoch 1586/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0288 - accuracy: 0.9882 - val_loss: 0.8112 - val_accuracy: 0.9041\n",
      "Epoch 1587/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0288 - accuracy: 0.9882 - val_loss: 0.8097 - val_accuracy: 0.9041\n",
      "Epoch 1588/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0286 - accuracy: 0.9882 - val_loss: 0.8096 - val_accuracy: 0.9041\n",
      "Epoch 1589/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0285 - accuracy: 0.9882 - val_loss: 0.8109 - val_accuracy: 0.9041\n",
      "Epoch 1590/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0288 - accuracy: 0.9882 - val_loss: 0.8127 - val_accuracy: 0.9041\n",
      "Epoch 1591/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0282 - accuracy: 0.9882 - val_loss: 0.8087 - val_accuracy: 0.9041\n",
      "Epoch 1592/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0291 - accuracy: 0.9882 - val_loss: 0.8096 - val_accuracy: 0.9041\n",
      "Epoch 1593/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0290 - accuracy: 0.9882 - val_loss: 0.8115 - val_accuracy: 0.9041\n",
      "Epoch 1594/2000\n",
      "338/338 [==============================] - 0s 74us/step - loss: 0.0287 - accuracy: 0.9882 - val_loss: 0.8107 - val_accuracy: 0.9041\n",
      "Epoch 1595/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0293 - accuracy: 0.9882 - val_loss: 0.8120 - val_accuracy: 0.9041\n",
      "Epoch 1596/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0283 - accuracy: 0.9882 - val_loss: 0.8159 - val_accuracy: 0.9041\n",
      "Epoch 1597/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0290 - accuracy: 0.9882 - val_loss: 0.8147 - val_accuracy: 0.9041\n",
      "Epoch 1598/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "338/338 [==============================] - 0s 68us/step - loss: 0.0285 - accuracy: 0.9882 - val_loss: 0.8135 - val_accuracy: 0.9041\n",
      "Epoch 1599/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0288 - accuracy: 0.9882 - val_loss: 0.8123 - val_accuracy: 0.9041\n",
      "Epoch 1600/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0285 - accuracy: 0.9882 - val_loss: 0.8127 - val_accuracy: 0.9041\n",
      "Epoch 1601/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0287 - accuracy: 0.9882 - val_loss: 0.8110 - val_accuracy: 0.9041\n",
      "Epoch 1602/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0283 - accuracy: 0.9882 - val_loss: 0.8136 - val_accuracy: 0.9041\n",
      "Epoch 1603/2000\n",
      "338/338 [==============================] - 0s 76us/step - loss: 0.0292 - accuracy: 0.9882 - val_loss: 0.8126 - val_accuracy: 0.9041\n",
      "Epoch 1604/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0284 - accuracy: 0.9882 - val_loss: 0.8125 - val_accuracy: 0.9041\n",
      "Epoch 1605/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0284 - accuracy: 0.9882 - val_loss: 0.8150 - val_accuracy: 0.9041\n",
      "Epoch 1606/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0288 - accuracy: 0.9882 - val_loss: 0.8139 - val_accuracy: 0.9041\n",
      "Epoch 1607/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0291 - accuracy: 0.9882 - val_loss: 0.8155 - val_accuracy: 0.9041\n",
      "Epoch 1608/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0279 - accuracy: 0.9882 - val_loss: 0.8126 - val_accuracy: 0.9041\n",
      "Epoch 1609/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0286 - accuracy: 0.9882 - val_loss: 0.8127 - val_accuracy: 0.9041\n",
      "Epoch 1610/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0284 - accuracy: 0.9882 - val_loss: 0.8135 - val_accuracy: 0.9041\n",
      "Epoch 1611/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0284 - accuracy: 0.9882 - val_loss: 0.8113 - val_accuracy: 0.9041\n",
      "Epoch 1612/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0288 - accuracy: 0.9882 - val_loss: 0.8128 - val_accuracy: 0.9041\n",
      "Epoch 1613/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0285 - accuracy: 0.9882 - val_loss: 0.8140 - val_accuracy: 0.9041\n",
      "Epoch 1614/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0288 - accuracy: 0.9882 - val_loss: 0.8153 - val_accuracy: 0.9041\n",
      "Epoch 1615/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0290 - accuracy: 0.9882 - val_loss: 0.8111 - val_accuracy: 0.9041\n",
      "Epoch 1616/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0285 - accuracy: 0.9882 - val_loss: 0.8121 - val_accuracy: 0.9041\n",
      "Epoch 1617/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0294 - accuracy: 0.9882 - val_loss: 0.8125 - val_accuracy: 0.9041\n",
      "Epoch 1618/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0284 - accuracy: 0.9882 - val_loss: 0.8123 - val_accuracy: 0.9041\n",
      "Epoch 1619/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0287 - accuracy: 0.9882 - val_loss: 0.8126 - val_accuracy: 0.9041\n",
      "Epoch 1620/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0285 - accuracy: 0.9882 - val_loss: 0.8139 - val_accuracy: 0.9041\n",
      "Epoch 1621/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0282 - accuracy: 0.9882 - val_loss: 0.8135 - val_accuracy: 0.9041\n",
      "Epoch 1622/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0286 - accuracy: 0.9882 - val_loss: 0.8128 - val_accuracy: 0.9041\n",
      "Epoch 1623/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0290 - accuracy: 0.9882 - val_loss: 0.8152 - val_accuracy: 0.9041\n",
      "Epoch 1624/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0283 - accuracy: 0.9882 - val_loss: 0.8140 - val_accuracy: 0.9041\n",
      "Epoch 1625/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0283 - accuracy: 0.9882 - val_loss: 0.8149 - val_accuracy: 0.9041\n",
      "Epoch 1626/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0285 - accuracy: 0.9882 - val_loss: 0.8176 - val_accuracy: 0.9041\n",
      "Epoch 1627/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0285 - accuracy: 0.9882 - val_loss: 0.8187 - val_accuracy: 0.9041\n",
      "Epoch 1628/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0285 - accuracy: 0.9882 - val_loss: 0.8173 - val_accuracy: 0.9041\n",
      "Epoch 1629/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0282 - accuracy: 0.9882 - val_loss: 0.8161 - val_accuracy: 0.9041\n",
      "Epoch 1630/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0285 - accuracy: 0.9882 - val_loss: 0.8145 - val_accuracy: 0.9041\n",
      "Epoch 1631/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0285 - accuracy: 0.9882 - val_loss: 0.8149 - val_accuracy: 0.9041\n",
      "Epoch 1632/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0286 - accuracy: 0.9882 - val_loss: 0.8175 - val_accuracy: 0.9041\n",
      "Epoch 1633/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0283 - accuracy: 0.9882 - val_loss: 0.8172 - val_accuracy: 0.9041\n",
      "Epoch 1634/2000\n",
      "338/338 [==============================] - 0s 65us/step - loss: 0.0282 - accuracy: 0.9882 - val_loss: 0.8174 - val_accuracy: 0.9041\n",
      "Epoch 1635/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0284 - accuracy: 0.9882 - val_loss: 0.8179 - val_accuracy: 0.9041\n",
      "Epoch 1636/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0283 - accuracy: 0.9882 - val_loss: 0.8170 - val_accuracy: 0.9041\n",
      "Epoch 1637/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0281 - accuracy: 0.9882 - val_loss: 0.8160 - val_accuracy: 0.9041\n",
      "Epoch 1638/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0284 - accuracy: 0.9882 - val_loss: 0.8149 - val_accuracy: 0.9041\n",
      "Epoch 1639/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0283 - accuracy: 0.9882 - val_loss: 0.8162 - val_accuracy: 0.9041\n",
      "Epoch 1640/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0280 - accuracy: 0.9882 - val_loss: 0.8155 - val_accuracy: 0.9041\n",
      "Epoch 1641/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0281 - accuracy: 0.9882 - val_loss: 0.8155 - val_accuracy: 0.9041\n",
      "Epoch 1642/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0283 - accuracy: 0.9882 - val_loss: 0.8155 - val_accuracy: 0.9041\n",
      "Epoch 1643/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0284 - accuracy: 0.9882 - val_loss: 0.8178 - val_accuracy: 0.9041\n",
      "Epoch 1644/2000\n",
      "338/338 [==============================] - 0s 74us/step - loss: 0.0282 - accuracy: 0.9882 - val_loss: 0.8184 - val_accuracy: 0.9041\n",
      "Epoch 1645/2000\n",
      "338/338 [==============================] - 0s 74us/step - loss: 0.0279 - accuracy: 0.9882 - val_loss: 0.8181 - val_accuracy: 0.9041\n",
      "Epoch 1646/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0285 - accuracy: 0.9882 - val_loss: 0.8203 - val_accuracy: 0.9041\n",
      "Epoch 1647/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0284 - accuracy: 0.9882 - val_loss: 0.8199 - val_accuracy: 0.9041\n",
      "Epoch 1648/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0282 - accuracy: 0.9882 - val_loss: 0.8186 - val_accuracy: 0.9041\n",
      "Epoch 1649/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0281 - accuracy: 0.9882 - val_loss: 0.8214 - val_accuracy: 0.9041\n",
      "Epoch 1650/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0281 - accuracy: 0.9882 - val_loss: 0.8218 - val_accuracy: 0.9041\n",
      "Epoch 1651/2000\n",
      "338/338 [==============================] - 0s 65us/step - loss: 0.0279 - accuracy: 0.9882 - val_loss: 0.8191 - val_accuracy: 0.9041\n",
      "Epoch 1652/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0282 - accuracy: 0.9882 - val_loss: 0.8219 - val_accuracy: 0.9041\n",
      "Epoch 1653/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "338/338 [==============================] - 0s 69us/step - loss: 0.0285 - accuracy: 0.9882 - val_loss: 0.8189 - val_accuracy: 0.9041\n",
      "Epoch 1654/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0285 - accuracy: 0.9882 - val_loss: 0.8186 - val_accuracy: 0.9041\n",
      "Epoch 1655/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0279 - accuracy: 0.9882 - val_loss: 0.8196 - val_accuracy: 0.9041\n",
      "Epoch 1656/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0279 - accuracy: 0.9882 - val_loss: 0.8179 - val_accuracy: 0.9041\n",
      "Epoch 1657/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0285 - accuracy: 0.9882 - val_loss: 0.8204 - val_accuracy: 0.9041\n",
      "Epoch 1658/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0283 - accuracy: 0.9882 - val_loss: 0.8218 - val_accuracy: 0.9041\n",
      "Epoch 1659/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0280 - accuracy: 0.9882 - val_loss: 0.8232 - val_accuracy: 0.9041\n",
      "Epoch 1660/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0282 - accuracy: 0.9882 - val_loss: 0.8228 - val_accuracy: 0.9041\n",
      "Epoch 1661/2000\n",
      "338/338 [==============================] - 0s 65us/step - loss: 0.0279 - accuracy: 0.9882 - val_loss: 0.8241 - val_accuracy: 0.9041\n",
      "Epoch 1662/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0277 - accuracy: 0.9852 - val_loss: 0.8218 - val_accuracy: 0.9041\n",
      "Epoch 1663/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0281 - accuracy: 0.9882 - val_loss: 0.8205 - val_accuracy: 0.9041\n",
      "Epoch 1664/2000\n",
      "338/338 [==============================] - 0s 65us/step - loss: 0.0284 - accuracy: 0.9882 - val_loss: 0.8229 - val_accuracy: 0.9041\n",
      "Epoch 1665/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0280 - accuracy: 0.9882 - val_loss: 0.8222 - val_accuracy: 0.9041\n",
      "Epoch 1666/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0280 - accuracy: 0.9882 - val_loss: 0.8212 - val_accuracy: 0.9041\n",
      "Epoch 1667/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0286 - accuracy: 0.9882 - val_loss: 0.8211 - val_accuracy: 0.9041\n",
      "Epoch 1668/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0282 - accuracy: 0.9882 - val_loss: 0.8230 - val_accuracy: 0.9041\n",
      "Epoch 1669/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0279 - accuracy: 0.9882 - val_loss: 0.8235 - val_accuracy: 0.9041\n",
      "Epoch 1670/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0284 - accuracy: 0.9882 - val_loss: 0.8244 - val_accuracy: 0.9041\n",
      "Epoch 1671/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0281 - accuracy: 0.9882 - val_loss: 0.8257 - val_accuracy: 0.9041\n",
      "Epoch 1672/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0280 - accuracy: 0.9882 - val_loss: 0.8223 - val_accuracy: 0.9041\n",
      "Epoch 1673/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0278 - accuracy: 0.9882 - val_loss: 0.8209 - val_accuracy: 0.9041\n",
      "Epoch 1674/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0279 - accuracy: 0.9882 - val_loss: 0.8213 - val_accuracy: 0.9041\n",
      "Epoch 1675/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0285 - accuracy: 0.9882 - val_loss: 0.8226 - val_accuracy: 0.9041\n",
      "Epoch 1676/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0277 - accuracy: 0.9882 - val_loss: 0.8235 - val_accuracy: 0.9041\n",
      "Epoch 1677/2000\n",
      "338/338 [==============================] - 0s 63us/step - loss: 0.0280 - accuracy: 0.9852 - val_loss: 0.8233 - val_accuracy: 0.9041\n",
      "Epoch 1678/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0278 - accuracy: 0.9882 - val_loss: 0.8240 - val_accuracy: 0.9041\n",
      "Epoch 1679/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0279 - accuracy: 0.9882 - val_loss: 0.8241 - val_accuracy: 0.9041\n",
      "Epoch 1680/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0286 - accuracy: 0.9882 - val_loss: 0.8261 - val_accuracy: 0.9041\n",
      "Epoch 1681/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0278 - accuracy: 0.9882 - val_loss: 0.8260 - val_accuracy: 0.9041\n",
      "Epoch 1682/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0280 - accuracy: 0.9882 - val_loss: 0.8270 - val_accuracy: 0.9041\n",
      "Epoch 1683/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0279 - accuracy: 0.9882 - val_loss: 0.8270 - val_accuracy: 0.9041\n",
      "Epoch 1684/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0291 - accuracy: 0.9882 - val_loss: 0.8254 - val_accuracy: 0.9041\n",
      "Epoch 1685/2000\n",
      "338/338 [==============================] - 0s 76us/step - loss: 0.0279 - accuracy: 0.9882 - val_loss: 0.8281 - val_accuracy: 0.9041\n",
      "Epoch 1686/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0275 - accuracy: 0.9882 - val_loss: 0.8293 - val_accuracy: 0.9041\n",
      "Epoch 1687/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0279 - accuracy: 0.9882 - val_loss: 0.8295 - val_accuracy: 0.9041\n",
      "Epoch 1688/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0279 - accuracy: 0.9882 - val_loss: 0.8323 - val_accuracy: 0.9041\n",
      "Epoch 1689/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0279 - accuracy: 0.9852 - val_loss: 0.8314 - val_accuracy: 0.9041\n",
      "Epoch 1690/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0279 - accuracy: 0.9882 - val_loss: 0.8301 - val_accuracy: 0.9041\n",
      "Epoch 1691/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0277 - accuracy: 0.9882 - val_loss: 0.8288 - val_accuracy: 0.9041\n",
      "Epoch 1692/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0278 - accuracy: 0.9882 - val_loss: 0.8288 - val_accuracy: 0.9041\n",
      "Epoch 1693/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0280 - accuracy: 0.9882 - val_loss: 0.8290 - val_accuracy: 0.9041\n",
      "Epoch 1694/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0280 - accuracy: 0.9882 - val_loss: 0.8292 - val_accuracy: 0.9041\n",
      "Epoch 1695/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0282 - accuracy: 0.9882 - val_loss: 0.8274 - val_accuracy: 0.9041\n",
      "Epoch 1696/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0278 - accuracy: 0.9882 - val_loss: 0.8271 - val_accuracy: 0.9041\n",
      "Epoch 1697/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0278 - accuracy: 0.9882 - val_loss: 0.8278 - val_accuracy: 0.9041\n",
      "Epoch 1698/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0279 - accuracy: 0.9882 - val_loss: 0.8276 - val_accuracy: 0.9041\n",
      "Epoch 1699/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0278 - accuracy: 0.9882 - val_loss: 0.8274 - val_accuracy: 0.9041\n",
      "Epoch 1700/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0276 - accuracy: 0.9882 - val_loss: 0.8292 - val_accuracy: 0.9041\n",
      "Epoch 1701/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0277 - accuracy: 0.9882 - val_loss: 0.8296 - val_accuracy: 0.9041\n",
      "Epoch 1702/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0277 - accuracy: 0.9882 - val_loss: 0.8278 - val_accuracy: 0.9041\n",
      "Epoch 1703/2000\n",
      "338/338 [==============================] - 0s 74us/step - loss: 0.0277 - accuracy: 0.9882 - val_loss: 0.8276 - val_accuracy: 0.9041\n",
      "Epoch 1704/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0279 - accuracy: 0.9882 - val_loss: 0.8256 - val_accuracy: 0.9041\n",
      "Epoch 1705/2000\n",
      "338/338 [==============================] - 0s 78us/step - loss: 0.0275 - accuracy: 0.9882 - val_loss: 0.8234 - val_accuracy: 0.9041\n",
      "Epoch 1706/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0278 - accuracy: 0.9882 - val_loss: 0.8245 - val_accuracy: 0.9041\n",
      "Epoch 1707/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0276 - accuracy: 0.9882 - val_loss: 0.8218 - val_accuracy: 0.9041\n",
      "Epoch 1708/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "338/338 [==============================] - 0s 72us/step - loss: 0.0279 - accuracy: 0.9882 - val_loss: 0.8221 - val_accuracy: 0.9041\n",
      "Epoch 1709/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0276 - accuracy: 0.9882 - val_loss: 0.8230 - val_accuracy: 0.9041\n",
      "Epoch 1710/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0278 - accuracy: 0.9882 - val_loss: 0.8211 - val_accuracy: 0.9041\n",
      "Epoch 1711/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0279 - accuracy: 0.9882 - val_loss: 0.8242 - val_accuracy: 0.9041\n",
      "Epoch 1712/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0276 - accuracy: 0.9882 - val_loss: 0.8260 - val_accuracy: 0.9041\n",
      "Epoch 1713/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0276 - accuracy: 0.9882 - val_loss: 0.8252 - val_accuracy: 0.9041\n",
      "Epoch 1714/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0275 - accuracy: 0.9882 - val_loss: 0.8231 - val_accuracy: 0.9041\n",
      "Epoch 1715/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0279 - accuracy: 0.9882 - val_loss: 0.8226 - val_accuracy: 0.9041\n",
      "Epoch 1716/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0273 - accuracy: 0.9882 - val_loss: 0.8241 - val_accuracy: 0.9041\n",
      "Epoch 1717/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0279 - accuracy: 0.9882 - val_loss: 0.8207 - val_accuracy: 0.9041\n",
      "Epoch 1718/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0279 - accuracy: 0.9882 - val_loss: 0.8219 - val_accuracy: 0.9041\n",
      "Epoch 1719/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0279 - accuracy: 0.9882 - val_loss: 0.8230 - val_accuracy: 0.9041\n",
      "Epoch 1720/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0275 - accuracy: 0.9882 - val_loss: 0.8224 - val_accuracy: 0.9041\n",
      "Epoch 1721/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0275 - accuracy: 0.9882 - val_loss: 0.8204 - val_accuracy: 0.9041\n",
      "Epoch 1722/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0277 - accuracy: 0.9882 - val_loss: 0.8233 - val_accuracy: 0.9041\n",
      "Epoch 1723/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0275 - accuracy: 0.9882 - val_loss: 0.8224 - val_accuracy: 0.9041\n",
      "Epoch 1724/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0278 - accuracy: 0.9882 - val_loss: 0.8230 - val_accuracy: 0.9041\n",
      "Epoch 1725/2000\n",
      "338/338 [==============================] - 0s 74us/step - loss: 0.0278 - accuracy: 0.9882 - val_loss: 0.8241 - val_accuracy: 0.9041\n",
      "Epoch 1726/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0275 - accuracy: 0.9882 - val_loss: 0.8250 - val_accuracy: 0.9041\n",
      "Epoch 1727/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0274 - accuracy: 0.9882 - val_loss: 0.8248 - val_accuracy: 0.9041\n",
      "Epoch 1728/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0278 - accuracy: 0.9882 - val_loss: 0.8249 - val_accuracy: 0.9041\n",
      "Epoch 1729/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0276 - accuracy: 0.9882 - val_loss: 0.8259 - val_accuracy: 0.9041\n",
      "Epoch 1730/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0278 - accuracy: 0.9882 - val_loss: 0.8278 - val_accuracy: 0.9041\n",
      "Epoch 1731/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0274 - accuracy: 0.9882 - val_loss: 0.8269 - val_accuracy: 0.9041\n",
      "Epoch 1732/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0276 - accuracy: 0.9882 - val_loss: 0.8258 - val_accuracy: 0.9041\n",
      "Epoch 1733/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0277 - accuracy: 0.9882 - val_loss: 0.8252 - val_accuracy: 0.9041\n",
      "Epoch 1734/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0286 - accuracy: 0.9882 - val_loss: 0.8270 - val_accuracy: 0.9041\n",
      "Epoch 1735/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0279 - accuracy: 0.9882 - val_loss: 0.8273 - val_accuracy: 0.9041\n",
      "Epoch 1736/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0276 - accuracy: 0.9882 - val_loss: 0.8280 - val_accuracy: 0.9041\n",
      "Epoch 1737/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0275 - accuracy: 0.9882 - val_loss: 0.8279 - val_accuracy: 0.9041\n",
      "Epoch 1738/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0274 - accuracy: 0.9882 - val_loss: 0.8266 - val_accuracy: 0.9041\n",
      "Epoch 1739/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0277 - accuracy: 0.9882 - val_loss: 0.8270 - val_accuracy: 0.9041\n",
      "Epoch 1740/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0276 - accuracy: 0.9882 - val_loss: 0.8285 - val_accuracy: 0.9041\n",
      "Epoch 1741/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0275 - accuracy: 0.9882 - val_loss: 0.8287 - val_accuracy: 0.9041\n",
      "Epoch 1742/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0276 - accuracy: 0.9882 - val_loss: 0.8297 - val_accuracy: 0.9041\n",
      "Epoch 1743/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0277 - accuracy: 0.9882 - val_loss: 0.8306 - val_accuracy: 0.9041\n",
      "Epoch 1744/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0272 - accuracy: 0.9882 - val_loss: 0.8336 - val_accuracy: 0.9041\n",
      "Epoch 1745/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0274 - accuracy: 0.9882 - val_loss: 0.8322 - val_accuracy: 0.9041\n",
      "Epoch 1746/2000\n",
      "338/338 [==============================] - 0s 74us/step - loss: 0.0275 - accuracy: 0.9882 - val_loss: 0.8324 - val_accuracy: 0.9041\n",
      "Epoch 1747/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0273 - accuracy: 0.9882 - val_loss: 0.8316 - val_accuracy: 0.9041\n",
      "Epoch 1748/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0276 - accuracy: 0.9882 - val_loss: 0.8308 - val_accuracy: 0.9041\n",
      "Epoch 1749/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0276 - accuracy: 0.9882 - val_loss: 0.8316 - val_accuracy: 0.9041\n",
      "Epoch 1750/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0274 - accuracy: 0.9882 - val_loss: 0.8325 - val_accuracy: 0.9041\n",
      "Epoch 1751/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0271 - accuracy: 0.9882 - val_loss: 0.8333 - val_accuracy: 0.9041\n",
      "Epoch 1752/2000\n",
      "338/338 [==============================] - 0s 86us/step - loss: 0.0274 - accuracy: 0.9882 - val_loss: 0.8344 - val_accuracy: 0.9041\n",
      "Epoch 1753/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0275 - accuracy: 0.9882 - val_loss: 0.8311 - val_accuracy: 0.9041\n",
      "Epoch 1754/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0271 - accuracy: 0.9882 - val_loss: 0.8323 - val_accuracy: 0.9041\n",
      "Epoch 1755/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0275 - accuracy: 0.9882 - val_loss: 0.8340 - val_accuracy: 0.9041\n",
      "Epoch 1756/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0272 - accuracy: 0.9882 - val_loss: 0.8339 - val_accuracy: 0.9041\n",
      "Epoch 1757/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0274 - accuracy: 0.9882 - val_loss: 0.8321 - val_accuracy: 0.9041\n",
      "Epoch 1758/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0274 - accuracy: 0.9882 - val_loss: 0.8333 - val_accuracy: 0.9041\n",
      "Epoch 1759/2000\n",
      "338/338 [==============================] - 0s 65us/step - loss: 0.0274 - accuracy: 0.9882 - val_loss: 0.8319 - val_accuracy: 0.9041\n",
      "Epoch 1760/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0276 - accuracy: 0.9882 - val_loss: 0.8333 - val_accuracy: 0.9041\n",
      "Epoch 1761/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0272 - accuracy: 0.9882 - val_loss: 0.8351 - val_accuracy: 0.9041\n",
      "Epoch 1762/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0275 - accuracy: 0.9852 - val_loss: 0.8335 - val_accuracy: 0.9041\n",
      "Epoch 1763/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "338/338 [==============================] - 0s 69us/step - loss: 0.0273 - accuracy: 0.9852 - val_loss: 0.8345 - val_accuracy: 0.9041\n",
      "Epoch 1764/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0274 - accuracy: 0.9882 - val_loss: 0.8342 - val_accuracy: 0.9041\n",
      "Epoch 1765/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0272 - accuracy: 0.9882 - val_loss: 0.8344 - val_accuracy: 0.9041\n",
      "Epoch 1766/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0277 - accuracy: 0.9882 - val_loss: 0.8315 - val_accuracy: 0.9041\n",
      "Epoch 1767/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0272 - accuracy: 0.9882 - val_loss: 0.8321 - val_accuracy: 0.9041\n",
      "Epoch 1768/2000\n",
      "338/338 [==============================] - 0s 75us/step - loss: 0.0273 - accuracy: 0.9882 - val_loss: 0.8326 - val_accuracy: 0.9041\n",
      "Epoch 1769/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0275 - accuracy: 0.9882 - val_loss: 0.8324 - val_accuracy: 0.9041\n",
      "Epoch 1770/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0274 - accuracy: 0.9882 - val_loss: 0.8312 - val_accuracy: 0.9041\n",
      "Epoch 1771/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0273 - accuracy: 0.9882 - val_loss: 0.8304 - val_accuracy: 0.9041\n",
      "Epoch 1772/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0277 - accuracy: 0.9882 - val_loss: 0.8328 - val_accuracy: 0.9041\n",
      "Epoch 1773/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0276 - accuracy: 0.9882 - val_loss: 0.8329 - val_accuracy: 0.9041\n",
      "Epoch 1774/2000\n",
      "338/338 [==============================] - 0s 65us/step - loss: 0.0273 - accuracy: 0.9882 - val_loss: 0.8333 - val_accuracy: 0.9041\n",
      "Epoch 1775/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0275 - accuracy: 0.9882 - val_loss: 0.8325 - val_accuracy: 0.9041\n",
      "Epoch 1776/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0271 - accuracy: 0.9882 - val_loss: 0.8327 - val_accuracy: 0.9041\n",
      "Epoch 1777/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0273 - accuracy: 0.9882 - val_loss: 0.8332 - val_accuracy: 0.9041\n",
      "Epoch 1778/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0277 - accuracy: 0.9882 - val_loss: 0.8339 - val_accuracy: 0.9041\n",
      "Epoch 1779/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0272 - accuracy: 0.9882 - val_loss: 0.8347 - val_accuracy: 0.9041\n",
      "Epoch 1780/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0272 - accuracy: 0.9882 - val_loss: 0.8329 - val_accuracy: 0.9041\n",
      "Epoch 1781/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0274 - accuracy: 0.9882 - val_loss: 0.8336 - val_accuracy: 0.9041\n",
      "Epoch 1782/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0271 - accuracy: 0.9882 - val_loss: 0.8325 - val_accuracy: 0.9041\n",
      "Epoch 1783/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0273 - accuracy: 0.9882 - val_loss: 0.8319 - val_accuracy: 0.9041\n",
      "Epoch 1784/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0272 - accuracy: 0.9882 - val_loss: 0.8314 - val_accuracy: 0.9041\n",
      "Epoch 1785/2000\n",
      "338/338 [==============================] - 0s 74us/step - loss: 0.0273 - accuracy: 0.9882 - val_loss: 0.8333 - val_accuracy: 0.9041\n",
      "Epoch 1786/2000\n",
      "338/338 [==============================] - 0s 74us/step - loss: 0.0274 - accuracy: 0.9882 - val_loss: 0.8339 - val_accuracy: 0.9041\n",
      "Epoch 1787/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0275 - accuracy: 0.9882 - val_loss: 0.8336 - val_accuracy: 0.9041\n",
      "Epoch 1788/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0272 - accuracy: 0.9882 - val_loss: 0.8337 - val_accuracy: 0.9041\n",
      "Epoch 1789/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0275 - accuracy: 0.9882 - val_loss: 0.8338 - val_accuracy: 0.9041\n",
      "Epoch 1790/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0270 - accuracy: 0.9882 - val_loss: 0.8329 - val_accuracy: 0.9041\n",
      "Epoch 1791/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0273 - accuracy: 0.9882 - val_loss: 0.8329 - val_accuracy: 0.9041\n",
      "Epoch 1792/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0274 - accuracy: 0.9882 - val_loss: 0.8327 - val_accuracy: 0.9041\n",
      "Epoch 1793/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0274 - accuracy: 0.9882 - val_loss: 0.8328 - val_accuracy: 0.9041\n",
      "Epoch 1794/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0271 - accuracy: 0.9852 - val_loss: 0.8322 - val_accuracy: 0.9041\n",
      "Epoch 1795/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0273 - accuracy: 0.9882 - val_loss: 0.8332 - val_accuracy: 0.9041\n",
      "Epoch 1796/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0273 - accuracy: 0.9882 - val_loss: 0.8356 - val_accuracy: 0.9041\n",
      "Epoch 1797/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0275 - accuracy: 0.9882 - val_loss: 0.8351 - val_accuracy: 0.9041\n",
      "Epoch 1798/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0271 - accuracy: 0.9882 - val_loss: 0.8347 - val_accuracy: 0.9041\n",
      "Epoch 1799/2000\n",
      "338/338 [==============================] - 0s 74us/step - loss: 0.0272 - accuracy: 0.9882 - val_loss: 0.8344 - val_accuracy: 0.9041\n",
      "Epoch 1800/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0271 - accuracy: 0.9852 - val_loss: 0.8331 - val_accuracy: 0.9041\n",
      "Epoch 1801/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0275 - accuracy: 0.9882 - val_loss: 0.8331 - val_accuracy: 0.9041\n",
      "Epoch 1802/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0272 - accuracy: 0.9882 - val_loss: 0.8349 - val_accuracy: 0.9041\n",
      "Epoch 1803/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0272 - accuracy: 0.9852 - val_loss: 0.8344 - val_accuracy: 0.9041\n",
      "Epoch 1804/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0274 - accuracy: 0.9882 - val_loss: 0.8357 - val_accuracy: 0.9041\n",
      "Epoch 1805/2000\n",
      "338/338 [==============================] - 0s 78us/step - loss: 0.0273 - accuracy: 0.9882 - val_loss: 0.8362 - val_accuracy: 0.9041\n",
      "Epoch 1806/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0270 - accuracy: 0.9882 - val_loss: 0.8353 - val_accuracy: 0.9041\n",
      "Epoch 1807/2000\n",
      "338/338 [==============================] - 0s 75us/step - loss: 0.0271 - accuracy: 0.9882 - val_loss: 0.8334 - val_accuracy: 0.9041\n",
      "Epoch 1808/2000\n",
      "338/338 [==============================] - 0s 64us/step - loss: 0.0275 - accuracy: 0.9882 - val_loss: 0.8322 - val_accuracy: 0.9041\n",
      "Epoch 1809/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0272 - accuracy: 0.9882 - val_loss: 0.8327 - val_accuracy: 0.9041\n",
      "Epoch 1810/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0272 - accuracy: 0.9882 - val_loss: 0.8329 - val_accuracy: 0.9041\n",
      "Epoch 1811/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0274 - accuracy: 0.9882 - val_loss: 0.8331 - val_accuracy: 0.9041\n",
      "Epoch 1812/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0272 - accuracy: 0.9882 - val_loss: 0.8341 - val_accuracy: 0.9041\n",
      "Epoch 1813/2000\n",
      "338/338 [==============================] - 0s 76us/step - loss: 0.0270 - accuracy: 0.9852 - val_loss: 0.8327 - val_accuracy: 0.9041\n",
      "Epoch 1814/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0274 - accuracy: 0.9882 - val_loss: 0.8329 - val_accuracy: 0.9041\n",
      "Epoch 1815/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0272 - accuracy: 0.9882 - val_loss: 0.8339 - val_accuracy: 0.9041\n",
      "Epoch 1816/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0272 - accuracy: 0.9882 - val_loss: 0.8347 - val_accuracy: 0.9041\n",
      "Epoch 1817/2000\n",
      "338/338 [==============================] - 0s 74us/step - loss: 0.0271 - accuracy: 0.9882 - val_loss: 0.8340 - val_accuracy: 0.9041\n",
      "Epoch 1818/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "338/338 [==============================] - 0s 66us/step - loss: 0.0274 - accuracy: 0.9882 - val_loss: 0.8349 - val_accuracy: 0.9041\n",
      "Epoch 1819/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0270 - accuracy: 0.9882 - val_loss: 0.8337 - val_accuracy: 0.9041\n",
      "Epoch 1820/2000\n",
      "338/338 [==============================] - 0s 79us/step - loss: 0.0273 - accuracy: 0.9882 - val_loss: 0.8351 - val_accuracy: 0.9041\n",
      "Epoch 1821/2000\n",
      "338/338 [==============================] - 0s 76us/step - loss: 0.0271 - accuracy: 0.9882 - val_loss: 0.8363 - val_accuracy: 0.9041\n",
      "Epoch 1822/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0270 - accuracy: 0.9882 - val_loss: 0.8355 - val_accuracy: 0.9041\n",
      "Epoch 1823/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0275 - accuracy: 0.9882 - val_loss: 0.8367 - val_accuracy: 0.9041\n",
      "Epoch 1824/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0270 - accuracy: 0.9882 - val_loss: 0.8365 - val_accuracy: 0.9041\n",
      "Epoch 1825/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0273 - accuracy: 0.9882 - val_loss: 0.8346 - val_accuracy: 0.9041\n",
      "Epoch 1826/2000\n",
      "338/338 [==============================] - 0s 76us/step - loss: 0.0270 - accuracy: 0.9882 - val_loss: 0.8356 - val_accuracy: 0.9041\n",
      "Epoch 1827/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0272 - accuracy: 0.9882 - val_loss: 0.8357 - val_accuracy: 0.9041\n",
      "Epoch 1828/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0272 - accuracy: 0.9882 - val_loss: 0.8355 - val_accuracy: 0.9041\n",
      "Epoch 1829/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0274 - accuracy: 0.9882 - val_loss: 0.8356 - val_accuracy: 0.9041\n",
      "Epoch 1830/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0271 - accuracy: 0.9882 - val_loss: 0.8358 - val_accuracy: 0.9041\n",
      "Epoch 1831/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0272 - accuracy: 0.9882 - val_loss: 0.8385 - val_accuracy: 0.9041\n",
      "Epoch 1832/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0269 - accuracy: 0.9882 - val_loss: 0.8388 - val_accuracy: 0.9041\n",
      "Epoch 1833/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0273 - accuracy: 0.9882 - val_loss: 0.8394 - val_accuracy: 0.9041\n",
      "Epoch 1834/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0264 - accuracy: 0.9882 - val_loss: 0.8368 - val_accuracy: 0.9041\n",
      "Epoch 1835/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0271 - accuracy: 0.9882 - val_loss: 0.8411 - val_accuracy: 0.9041\n",
      "Epoch 1836/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0266 - accuracy: 0.9882 - val_loss: 0.8388 - val_accuracy: 0.9041\n",
      "Epoch 1837/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0269 - accuracy: 0.9882 - val_loss: 0.8380 - val_accuracy: 0.9041\n",
      "Epoch 1838/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0273 - accuracy: 0.9882 - val_loss: 0.8387 - val_accuracy: 0.9041\n",
      "Epoch 1839/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0269 - accuracy: 0.9882 - val_loss: 0.8369 - val_accuracy: 0.9041\n",
      "Epoch 1840/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0270 - accuracy: 0.9882 - val_loss: 0.8382 - val_accuracy: 0.9041\n",
      "Epoch 1841/2000\n",
      "338/338 [==============================] - 0s 74us/step - loss: 0.0269 - accuracy: 0.9882 - val_loss: 0.8401 - val_accuracy: 0.9041\n",
      "Epoch 1842/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0265 - accuracy: 0.9882 - val_loss: 0.8359 - val_accuracy: 0.9041\n",
      "Epoch 1843/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0276 - accuracy: 0.9882 - val_loss: 0.8362 - val_accuracy: 0.9041\n",
      "Epoch 1844/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0269 - accuracy: 0.9882 - val_loss: 0.8368 - val_accuracy: 0.9041\n",
      "Epoch 1845/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0268 - accuracy: 0.9882 - val_loss: 0.8400 - val_accuracy: 0.9041\n",
      "Epoch 1846/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0271 - accuracy: 0.9882 - val_loss: 0.8381 - val_accuracy: 0.9041\n",
      "Epoch 1847/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0270 - accuracy: 0.9882 - val_loss: 0.8392 - val_accuracy: 0.9041\n",
      "Epoch 1848/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0270 - accuracy: 0.9882 - val_loss: 0.8407 - val_accuracy: 0.9041\n",
      "Epoch 1849/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0270 - accuracy: 0.9852 - val_loss: 0.8411 - val_accuracy: 0.9041\n",
      "Epoch 1850/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0267 - accuracy: 0.9882 - val_loss: 0.8414 - val_accuracy: 0.9041\n",
      "Epoch 1851/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0270 - accuracy: 0.9882 - val_loss: 0.8431 - val_accuracy: 0.9041\n",
      "Epoch 1852/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0267 - accuracy: 0.9882 - val_loss: 0.8428 - val_accuracy: 0.9041\n",
      "Epoch 1853/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0269 - accuracy: 0.9882 - val_loss: 0.8426 - val_accuracy: 0.9041\n",
      "Epoch 1854/2000\n",
      "338/338 [==============================] - 0s 74us/step - loss: 0.0268 - accuracy: 0.9882 - val_loss: 0.8419 - val_accuracy: 0.9041\n",
      "Epoch 1855/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0272 - accuracy: 0.9882 - val_loss: 0.8409 - val_accuracy: 0.9041\n",
      "Epoch 1856/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0270 - accuracy: 0.9882 - val_loss: 0.8426 - val_accuracy: 0.9041\n",
      "Epoch 1857/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0271 - accuracy: 0.9882 - val_loss: 0.8435 - val_accuracy: 0.9041\n",
      "Epoch 1858/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0268 - accuracy: 0.9882 - val_loss: 0.8428 - val_accuracy: 0.9041\n",
      "Epoch 1859/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0267 - accuracy: 0.9882 - val_loss: 0.8415 - val_accuracy: 0.9041\n",
      "Epoch 1860/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0272 - accuracy: 0.9882 - val_loss: 0.8429 - val_accuracy: 0.9041\n",
      "Epoch 1861/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0268 - accuracy: 0.9882 - val_loss: 0.8416 - val_accuracy: 0.9041\n",
      "Epoch 1862/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0270 - accuracy: 0.9882 - val_loss: 0.8429 - val_accuracy: 0.9041\n",
      "Epoch 1863/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0267 - accuracy: 0.9882 - val_loss: 0.8446 - val_accuracy: 0.9041\n",
      "Epoch 1864/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0268 - accuracy: 0.9852 - val_loss: 0.8437 - val_accuracy: 0.9041\n",
      "Epoch 1865/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0268 - accuracy: 0.9882 - val_loss: 0.8447 - val_accuracy: 0.9041\n",
      "Epoch 1866/2000\n",
      "338/338 [==============================] - 0s 77us/step - loss: 0.0269 - accuracy: 0.9882 - val_loss: 0.8434 - val_accuracy: 0.9041\n",
      "Epoch 1867/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0271 - accuracy: 0.9882 - val_loss: 0.8445 - val_accuracy: 0.9041\n",
      "Epoch 1868/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0268 - accuracy: 0.9882 - val_loss: 0.8454 - val_accuracy: 0.9041\n",
      "Epoch 1869/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0265 - accuracy: 0.9882 - val_loss: 0.8448 - val_accuracy: 0.9041\n",
      "Epoch 1870/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0275 - accuracy: 0.9882 - val_loss: 0.8448 - val_accuracy: 0.9041\n",
      "Epoch 1871/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0267 - accuracy: 0.9882 - val_loss: 0.8451 - val_accuracy: 0.9041\n",
      "Epoch 1872/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0264 - accuracy: 0.9852 - val_loss: 0.8437 - val_accuracy: 0.9041\n",
      "Epoch 1873/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "338/338 [==============================] - 0s 69us/step - loss: 0.0270 - accuracy: 0.9882 - val_loss: 0.8460 - val_accuracy: 0.9041\n",
      "Epoch 1874/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0266 - accuracy: 0.9882 - val_loss: 0.8473 - val_accuracy: 0.9041\n",
      "Epoch 1875/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0273 - accuracy: 0.9882 - val_loss: 0.8467 - val_accuracy: 0.9041\n",
      "Epoch 1876/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0268 - accuracy: 0.9882 - val_loss: 0.8469 - val_accuracy: 0.9041\n",
      "Epoch 1877/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0269 - accuracy: 0.9882 - val_loss: 0.8464 - val_accuracy: 0.9041\n",
      "Epoch 1878/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0265 - accuracy: 0.9882 - val_loss: 0.8463 - val_accuracy: 0.9041\n",
      "Epoch 1879/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0265 - accuracy: 0.9882 - val_loss: 0.8467 - val_accuracy: 0.9041\n",
      "Epoch 1880/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0275 - accuracy: 0.9882 - val_loss: 0.8478 - val_accuracy: 0.9041\n",
      "Epoch 1881/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0275 - accuracy: 0.9882 - val_loss: 0.8494 - val_accuracy: 0.9041\n",
      "Epoch 1882/2000\n",
      "338/338 [==============================] - 0s 65us/step - loss: 0.0266 - accuracy: 0.9882 - val_loss: 0.8512 - val_accuracy: 0.9041\n",
      "Epoch 1883/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0267 - accuracy: 0.9882 - val_loss: 0.8512 - val_accuracy: 0.9041\n",
      "Epoch 1884/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0267 - accuracy: 0.9852 - val_loss: 0.8514 - val_accuracy: 0.9041\n",
      "Epoch 1885/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0271 - accuracy: 0.9882 - val_loss: 0.8496 - val_accuracy: 0.9041\n",
      "Epoch 1886/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0266 - accuracy: 0.9882 - val_loss: 0.8517 - val_accuracy: 0.9041\n",
      "Epoch 1887/2000\n",
      "338/338 [==============================] - 0s 74us/step - loss: 0.0265 - accuracy: 0.9882 - val_loss: 0.8520 - val_accuracy: 0.9041\n",
      "Epoch 1888/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0270 - accuracy: 0.9882 - val_loss: 0.8514 - val_accuracy: 0.9041\n",
      "Epoch 1889/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0266 - accuracy: 0.9882 - val_loss: 0.8502 - val_accuracy: 0.9041\n",
      "Epoch 1890/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0266 - accuracy: 0.9882 - val_loss: 0.8522 - val_accuracy: 0.9041\n",
      "Epoch 1891/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0268 - accuracy: 0.9882 - val_loss: 0.8522 - val_accuracy: 0.9041\n",
      "Epoch 1892/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0270 - accuracy: 0.9882 - val_loss: 0.8504 - val_accuracy: 0.9041\n",
      "Epoch 1893/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0269 - accuracy: 0.9882 - val_loss: 0.8507 - val_accuracy: 0.9041\n",
      "Epoch 1894/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0274 - accuracy: 0.9882 - val_loss: 0.8516 - val_accuracy: 0.9041\n",
      "Epoch 1895/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0266 - accuracy: 0.9882 - val_loss: 0.8528 - val_accuracy: 0.9041\n",
      "Epoch 1896/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0266 - accuracy: 0.9882 - val_loss: 0.8507 - val_accuracy: 0.9041\n",
      "Epoch 1897/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0272 - accuracy: 0.9882 - val_loss: 0.8509 - val_accuracy: 0.9041\n",
      "Epoch 1898/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0266 - accuracy: 0.9882 - val_loss: 0.8506 - val_accuracy: 0.9041\n",
      "Epoch 1899/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0267 - accuracy: 0.9882 - val_loss: 0.8489 - val_accuracy: 0.9041\n",
      "Epoch 1900/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0270 - accuracy: 0.9882 - val_loss: 0.8507 - val_accuracy: 0.9041\n",
      "Epoch 1901/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0267 - accuracy: 0.9882 - val_loss: 0.8536 - val_accuracy: 0.9041\n",
      "Epoch 1902/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0265 - accuracy: 0.9882 - val_loss: 0.8517 - val_accuracy: 0.9041\n",
      "Epoch 1903/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0265 - accuracy: 0.9882 - val_loss: 0.8521 - val_accuracy: 0.9041\n",
      "Epoch 1904/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0267 - accuracy: 0.9882 - val_loss: 0.8526 - val_accuracy: 0.9041\n",
      "Epoch 1905/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0265 - accuracy: 0.9882 - val_loss: 0.8521 - val_accuracy: 0.9041\n",
      "Epoch 1906/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0266 - accuracy: 0.9882 - val_loss: 0.8505 - val_accuracy: 0.9041\n",
      "Epoch 1907/2000\n",
      "338/338 [==============================] - 0s 75us/step - loss: 0.0266 - accuracy: 0.9882 - val_loss: 0.8512 - val_accuracy: 0.9041\n",
      "Epoch 1908/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0269 - accuracy: 0.9882 - val_loss: 0.8528 - val_accuracy: 0.9041\n",
      "Epoch 1909/2000\n",
      "338/338 [==============================] - 0s 74us/step - loss: 0.0267 - accuracy: 0.9882 - val_loss: 0.8530 - val_accuracy: 0.9041\n",
      "Epoch 1910/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0262 - accuracy: 0.9882 - val_loss: 0.8521 - val_accuracy: 0.9041\n",
      "Epoch 1911/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0269 - accuracy: 0.9882 - val_loss: 0.8530 - val_accuracy: 0.9041\n",
      "Epoch 1912/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0266 - accuracy: 0.9882 - val_loss: 0.8520 - val_accuracy: 0.9041\n",
      "Epoch 1913/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0269 - accuracy: 0.9882 - val_loss: 0.8535 - val_accuracy: 0.9041\n",
      "Epoch 1914/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0265 - accuracy: 0.9852 - val_loss: 0.8541 - val_accuracy: 0.9041\n",
      "Epoch 1915/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0271 - accuracy: 0.9882 - val_loss: 0.8522 - val_accuracy: 0.9041\n",
      "Epoch 1916/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0266 - accuracy: 0.9882 - val_loss: 0.8563 - val_accuracy: 0.9041\n",
      "Epoch 1917/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0265 - accuracy: 0.9882 - val_loss: 0.8567 - val_accuracy: 0.9041\n",
      "Epoch 1918/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0264 - accuracy: 0.9852 - val_loss: 0.8562 - val_accuracy: 0.9041\n",
      "Epoch 1919/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0268 - accuracy: 0.9882 - val_loss: 0.8564 - val_accuracy: 0.9041\n",
      "Epoch 1920/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0264 - accuracy: 0.9882 - val_loss: 0.8539 - val_accuracy: 0.9041\n",
      "Epoch 1921/2000\n",
      "338/338 [==============================] - 0s 74us/step - loss: 0.0265 - accuracy: 0.9882 - val_loss: 0.8527 - val_accuracy: 0.9041\n",
      "Epoch 1922/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0269 - accuracy: 0.9882 - val_loss: 0.8553 - val_accuracy: 0.9041\n",
      "Epoch 1923/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0265 - accuracy: 0.9882 - val_loss: 0.8558 - val_accuracy: 0.9041\n",
      "Epoch 1924/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0264 - accuracy: 0.9882 - val_loss: 0.8548 - val_accuracy: 0.9041\n",
      "Epoch 1925/2000\n",
      "338/338 [==============================] - 0s 74us/step - loss: 0.0267 - accuracy: 0.9882 - val_loss: 0.8541 - val_accuracy: 0.9041\n",
      "Epoch 1926/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0263 - accuracy: 0.9882 - val_loss: 0.8547 - val_accuracy: 0.9041\n",
      "Epoch 1927/2000\n",
      "338/338 [==============================] - 0s 81us/step - loss: 0.0266 - accuracy: 0.9882 - val_loss: 0.8544 - val_accuracy: 0.9041\n",
      "Epoch 1928/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "338/338 [==============================] - 0s 63us/step - loss: 0.0263 - accuracy: 0.9882 - val_loss: 0.8545 - val_accuracy: 0.9041\n",
      "Epoch 1929/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0267 - accuracy: 0.9882 - val_loss: 0.8529 - val_accuracy: 0.9041\n",
      "Epoch 1930/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0266 - accuracy: 0.9882 - val_loss: 0.8521 - val_accuracy: 0.9041\n",
      "Epoch 1931/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0265 - accuracy: 0.9882 - val_loss: 0.8539 - val_accuracy: 0.9041\n",
      "Epoch 1932/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0265 - accuracy: 0.9852 - val_loss: 0.8550 - val_accuracy: 0.9041\n",
      "Epoch 1933/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0264 - accuracy: 0.9852 - val_loss: 0.8542 - val_accuracy: 0.9041\n",
      "Epoch 1934/2000\n",
      "338/338 [==============================] - 0s 64us/step - loss: 0.0268 - accuracy: 0.9882 - val_loss: 0.8536 - val_accuracy: 0.9041\n",
      "Epoch 1935/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0266 - accuracy: 0.9882 - val_loss: 0.8544 - val_accuracy: 0.9041\n",
      "Epoch 1936/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0269 - accuracy: 0.9882 - val_loss: 0.8552 - val_accuracy: 0.9041\n",
      "Epoch 1937/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0265 - accuracy: 0.9882 - val_loss: 0.8549 - val_accuracy: 0.9041\n",
      "Epoch 1938/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0265 - accuracy: 0.9882 - val_loss: 0.8540 - val_accuracy: 0.9041\n",
      "Epoch 1939/2000\n",
      "338/338 [==============================] - 0s 64us/step - loss: 0.0265 - accuracy: 0.9882 - val_loss: 0.8557 - val_accuracy: 0.9041\n",
      "Epoch 1940/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0265 - accuracy: 0.9882 - val_loss: 0.8564 - val_accuracy: 0.9041\n",
      "Epoch 1941/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0266 - accuracy: 0.9882 - val_loss: 0.8556 - val_accuracy: 0.9041\n",
      "Epoch 1942/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0267 - accuracy: 0.9822 - val_loss: 0.8558 - val_accuracy: 0.9041\n",
      "Epoch 1943/2000\n",
      "338/338 [==============================] - 0s 63us/step - loss: 0.0265 - accuracy: 0.9882 - val_loss: 0.8589 - val_accuracy: 0.9041\n",
      "Epoch 1944/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0267 - accuracy: 0.9882 - val_loss: 0.8578 - val_accuracy: 0.9041\n",
      "Epoch 1945/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0264 - accuracy: 0.9852 - val_loss: 0.8587 - val_accuracy: 0.9041\n",
      "Epoch 1946/2000\n",
      "338/338 [==============================] - 0s 74us/step - loss: 0.0264 - accuracy: 0.9882 - val_loss: 0.8574 - val_accuracy: 0.9041\n",
      "Epoch 1947/2000\n",
      "338/338 [==============================] - 0s 75us/step - loss: 0.0264 - accuracy: 0.9882 - val_loss: 0.8594 - val_accuracy: 0.9041\n",
      "Epoch 1948/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0265 - accuracy: 0.9882 - val_loss: 0.8572 - val_accuracy: 0.9041\n",
      "Epoch 1949/2000\n",
      "338/338 [==============================] - 0s 65us/step - loss: 0.0262 - accuracy: 0.9882 - val_loss: 0.8540 - val_accuracy: 0.9041\n",
      "Epoch 1950/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0267 - accuracy: 0.9882 - val_loss: 0.8558 - val_accuracy: 0.9041\n",
      "Epoch 1951/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0265 - accuracy: 0.9882 - val_loss: 0.8552 - val_accuracy: 0.9041\n",
      "Epoch 1952/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0266 - accuracy: 0.9882 - val_loss: 0.8566 - val_accuracy: 0.9041\n",
      "Epoch 1953/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0266 - accuracy: 0.9882 - val_loss: 0.8577 - val_accuracy: 0.9041\n",
      "Epoch 1954/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0264 - accuracy: 0.9882 - val_loss: 0.8576 - val_accuracy: 0.9041\n",
      "Epoch 1955/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0268 - accuracy: 0.9852 - val_loss: 0.8588 - val_accuracy: 0.9041\n",
      "Epoch 1956/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0267 - accuracy: 0.9882 - val_loss: 0.8595 - val_accuracy: 0.9041\n",
      "Epoch 1957/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0263 - accuracy: 0.9882 - val_loss: 0.8606 - val_accuracy: 0.9041\n",
      "Epoch 1958/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0264 - accuracy: 0.9852 - val_loss: 0.8593 - val_accuracy: 0.9041\n",
      "Epoch 1959/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0265 - accuracy: 0.9852 - val_loss: 0.8590 - val_accuracy: 0.9041\n",
      "Epoch 1960/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0266 - accuracy: 0.9882 - val_loss: 0.8571 - val_accuracy: 0.9041\n",
      "Epoch 1961/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0264 - accuracy: 0.9882 - val_loss: 0.8596 - val_accuracy: 0.9041\n",
      "Epoch 1962/2000\n",
      "338/338 [==============================] - 0s 75us/step - loss: 0.0261 - accuracy: 0.9882 - val_loss: 0.8606 - val_accuracy: 0.9041\n",
      "Epoch 1963/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0263 - accuracy: 0.9852 - val_loss: 0.8591 - val_accuracy: 0.9041\n",
      "Epoch 1964/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0265 - accuracy: 0.9852 - val_loss: 0.8586 - val_accuracy: 0.9041\n",
      "Epoch 1965/2000\n",
      "338/338 [==============================] - 0s 77us/step - loss: 0.0265 - accuracy: 0.9852 - val_loss: 0.8568 - val_accuracy: 0.9041\n",
      "Epoch 1966/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0264 - accuracy: 0.9882 - val_loss: 0.8581 - val_accuracy: 0.9041\n",
      "Epoch 1967/2000\n",
      "338/338 [==============================] - 0s 80us/step - loss: 0.0270 - accuracy: 0.9882 - val_loss: 0.8592 - val_accuracy: 0.9041\n",
      "Epoch 1968/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0267 - accuracy: 0.9882 - val_loss: 0.8611 - val_accuracy: 0.9041\n",
      "Epoch 1969/2000\n",
      "338/338 [==============================] - 0s 74us/step - loss: 0.0264 - accuracy: 0.9852 - val_loss: 0.8615 - val_accuracy: 0.9041\n",
      "Epoch 1970/2000\n",
      "338/338 [==============================] - 0s 75us/step - loss: 0.0266 - accuracy: 0.9882 - val_loss: 0.8631 - val_accuracy: 0.9041\n",
      "Epoch 1971/2000\n",
      "338/338 [==============================] - 0s 77us/step - loss: 0.0263 - accuracy: 0.9852 - val_loss: 0.8626 - val_accuracy: 0.9041\n",
      "Epoch 1972/2000\n",
      "338/338 [==============================] - 0s 64us/step - loss: 0.0265 - accuracy: 0.9882 - val_loss: 0.8640 - val_accuracy: 0.9041\n",
      "Epoch 1973/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0265 - accuracy: 0.9852 - val_loss: 0.8615 - val_accuracy: 0.9041\n",
      "Epoch 1974/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0264 - accuracy: 0.9882 - val_loss: 0.8598 - val_accuracy: 0.9041\n",
      "Epoch 1975/2000\n",
      "338/338 [==============================] - 0s 69us/step - loss: 0.0264 - accuracy: 0.9882 - val_loss: 0.8608 - val_accuracy: 0.9041\n",
      "Epoch 1976/2000\n",
      "338/338 [==============================] - 0s 63us/step - loss: 0.0262 - accuracy: 0.9852 - val_loss: 0.8588 - val_accuracy: 0.9041\n",
      "Epoch 1977/2000\n",
      "338/338 [==============================] - 0s 71us/step - loss: 0.0266 - accuracy: 0.9882 - val_loss: 0.8601 - val_accuracy: 0.9041\n",
      "Epoch 1978/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0265 - accuracy: 0.9852 - val_loss: 0.8608 - val_accuracy: 0.9041\n",
      "Epoch 1979/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0263 - accuracy: 0.9882 - val_loss: 0.8595 - val_accuracy: 0.9041\n",
      "Epoch 1980/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0265 - accuracy: 0.9882 - val_loss: 0.8622 - val_accuracy: 0.9041\n",
      "Epoch 1981/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0263 - accuracy: 0.9882 - val_loss: 0.8611 - val_accuracy: 0.9041\n",
      "Epoch 1982/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0270 - accuracy: 0.9882 - val_loss: 0.8559 - val_accuracy: 0.9041\n",
      "Epoch 1983/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "338/338 [==============================] - 0s 67us/step - loss: 0.0263 - accuracy: 0.9882 - val_loss: 0.8566 - val_accuracy: 0.9041\n",
      "Epoch 1984/2000\n",
      "338/338 [==============================] - 0s 64us/step - loss: 0.0268 - accuracy: 0.9852 - val_loss: 0.8578 - val_accuracy: 0.9041\n",
      "Epoch 1985/2000\n",
      "338/338 [==============================] - 0s 66us/step - loss: 0.0262 - accuracy: 0.9882 - val_loss: 0.8583 - val_accuracy: 0.9041\n",
      "Epoch 1986/2000\n",
      "338/338 [==============================] - 0s 67us/step - loss: 0.0268 - accuracy: 0.9882 - val_loss: 0.8591 - val_accuracy: 0.9041\n",
      "Epoch 1987/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0260 - accuracy: 0.9882 - val_loss: 0.8622 - val_accuracy: 0.9041\n",
      "Epoch 1988/2000\n",
      "338/338 [==============================] - 0s 73us/step - loss: 0.0262 - accuracy: 0.9822 - val_loss: 0.8605 - val_accuracy: 0.9041\n",
      "Epoch 1989/2000\n",
      "338/338 [==============================] - 0s 68us/step - loss: 0.0264 - accuracy: 0.9882 - val_loss: 0.8598 - val_accuracy: 0.9041\n",
      "Epoch 1990/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0260 - accuracy: 0.9882 - val_loss: 0.8580 - val_accuracy: 0.9041\n",
      "Epoch 1991/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0265 - accuracy: 0.9882 - val_loss: 0.8592 - val_accuracy: 0.9041\n",
      "Epoch 1992/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0260 - accuracy: 0.9822 - val_loss: 0.8568 - val_accuracy: 0.9041\n",
      "Epoch 1993/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0268 - accuracy: 0.9882 - val_loss: 0.8570 - val_accuracy: 0.9041\n",
      "Epoch 1994/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0262 - accuracy: 0.9882 - val_loss: 0.8598 - val_accuracy: 0.9041\n",
      "Epoch 1995/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0263 - accuracy: 0.9852 - val_loss: 0.8590 - val_accuracy: 0.9041\n",
      "Epoch 1996/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0264 - accuracy: 0.9882 - val_loss: 0.8599 - val_accuracy: 0.9041\n",
      "Epoch 1997/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0261 - accuracy: 0.9882 - val_loss: 0.8607 - val_accuracy: 0.9041\n",
      "Epoch 1998/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0263 - accuracy: 0.9882 - val_loss: 0.8614 - val_accuracy: 0.9041\n",
      "Epoch 1999/2000\n",
      "338/338 [==============================] - 0s 72us/step - loss: 0.0266 - accuracy: 0.9882 - val_loss: 0.8622 - val_accuracy: 0.9041\n",
      "Epoch 2000/2000\n",
      "338/338 [==============================] - 0s 70us/step - loss: 0.0264 - accuracy: 0.9882 - val_loss: 0.8620 - val_accuracy: 0.9041\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "X = df.iloc[:,:-1]\n",
    "Y = df.iloc[:,-1]\n",
    "print(X)\n",
    "print(Y)\n",
    "\n",
    "\n",
    "def create_model_null():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(144,input_dim = 48, activation = 'sigmoid'))\n",
    "    model.add(Dense(1,activation = 'sigmoid'))\n",
    "    return model\n",
    "\n",
    "\n",
    "'''\n",
    "Model just with backpropagation\n",
    "'''\n",
    "def BP(X,Y):\n",
    "    n = create_model_null()\n",
    "    n.compile(optimizer = 'rmsprop', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    history = n.fit(X, Y, validation_split=0.3, epochs=2000, batch_size=20, verbose=1, shuffle = True)\n",
    "    # Plot training & validation accuracy values\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('Model accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    # Plot training & validation loss values\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper left')\n",
    "    plt.show()\n",
    "    \n",
    "BP(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.952054794520548\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=1) \n",
    "# 70% training and 30% test\n",
    "clf = DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
